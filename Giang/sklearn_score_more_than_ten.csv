Title,Body
"Python scikit-learn: exporting trained classifier","<p>I am using a DBN (deep belief network) from <a href=""https://pypi.python.org/pypi/nolearn"">nolearn</a> based on scikit-learn.</p>

<p>I have already build a Network which can classify my data very well, now I am interested in exporting the model for deployment, but I don't know how (I am training the DBN every time I want predict something). In matlab I would just export the weight matrix and import it in another machine.</p>

<p>Does someone know how to export the model/the weight matrix to be imported without needing to train the whole model again? </p>
"
"Use attribute and target matrices for TensorFlow Linear Regression Python","<p>I'm trying to follow <a href=""http://www.tensorflow.org/tutorials/mnist/beginners/index.md"" rel=""noreferrer"">this tutorial</a>.</p>

<p>TensorFlow just came out and I'm really trying to understand it.  I'm familiar with <em>penalized linear regression</em> like Lasso, Ridge, and ElasticNet and its usage in <code>scikit-learn</code>.  </p>

<p>For <code>scikit-learn</code> Lasso regression, all I need to input into the regression algorithm is <code>DF_X</code> [an M x N dimensional attribute matrix (pd.DataFrame)] and <code>SR_y</code> [an M dimensional target vector (pd.Series)].  The <code>Variable</code> structure in TensorFlow is a bit new to me and I'm not sure how to structure my input data into what it wants. </p>

<p>It seems as if softmax regression is for classification.  <strong>How can I restructure my <code>DF_X</code> (M x N attribute matrix) and <code>SR_y</code> (M dimensional target vector) to input into <code>tensorflow</code> for linear regression?</strong> </p>

<p>My current method for doing a Linear Regression uses pandas, numpy, and sklearn and it's shown below. I think this question will be really helpful for people getting familiar with TensorFlow:</p>

<pre><code>#!/usr/bin/python
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.linear_model import LassoCV

#Create DataFrames for attribute and target matrices
DF_X = pd.DataFrame(np.array([[0,0,1],[2,3,1],[4,5,1],[3,4,1]]),columns=[""att1"",""att2"",""att3""],index=[""s1"",""s2"",""s3"",""s4""])
SR_y = pd.Series(np.array([3,2,5,8]),index=[""s1"",""s2"",""s3"",""s4""],name=""target"")

print DF_X
#att1  att2  att3
#s1     0     0     1
#s2     2     3     1
#s3     4     5     1
#s4     3     4     1

print SR_y
#s1    3
#s2    2
#s3    5
#s4    8
#Name: target, dtype: int64

#Create Linear Model (Lasso Regression)
model = LassoCV()
model.fit(DF_X,SR_y)

print model
#LassoCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True,
#max_iter=1000, n_alphas=100, n_jobs=1, normalize=False, positive=False,
#precompute='auto', random_state=None, selection='cyclic', tol=0.0001,
#verbose=False)

print model.coef_
#[ 0.         0.3833346  0.       ]
</code></pre>
"
"Feature selection using scikit-learn","<p>I'm new in machine learning. I'm preparing my data for classification using Scikit Learn SVM. 
in order  to select the best features i have used the following method : </p>

<pre><code>SelectKBest(chi2, k=10).fit_transform(A1, A2)
</code></pre>

<p>Since my dataset consist of negative values, I get the following error:</p>

<pre><code>ValueError                                Traceback (most recent call last)

/media/5804B87404B856AA/TFM_UC3M/test2_v.py in &lt;module&gt;()
----&gt; 1 
      2 
      3 
      4 
      5 

/usr/local/lib/python2.6/dist-packages/sklearn/base.pyc in fit_transform(self, X, y,     **fit_params)
    427         else:
    428             # fit method of arity 2 (supervised transformation)

--&gt; 429             return self.fit(X, y, **fit_params).transform(X)
    430 
    431 

/usr/local/lib/python2.6/dist-packages/sklearn/feature_selection/univariate_selection.pyc in fit(self, X, y)
    300         self._check_params(X, y)
    301 
--&gt; 302         self.scores_, self.pvalues_ = self.score_func(X, y)
    303         self.scores_ = np.asarray(self.scores_)
    304         self.pvalues_ = np.asarray(self.pvalues_)

/usr/local/lib/python2.6/dist-  packages/sklearn/feature_selection/univariate_selection.pyc in chi2(X, y)
    190     X = atleast2d_or_csr(X)
    191     if np.any((X.data if issparse(X) else X) &lt; 0):
--&gt; 192         raise ValueError(""Input X must be non-negative."")
    193 
    194     Y = LabelBinarizer().fit_transform(y)

ValueError: Input X must be non-negative.
</code></pre>

<p>Can someone tell me how can I transform my data ?</p>

<p>Thank you in advance.</p>
"
"SKlearn import MLPClassifier fails","<p>I am trying to use the <a href=""http://scikit-learn.org/dev/modules/neural_networks_supervised.html#classification"">multilayer perceptron</a> from scikit-learn in python. My problem is, that the import is not working. All other modules from scikit-learn are working fine. </p>

<pre><code>from sklearn.neural_network import MLPClassifier
</code></pre>

<blockquote>
  <p>Import Error: cannot import name MLPClassifier</p>
</blockquote>

<p>I'm using the Python Environment Python64-bit 3.4 in Visual Studio 2015. 
I installed sklearn over the console with: <code>conda install scikit-learn</code>
I also installed numpy and pandas. After I had the error above I also installed <a href=""http://scikit-neuralnetwork.readthedocs.org/en/latest/index.html"">scikit-neuralnetwork</a> with: <code>pip install scikit-neuralnetwork</code>
The installed scikit-learn version is 0.17.</p>

<p>What have I done wrong? Am I missing an installation?</p>

<p>----- EDIT ----</p>

<p>In addition to the answer of tttthomasssss, I found the solution on how to install the sknn library for neuronal networks. I followed this <a href=""http://deeplearning.net/software/theano/install_windows.html"">tutorial</a>.
Do the following steps:</p>

<ul>
<li><code>pip install scikit-neuralnetwork</code></li>
<li>download and install the <a href=""http://tdm-gcc.tdragon.net/"">GCC compiler</a></li>
<li>install mingw with <code>conda install mingw libpython</code></li>
</ul>

<p>You can use the <a href=""http://scikit-neuralnetwork.readthedocs.org/en/latest/guide_beginners.html#example-regression"">sknn</a> library after.</p>
"
"A column-vector y was passed when a 1d array was expected","<p>I need to fit <code>RandomForestRegressor</code> from <code>sklearn.ensemble</code>.</p>

<pre><code>forest = ensemble.RandomForestRegressor(**RF_tuned_parameters)
model = forest.fit(train_fold, train_y)
yhat = model.predict(test_fold)
</code></pre>

<p>This code always worked until I made some preprocessing of data (<code>train_y</code>).
The error message says:</p>

<blockquote>
  <p>DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().</p>
  
  <p>model = forest.fit(train_fold, train_y)</p>
</blockquote>

<p>Previously <code>train_y</code> was a Series, now it's numpy array (it is a column-vector). If I apply <code>train_y.ravel()</code>, then it becomes a row vector and no error message appears, through the prediction step takes very long time (actually it never finishes...).</p>

<p>In the docs of <code>RandomForestRegressor</code> I found that <code>train_y</code> should be defined as <code>y : array-like, shape = [n_samples] or [n_samples, n_outputs]</code>
Any idea how to solve this issue?</p>
"
"Adding words to scikit-learn's CountVectorizer's stop list","<p>Scikit-learn's <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"">CountVectorizer</a> class lets you pass a string 'english' to the argument stop_words.  I want to add some things to this predefined list.  Can anyone tell me how to do this?  </p>
"
"Can you fix the false negative rate in a classifier in scikit learn","<p>I am using a <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"" rel=""noreferrer"">Random Forest classifer</a> in scikit learn with an imbalanced data set of two classes. I am much more worried about false negatives than  false positives.  Is it possible to fix the false negative rate (to, say, 1%) and ask scikit to optimize the false positive rate somehow?</p>

<p>If this classifier doesn't support it, is there another classifier that  does?</p>
"
"How can I capture return value with Python timeit module?","<p>Im running several machine learning algorithms with sklearn in a for loop and want to see how long each of them takes.  The problem is I also need to return a value and DONT want to have to run it more than once because each algorithm takes so long. Is there a way to capture the return value 'clf' using python's timeit module or a similar one with a function like this...</p>

<pre><code>def RandomForest(train_input, train_output):
    clf = ensemble.RandomForestClassifier(n_estimators=10)
    clf.fit(train_input, train_output)
    return clf
</code></pre>

<p>when I call the function like this</p>

<pre><code>t = Timer(lambda : RandomForest(trainX,trainy))
print t.timeit(number=1)
</code></pre>

<p>P.S. I also dont want to set a global 'clf' because I might want to do multithreading or multiprocessing later.</p>
"
"Normalise between 0 and 1 ignoring NaN","<p>For a list of numbers ranging from <code>x</code> to <code>y</code> that may contain <code>NaN</code>, how can I normalise between 0 and 1, ignoring the <code>NaN</code> values (they stay as <code>NaN</code>).</p>

<p>Typically I would use <code>MinMaxScaler</code> (<a href=""http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler"" rel=""noreferrer"">ref page</a>) from <code>sklearn.preprocessing</code>, but this cannot handle <code>NaN</code> and recommends imputing the values based on mean or median etc. it doesn't offer the option to ignore all the <code>NaN</code> values.</p>
"
"Blaze with Scikit Learn K-Means","<p>I am trying to fit Blaze data object to scikit kmeans function.</p>

<pre><code>from blaze import *
from sklearn.cluster import KMeans
data_numeric = Data('data.csv')
data_cluster = KMeans(n_clusters=5)
data_cluster.fit(data_numeric)
</code></pre>

<p>Data Sample:</p>

<pre><code>A  B  C
1  32 34
5  57 92
89 67 21
</code></pre>

<p>Its throwing error :</p>

<p><a href=""https://i.stack.imgur.com/g3IBI.png."" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/g3IBI.png."" alt=""enter image description here""></a></p>

<p>I have been able to do it with Pandas Dataframe. Any way to feed blaze object to this function ?</p>
"
"scikit learn: how to check coefficients significance","<p>i tried to do a LR with SKLearn for a rather large dataset with ~600 dummy and only few interval variables (and 300 K lines in my dataset) and the resulting confusion matrix looks suspicious. I wanted to check the significance of the returned coefficients and ANOVA but I cannot find how to access it. Is it possible at all? And what is the best strategy for data that contains lots of dummy variables? Thanks a lot!    </p>
"
"Impute categorical missing values in scikit-learn","<p>I've got pandas data with some columns of text type. There are some NaN values along with these text columns. What I'm trying to do is to impute those NaN's by sklearn.preprocessing. Imputer (replacing NaN by the most frequent value). The problem is in implementation.
Suppose there is a Pandas dataframe df with 30 columns, 10 of which are of categorical nature.
Once I run</p>

<pre><code>from sklearn.preprocessing import Imputer
imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)
imp.fit(df) 
</code></pre>

<p>Python generates an error: 'could not convert string to float: 'run1'', where 'run1' is an ordinary (non-missing) value from the first column with categorical data.</p>

<p>Any help would be very welcome</p>
"
"Why does one hot encoding improve machine learning performance?","<p>I have noticed that when One Hot encoding is used on a particular data set (a matrix) and used as training data for learning algorithms, it gives significantly better results with respect to prediction accuracy, compared to using the original matrix itself as training data. How does this performance increase happen? </p>
"
"Scoring function for RidgeClassifierCV","<p>I'm trying to implement a custom scoring function for RidgeClassifierCV in scikit-learn.  This involves passing a custom scoring function as the <code>score_func</code> when initializing the <code>RidgeClassifierCV</code> object.  I expected the score_func to take in categorical values as input for <code>y_true</code> and <code>y_pred</code>.  Instead, however, floating point values are passed in as <code>y_true</code> and <code>y_pred</code>.  The size of the y vectors is equal to the number of classes times the number of training examples, rather than simply having a y vector with length equivalent to the number of training examples. </p>

<p>Can I somehow force categorical predictions to be passed into the custom scoring function, or do I have to deal with the raw weights?  If I do have to deal directly with the raw weights, is the index of the maximum value in a slice of the vector of outputs equivalent to the predicted class?</p>
"
"Naive Bayes: Imbalanced Test Dataset","<p>I am using scikit-learn Multinomial Naive Bayes classifier for binary text classification (classifier tells me whether the document belongs to the category X or not). I use a balanced dataset to train my model and a balanced test set to test it and the results are very promising.</p>

<p>This classifer needs to run in real time and constantly analyze documents thrown at it randomly.</p>

<p>However, when I run my classifier in production, the number of false positives is very high and therefore I end up with a very low precision. The reason is simple: there are many more negative samples that the classifer encounters in the real-time scenario (around 90 % of the time) and this does not correspond to the ideal balanced dataset I used for testing and training.</p>

<p>Is there a way I can simulate this real-time case during training or are there any tricks that I can use (including pre-processing on the documents to see if they are suitable for the classifer)? </p>

<p>I was planning to train my classifier using an imbalanced dataset with the same proportions as I have in real-time case but I am afraid that might bias Naive Bayes towards the negative class and lose the recall I have on the positive class.</p>

<p>Any advice is appreciated. </p>
"
"How to obtain information gain from a scikit-learn DecisionTreeClassifier?","<p>I see that DecisionTreeClassifier accepts criterion='entropy', which means that it must be using information gain as a criterion for splitting the decision tree. 
What I need is the information gain for each feature at the root level, when it is about to split the root node.</p>
"
"How can I fix a MemoryError when executing scikit-learns silhouette score?","<p>I run a clustering algorithm and want to evaluate the result by using silhouette score in scikit-learn. But in the scikit-learn, it needs to calculate the distance matrix: distances = pairwise_distances(X, metric=metric, **kwds)</p>

<p>Due to the fact that my data is order of 300K, and my memory is 2GB, and the result is out of memory. And I can not evaluate the clustering result.</p>

<p>Does anyone know how to overcome this problem?</p>
"
"Regression with Date variable using Scikit-learn","<p>I have a Pandas DataFrame with a <code>date</code> column (eg: <code>2013-04-01</code>) of dtype <code>datetime.date</code>. When I include that column in <code>X_train</code> and try to fit the regression model, I get the error <code>float() argument must be a string or a number</code>. Removing the <code>date</code> column avoided this error.</p>

<p>What is the proper way to take the <code>date</code> into account in the regression model?</p>

<p><strong>Code</strong></p>

<pre><code>data = sql.read_frame(...)
X_train = data.drop('y', axis=1)
y_train = data.y

rf = RandomForestRegressor().fit(X_train, y_train)
</code></pre>

<p><strong>Error</strong></p>

<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-35-8bf6fc450402&gt; in &lt;module&gt;()
----&gt; 2 rf = RandomForestRegressor().fit(X_train, y_train)

C:\Python27\lib\site-packages\sklearn\ensemble\forest.pyc in fit(self, X, y, sample_weight)
    292                 X.ndim != 2 or
    293                 not X.flags.fortran):
--&gt; 294             X = array2d(X, dtype=DTYPE, order=""F"")
    295 
    296         n_samples, self.n_features_ = X.shape

C:\Python27\lib\site-packages\sklearn\utils\validation.pyc in array2d(X, dtype, order, copy)
     78         raise TypeError('A sparse matrix was passed, but dense data '
     79                         'is required. Use X.toarray() to convert to dense.')
---&gt; 80     X_2d = np.asarray(np.atleast_2d(X), dtype=dtype, order=order)
     81     _assert_all_finite(X_2d)
     82     if X is X_2d and copy:

C:\Python27\lib\site-packages\numpy\core\numeric.pyc in asarray(a, dtype, order)
    318 
    319     """"""
--&gt; 320     return array(a, dtype, copy=False, order=order)
    321 
    322 def asanyarray(a, dtype=None, order=None):

TypeError: float() argument must be a string or a number
</code></pre>
"
"Sklearn SGDClassifier partial fit","<p>I'm trying to use SGD to classify a large dataset. As the data is too large to fit into memory, I'd like to use the <em>partial_fit</em> method to train the classifier. I have selected a sample of the dataset (100,000 rows) that fits into memory to test <em>fit</em> vs. <em>partial_fit</em>:</p>

<pre><code>from sklearn.linear_model import SGDClassifier

def batches(l, n):
    for i in xrange(0, len(l), n):
        yield l[i:i+n]

clf1 = SGDClassifier(shuffle=True, loss='log')
clf1.fit(X, Y)

clf2 = SGDClassifier(shuffle=True, loss='log')
n_iter = 60
for n in range(n_iter):
    for batch in batches(range(len(X)), 10000):
        clf2.partial_fit(X[batch[0]:batch[-1]+1], Y[batch[0]:batch[-1]+1], classes=numpy.unique(Y))
</code></pre>

<p>I then test both classifiers with an identical test set. In the first case I get an accuracy of 100%. As I understand it, SGD by default passes 5 times over the training data (n_iter = 5).</p>

<p>In the second case, I have to pass 60 times over the data to reach the same accuracy.</p>

<p>Why this difference (5 vs. 60)? Or am I doing something wrong?</p>
"
"How to save Scikit-Learn-Keras Model into a Persistence File (pickle/hd5/json/yaml)","<p>I have the following code, using <a href=""https://github.com/fchollet/keras/blob/master/keras/wrappers/scikit_learn.py"">Keras Scikit-Learn Wrapper</a>:</p>

<pre><code>from keras.models import Sequential
from sklearn import datasets
from keras.layers import Dense
from sklearn.model_selection import train_test_split
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn import preprocessing
import pickle
import numpy as np
import json

def classifier(X, y):
    """"""
    Description of classifier
    """"""
    NOF_ROW, NOF_COL =  X.shape

    def create_model():
        # create model
        model = Sequential()
        model.add(Dense(12, input_dim=NOF_COL, init='uniform', activation='relu'))
        model.add(Dense(6, init='uniform', activation='relu'))
        model.add(Dense(1, init='uniform', activation='sigmoid'))
        # Compile model
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        return model

    # evaluate using 10-fold cross validation
    seed = 7
    np.random.seed(seed)
    model = KerasClassifier(build_fn=create_model, nb_epoch=150, batch_size=10, verbose=0)
    return model


def main():
    """"""
    Description of main
    """"""

    iris = datasets.load_iris()
    X, y = iris.data, iris.target
    X = preprocessing.scale(X)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)
    model_tt = classifier(X_train, y_train)
    model_tt.fit(X_train,y_train)

    #--------------------------------------------------
    # This fail
    #-------------------------------------------------- 
    filename = 'finalized_model.sav'
    pickle.dump(model_tt, open(filename, 'wb'))
    # load the model from disk
    loaded_model = pickle.load(open(filename, 'rb'))
    result = loaded_model.score(X_test, Y_test)
    print(result)

    #--------------------------------------------------
    # This also fail
    #--------------------------------------------------
    # from keras.models import load_model       
    # model_tt.save('test_model.h5')


    #--------------------------------------------------
    # This works OK 
    #-------------------------------------------------- 
    # print model_tt.score(X_test, y_test)
    # print model_tt.predict_proba(X_test)
    # print model_tt.predict(X_test)


# Output of predict_proba
# 2nd column is the probability that the prediction is 1
# this value is used as final score, which can be used
# with other method as comparison
# [   [ 0.25311464  0.74688536]
#     [ 0.84401423  0.15598579]
#     [ 0.96047372  0.03952631]
#     ...,
#     [ 0.25518912  0.74481088]
#     [ 0.91467732  0.08532269]
#     [ 0.25473493  0.74526507]]

# Output of predict
# [[1]
# [0]
# [0]
# ...,
# [1]
# [0]
# [1]]


if __name__ == '__main__':
    main()
</code></pre>

<p>As stated in the code there it fails at this line:</p>

<pre><code>pickle.dump(model_tt, open(filename, 'wb'))
</code></pre>

<p>With this error:</p>

<pre><code>pickle.PicklingError: Can't pickle &lt;function create_model at 0x101c09320&gt;: it's not found as __main__.create_model
</code></pre>

<p>How can I get around it?</p>
"
"Python - What is exactly sklearn.pipeline.Pipeline?","<p>I can't figure out how the <code>sklearn.pipeline.Pipeline</code> works exactly.</p>

<p>There are a few explanation in the <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"" rel=""noreferrer"">doc</a>. For example what do they mean by:</p>

<blockquote>
  <p>Pipeline of transforms with a final estimator.</p>
</blockquote>

<p>To make my question clearer, what are <code>steps</code>? How do they work?</p>

<p><strong>Edit</strong></p>

<p>Thanks to the answers I can make my question clearer:</p>

<p>When I call pipeline and pass, as steps, two transformers and one estimator, e.g:</p>

<pre><code>pipln = Pipeline([(""trsfm1"",transformer_1),
                  (""trsfm2"",transformer_2),
                  (""estmtr"",estimator)])
</code></pre>

<p>What happens when I call this?</p>

<pre><code>pipln.fit()
OR
pipln.fit_transform()
</code></pre>

<p>I can't figure out how an estimator can be a transformer and how a transformer can be fitted.</p>
"
"multiprocessing.Pool hangs if child causes a segmentation fault","<p>I want to apply a function in parallel using multiprocessing.Pool.
The problem is that if one function call triggers a segmentation fault the Pool hangs forever.
Has anybody an idea how I can make a Pool that detects when something like this happens and raises an error?</p>

<p>The following example shows how to reproduce it (requires scikit-learn > 0.14)</p>

<pre><code>import numpy as np
from sklearn.ensemble import gradient_boosting
import time

from multiprocessing import Pool

class Bad(object):
    tree_ = None


def fit_one(i):
    if i == 3:
        # this will segfault                                                    
        bad = np.array([[Bad()] * 2], dtype=np.object)
        gradient_boosting.predict_stages(bad,
                                         np.random.rand(20, 2).astype(np.float32),
                                         1.0, np.random.rand(20, 2))
    else:
        time.sleep(1)
    return i


pool = Pool(2)
out = pool.imap_unordered(fit_one, range(10))
# we will never see 3
for o in out:
    print o
</code></pre>
"
"Label encoding across multiple columns in scikit-learn","<p>I'm trying to use scikit-learn's <code>LabelEncoder</code> to encode a pandas <code>DataFrame</code> of string labels. As the dataframe has many (50+) columns, I want to avoid creating a <code>LabelEncoder</code> object for each column; I'd rather just have one big <code>LabelEncoder</code> objects that works across <em>all</em> my columns of data.  </p>

<p>Throwing the entire <code>DataFrame</code> into <code>LabelEncoder</code> creates the below error.  Please bear in mind that I'm using dummy data here; in actuality I'm dealing with about 50 columns of string labeled data, so need a solution that doesn't reference any columns by name. </p>

<pre><code>import pandas
from sklearn import preprocessing 

df = pandas.DataFrame({'pets':['cat', 'dog', 'cat', 'monkey', 'dog', 'dog'], 'owner':['Champ', 'Ron', 'Brick', 'Champ', 'Veronica', 'Ron'], 'location':['San_Diego', 'New_York', 'New_York', 'San_Diego', 'San_Diego', 'New_York']})
le = preprocessing.LabelEncoder()

le.fit(df)
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/Users/bbalin/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/label.py"", line 103, in fit
    y = column_or_1d(y, warn=True)
  File ""/Users/bbalin/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py"", line 306, in column_or_1d
    raise ValueError(""bad input shape {0}"".format(shape))
ValueError: bad input shape (6, 3)
</code></pre>

<p>Any thoughts on how to get around this problem? </p>
"
"Eliminating warnings from scikit-learn","<p>I would like to ignore warnings from all packages when I am teaching, but scikit-learn seems to work around the use of the <code>warnings</code> package to control this. For example:</p>

<pre><code>with warnings.catch_warnings():
    warnings.simplefilter(""ignore"")
    from sklearn import preprocessing

/usr/local/lib/python3.5/site-packages/sklearn/utils/fixes.py:66: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead
  if 'order' in inspect.getargspec(np.copy)[0]:
/usr/local/lib/python3.5/site-packages/sklearn/utils/fixes.py:358: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead
  if 'exist_ok' in inspect.getargspec(os.makedirs).args:
</code></pre>

<p>Am I using this module incorrectly, or is sklearn doing something its not supposed to?</p>
"
"What are the pitfalls of using Dill to serialise scikit-learn/statsmodels models?","<p>I need to serialise scikit-learn/statsmodels models such that all the dependencies (code + data) are packaged in an artefact and this artefact can be used to initialise the model and make predictions. Using the pickle <code>module</code> is not an option because this will only take care of the data dependency (the code will not be packaged). So, I have been conducting experiments with <a href=""https://pypi.python.org/pypi/dill"">Dill</a>. To make my question more precise, the following is an example where I build a model and persist it. </p>

<pre><code>from sklearn import datasets
from sklearn import svm
from sklearn.preprocessing import Normalizer
import dill

digits = datasets.load_digits()
training_data_X = digits.data[:-5]
training_data_Y = digits.target[:-5]
test_data_X = digits.data[-5:]
test_data_Y = digits.target[-5:]

class Model:
    def __init__(self):
        self.normalizer = Normalizer()
        self.clf = svm.SVC(gamma=0.001, C=100.)
    def train(self, training_data_X, training_data_Y):
        normalised_training_data_X = normalizer.fit_transform(training_data_X)
        self.clf.fit(normalised_training_data_X, training_data_Y)
    def predict(self, test_data_X):
        return self.clf.predict(self.normalizer.fit_transform(test_data_X))  

model = Model()
model.train(training_data_X, training_data_Y)
print model.predict(test_data_X)
dill.dump(model, open(""my_model.dill"", 'w'))
</code></pre>

<p>Corresponding to this, here is how I initialise the persisted model (in a new session) and make a prediction. Note that this code does not explicitly initialise or have knowledge of the <code>class Model</code>.</p>

<pre><code>import dill
from sklearn import datasets

digits = datasets.load_digits()
training_data_X = digits.data[:-5]
training_data_Y = digits.target[:-5]
test_data_X = digits.data[-5:]
test_data_Y = digits.target[-5:]

with open(""my_model.dill"") as model_file:
    model = dill.load(model_file)

print model.predict(test_data_X)
</code></pre>

<p>Has anyone used Dill isn this way?. The idea is for a data scientist to extend a <code>ModelWrapper class</code> for each model they implement and then build the infrastructure around this that persists the models, deploy the models as services and manage the entire lifecycle of the model.</p>

<pre><code>class ModelWrapper(object):
    __metaclass__ = abc.ABCMeta
    def __init__(self, model):
        self.model = model
    @abc.abstractmethod
    def predict(self, input):
        return
    def dumps(self):
        return dill.dumps(self)
    def loads(self, model_string):
        self.model = dill.loads(model_string)
</code></pre>

<p>Other than the security implications (arbitrary code execution) and the requirement that modules like <code>scikit-learn</code> will have to be installed on the machine thats serving the model, are there and any other pitfalls in this approach? Any comments or words of advice would be most helpful.  </p>

<p>I think that <a href=""https://www.yhathq.com/"">YHat</a> and <a href=""https://dato.com/"">Dato</a> have taken similar approach but rolled out there own implementations of Dill for similar purposes. </p>
"
"Is scikit-learn suitable for big data tasks?","<p>I'm working on a TREC task involving use of machine learning techniques, where the dataset consists of more than 5 terabytes of web documents, from which bag-of-words vectors are planned to be extracted. <code>scikit-learn</code> has a nice set of functionalities that seems to fit my need, but I don't know whether it is going to scale well to handle big data. For example, is <code>HashingVectorizer</code> able to handle 5 terabytes of documents, and is it feasible to parallelize it? Moreover, what are some alternatives out there for large-scale machine learning tasks?</p>
"
"Scikit-learn predict_proba gives wrong answers","<p>This is a follow-up question from <a href=""https://stackoverflow.com/questions/16937243/how-to-know-what-classes-are-represented-in-return-array-from-predict-proba-in-s"">How to know what classes are represented in return array from predict_proba in Scikit-learn</a></p>

<p>In that question, I quoted the following code:</p>

<pre><code>&gt;&gt;&gt; import sklearn
&gt;&gt;&gt; sklearn.__version__
'0.13.1'
&gt;&gt;&gt; from sklearn import svm
&gt;&gt;&gt; model = svm.SVC(probability=True)
&gt;&gt;&gt; X = [[1,2,3], [2,3,4]] # feature vectors
&gt;&gt;&gt; Y = ['apple', 'orange'] # classes
&gt;&gt;&gt; model.fit(X, Y)
&gt;&gt;&gt; model.predict_proba([1,2,3])
array([[ 0.39097541,  0.60902459]])
</code></pre>

<p>I discovered in that question this result represents the probability of the point belonging to each class, in the order given by model.classes_</p>

<pre><code>&gt;&gt;&gt; zip(model.classes_, model.predict_proba([1,2,3])[0])
[('apple', 0.39097541289393828), ('orange', 0.60902458710606167)]
</code></pre>

<p>So... this answer, if interpreted correctly, says that the point is probably an 'orange' (with a fairly low confidence, due to the tiny amount of data). But intuitively, this result is obviously incorrect, since the point given was identical to the training data for 'apple'. Just to be sure, I tested the reverse as well: </p>

<pre><code>&gt;&gt;&gt; zip(model.classes_, model.predict_proba([2,3,4])[0])
[('apple', 0.60705475211840931), ('orange', 0.39294524788159074)]
</code></pre>

<p>Again, obviously incorrect, but in the other direction.</p>

<p>Finally, I tried it with points that were much further away.</p>

<pre><code>&gt;&gt;&gt; X = [[1,1,1], [20,20,20]] # feature vectors
&gt;&gt;&gt; model.fit(X, Y)
&gt;&gt;&gt; zip(model.classes_, model.predict_proba([1,1,1])[0])
[('apple', 0.33333332048410247), ('orange', 0.66666667951589786)]
</code></pre>

<p>Again, the model predicts the wrong probabilities. BUT, the model.predict function gets it right!</p>

<pre><code>&gt;&gt;&gt; model.predict([1,1,1])[0]
'apple'
</code></pre>

<p>Now, I remember reading something in the docs about predict_proba being inaccurate for small datasets, though I can't seem to find it again. Is this the expected behaviour, or am I doing something wrong? If this IS the expected behaviour, then why does the predict and predict_proba function disagree one the output? And importantly, how big does the dataset need to be before I can trust the results from predict_proba?</p>

<p><strong>-------- UPDATE --------</strong></p>

<p>Ok, so I did some more 'experiments' into this: the behaviour of predict_proba is heavily dependent on 'n', but not in any predictable way!</p>

<pre><code>&gt;&gt;&gt; def train_test(n):
...     X = [[1,2,3], [2,3,4]] * n
...     Y = ['apple', 'orange'] * n
...     model.fit(X, Y)
...     print ""n ="", n, zip(model.classes_, model.predict_proba([1,2,3])[0])
... 
&gt;&gt;&gt; train_test(1)
n = 1 [('apple', 0.39097541289393828), ('orange', 0.60902458710606167)]
&gt;&gt;&gt; for n in range(1,10):
...     train_test(n)
... 
n = 1 [('apple', 0.39097541289393828), ('orange', 0.60902458710606167)]
n = 2 [('apple', 0.98437355278112448), ('orange', 0.015626447218875527)]
n = 3 [('apple', 0.90235408180319321), ('orange', 0.097645918196806694)]
n = 4 [('apple', 0.83333299908143665), ('orange', 0.16666700091856332)]
n = 5 [('apple', 0.85714254878984497), ('orange', 0.14285745121015511)]
n = 6 [('apple', 0.87499969631893626), ('orange', 0.1250003036810636)]
n = 7 [('apple', 0.88888844127886335), ('orange', 0.11111155872113669)]
n = 8 [('apple', 0.89999988018127364), ('orange', 0.10000011981872642)]
n = 9 [('apple', 0.90909082368682159), ('orange', 0.090909176313178491)]
</code></pre>

<p>How should I use this function safely in my code? At the very least, is there any value of n for which it will be guaranteed to agree with the result of model.predict?</p>
"
"Save classifier to disk in scikit-learn","<p>How do I save a trained <strong>Naive Bayes classifier</strong> to <strong>disk</strong> and use it to <strong>predict</strong> data?</p>

<p>I have the following sample program from the scikit-learn website:</p>

<pre><code>from sklearn import datasets
iris = datasets.load_iris()
from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)
print ""Number of mislabeled points : %d"" % (iris.target != y_pred).sum()
</code></pre>
"
"TFIDF for Large Dataset","<p>I have a corpus which has around 8 million news articles, I need to get the TFIDF representation of them as a sparse matrix. I have been able to do that using scikit-learn for relatively lower number of samples, but I believe it can't be used for such a huge dataset as it loads the input matrix into memory first and that's an expensive process.</p>

<p>Does anyone know, what would be the best way to extract out the TFIDF vectors for large datasets?</p>
"
"Python scikit-learn SVM Classifier ""ValueError: Found array with dim 3. Expected <= 2""","<p>I am trying to implement SVM Classifier over MNIST dataset.
As my parameters are 3 dimensional its throwing the following error:</p>

<pre><code>ValueError: Found array with dim 3. Expected &lt;= 2
</code></pre>

<p>Following is my code snippet:</p>

<pre><code>import mnist
from sklearn import svm

training_images, training_labels = mnist.load_mnist(""training"", digits = [1,2,3,4])
classifier = svm.SVC()
classifier.fit(training_images, training_labels)
</code></pre>

<p>Does sklearn support a multi-dimensional classifier?</p>
"
"scikit-learn: clustering text documents using DBSCAN","<p>I'm tryin to use scikit-learn to cluster text documents. On the whole, I find my way around, but I have my problems with specific issues. Most of the examples I found illustrate clustering using scikit-learn with k-means as clustering algorithm. Adopting these example with k-means to my setting works in principle. However, k-means is not suitable since I don't know the number of clusters. From what I read so far -- please correct me here if needed -- DBSCAN or MeanShift seem the be more appropriate in my case. The scikit-learn website provides examples for each cluster algorithm. The problem is now, that with both DBSCAN and MeanShift I get errors I cannot comprehend, let alone solve.</p>

<p>My minimal code is as follows:</p>

<pre><code>docs = []
for item in [database]:
    docs.append(item)

vectorizer = TfidfVectorizer(min_df=1)
X = vectorizer.fit_transform(docs)

X = X.todense() # &lt;-- This line was needed to resolve the isse

db = DBSCAN(eps=0.3, min_samples=10).fit(X)
...
</code></pre>

<p>(My documents are already processed, i.e., stopwords have been removed and an Porter Stemmer has been applied.)</p>

<p>When I run this code, I get the following error when instatiating DBSCAN and calling <code>fit()</code>:</p>

<pre><code>...
File ""/usr/local/lib/python2.7/dist-packages/sklearn/cluster/dbscan_.py"", line 248, in fit
clust = dbscan(X, **self.get_params())
File ""/usr/local/lib/python2.7/dist-packages/sklearn/cluster/dbscan_.py"", line 86, in dbscan
n = X.shape[0]
IndexError: tuple index out of range
</code></pre>

<p>Clicking on the line in <code>dbscan_.py</code> that throws the error, I noticed the following line</p>

<pre><code>...
X = np.asarray(X)
n = X.shape[0]
...
</code></pre>

<p>When I use these to lines directly in my code for testing, I get the same error. I don't really know what <code>np.asarray(X)</code> is doing here, but after the command <code>X.shape = ()</code>. Hence <code>X.shape[0]</code> bombs -- before, <code>X.shape[0]</code> correctly refers to the number of documents. Out of curiosity, I removed <code>X = np.asarray(X)</code> from <code>dbscan_.py</code>. When I do this, something is computing heavily. But after some seconds, I get another error:</p>

<pre><code>...
File ""/usr/lib/python2.7/dist-packages/scipy/sparse/csr.py"", line 214, in extractor
(min_indx,max_indx) = check_bounds(indices,N)
File ""/usr/lib/python2.7/dist-packages/scipy/sparse/csr.py"", line 198, in check_bounds
max_indx = indices.max()
File ""/usr/lib/python2.7/dist-packages/numpy/core/_methods.py"", line 17, in _amax
out=out, keepdims=keepdims)
ValueError: zero-size array to reduction operation maximum which has no identity
</code></pre>

<p>In short, I have no clue how to get DBSCAN working, or what I might have missed, in general.</p>
"
"How to see top n entries of term-document matrix after tfidf in scikit-learn","<p>I am new to scikit-learn, and I was using <code>TfidfVectorizer</code> to find the tfidf values of terms in a set of documents. I used the following code to obtain the same.</p>

<pre><code>vectorizer = TfidfVectorizer(stop_words=u'english',ngram_range=(1,5),lowercase=True)
X = vectorizer.fit_transform(lectures)
</code></pre>

<p>Now If I print X, I am able to see all the entries in matrix, but how can I find top n entries based on tfidf score. In addition to that is there any method that will help me to find top n entries based on tfidf score per ngram i.e. top entries among unigram,bigram,trigram and so on?</p>
"
"Fastest SVM implementation usable in Python","<p>I'm building some predictive models in Python and have been using scikits learn's SVM implementation. It's been really great, easy to use, and relatively fast.</p>

<p>Unfortunately, I'm beginning to become constrained by my runtime. I run a rbf SVM on a full dataset of about 4 - 5000 with 650 features. Each run takes about a minute. But with a 5 fold cross validation + grid search (using a coarse to fine search), it's getting a bit unfeasible for my task at hand. So generally, do people have any recommendations in terms of the fastest SVM implementation that can be used in Python? That, or any ways to speed up my modeling?</p>

<p>I've heard of LIBSVM's GPU implementation, which seems like it could work. I don't know of any other GPU SVM implementations usable in Python, but it would definitely be open to others. Also, does using the GPU significantly increase runtime?</p>

<p>I've also heard that there are ways of approximating the rbf SVM by using a linear SVM + feature map in scikits. Not sure what people think about this approach. Again, anyone using this approach, is it a significant increase in runtime?</p>

<p>All ideas for increasing the speed of program is most welcome.</p>
"
"How to import csv data file into scikit-learn?","<p>From my understanding, the scikit-learn accepts data in (n-sample, n-feature) format which is a 2D array. Assuming I have data in the form ...</p>

<pre><code>Stock prices    indicator1    indicator2
2.0             123           1252
1.0             ..            ..
..              .             . 
.
</code></pre>

<p>How do I import this? </p>
"
"How to use the a k-fold cross validation in scikit with naive bayes classifier and NLTK","<p>I have a small corpus and I want to calculate the accuracy of naive Bayes classifier using 10-fold cross validation, how can do it.</p>
"
"scikit-learn DBSCAN memory usage","<p><strong>UPDATED:</strong> In the end, the solution I opted to use for clustering my large dataset was one suggested by Anony-Mousse below. That is, using ELKI's DBSCAN implimentation to do my clustering rather than scikit-learn's. It can be run from the command line and with proper indexing, performs this task within a few hours. Use the GUI and small sample datasets to work out the options you want to use and then go to town. Worth looking into. Anywho, read on for a description of my original problem and some interesting discussion.</p>

<p>I have a dataset with ~2.5 million samples, each with 35 features (floating point values) that I'm trying to cluster. I've been trying to do this with scikit-learn's implementation of DBSCAN, using the Manhattan distance metric and a value of epsilon estimated from some small random samples drawn from the data. So far, so good. (here is the snippet, for reference)</p>

<pre><code>db = DBSCAN(eps=40, min_samples=10, metric='cityblock').fit(mydata)
</code></pre>

<p>My issue at the moment is that I easily run out of memory. (I'm currently working on a machine with 16 GB of RAM)</p>

<p>My question is, is DBSCAN calculating the pairwise distance matrix on the fly as it runs, and that's what's gobbling up my memory? (2.5 million ^ 2) * 8 bytes is obviously stupidly large, I would understand that. Should I not be using the <code>fit()</code> method? And more generally, is there a way around this issue, or am I generally barking up the wrong tree here?</p>

<p>Apologies if the answer winds up being obvious. I've been puzzling over this for a few days. Thanks!</p>

<p>Addendum: Also if anyone could explain the difference between <code>fit(X)</code> and <code>fit_predict(X)</code> to me more explicitly I'd also appreciate that--I'm afraid I just don't quite get it.</p>

<p>Addendum #2: To be sure, I just tried this on a machine with ~550 GB of RAM and it still blew up, so I feel like DBSCAN is likely trying to make a pairwise distance matrix or something I clearly don't want it to do. I guess now the big question is how to stop that behavior, or find other methods that might suit my needs more. Thanks for bearing with me here. </p>

<p>Addendum #3(!): I forgot to attach the traceback, here it is,</p>

<pre><code>Traceback (most recent call last):
  File ""tDBSCAN.py"", line 34, in &lt;module&gt;
    db = DBSCAN(eps=float(sys.argv[2]), min_samples=10, metric='cityblock').fit(mydata)
  File ""/home/jtownsend/.local/lib/python2.6/site-packages/sklearn/base.py"", line 329, in fit_predict
    self.fit(X)
  File ""/home/jtownsend/.local/lib/python2.6/site-packages/sklearn/cluster/dbscan_.py"", line 186, in fit
    **self.get_params())
  File ""/home/jtownsend/.local/lib/python2.6/site-packages/sklearn/cluster/dbscan_.py"", line 69, in dbscan
    D = pairwise_distances(X, metric=metric)
  File ""/home/jtownsend/.local/lib/python2.6/site-packages/sklearn/metrics/pairwise.py"", line 651, in pairwise_distances
    return func(X, Y, **kwds)
  File ""/home/jtownsend/.local/lib/python2.6/site-packages/sklearn/metrics/pairwise.py"", line 237, in manhattan_distances
    D = np.abs(X[:, np.newaxis, :] - Y[np.newaxis, :, :])
MemoryError
</code></pre>
"
"ImportError: No module named model_selection","<p>I am trying to use <code>train_test_split</code> function and write:</p>

<pre><code>from sklearn.model_selection import train_test_split
</code></pre>

<p>and this causes </p>

<pre><code>ImportError: No module named model_selection
</code></pre>

<p>Why? And how to overcome?</p>
"
"How to convert a pandas DataFrame subset of columns AND rows into a numpy array?","<p>I'm wondering if there is a simpler, memory efficient way to select a subset of rows and columns from a pandas DataFrame.</p>

<p>For instance, given this dataframe:</p>

<pre>
df = DataFrame(np.random.rand(4,5), columns = list('abcde'))
print df

          a         b         c         d         e
0  0.945686  0.000710  0.909158  0.892892  0.326670
1  0.919359  0.667057  0.462478  0.008204  0.473096
2  0.976163  0.621712  0.208423  0.980471  0.048334
3  0.459039  0.788318  0.309892  0.100539  0.753992
</pre>

<p>I want only those rows in which the value for column 'c' is greater than 0.5, but I only need columns 'b' and 'e' for those rows.</p>

<p>This is the method that I've come up with - perhaps there is a better ""pandas"" way?</p>

<pre>
locs = [df.columns.get_loc(_) for _ in ['a', 'd']]
print df[df.c > 0.5][locs]

          a         d
0  0.945686  0.892892
</pre>

<p>My final goal is to convert the result to a numpy array to pass into an sklearn regression algorithm, so I will use the code above like this:</p>

<pre>
training_set = array(df[df.c > 0.5][locs])
</pre>

<p>... and that peeves me since I end up with a huge array copy in memory. Perhaps there's a better way for that too?</p>
"
"Can sklearn random forest directly handle categorical features?","<p>Say I have a categorical feature, color, which takes the values</p>

<p>['red', 'blue', 'green', 'orange'],</p>

<p>and I want to use it to predict something in a random forest.  If I one-hot encode it (i.e. I change it to four dummy variables), how do I tell sklearn that the four dummy variables are really one variable?  Specifically, when sklearn is randomly selecting features to use at different nodes, it should either include the red, blue, green and orange dummies together, or it shouldn't include any of them.</p>

<p>I've heard that there's no way to do this, but I'd imagine there must be a way to deal with categorical variables without arbitrarily coding them as numbers or something like that.</p>
"
"tf-idf feature weights using sklearn.feature_extraction.text.TfidfVectorizer","<p>this page: <a href=""http://scikit-learn.org/stable/modules/feature_extraction.html"">http://scikit-learn.org/stable/modules/feature_extraction.html</a> mentions:</p>

<blockquote>
  <p>As tf–idf is a very often used for text features, there is also another class called <strong>TfidfVectorizer</strong> that combines all the option of <strong>CountVectorizer</strong> and <strong>TfidfTransformer</strong> in a single model.</p>
</blockquote>

<p>then I followed the code and use fit_transform() on my corpus. How to get the weight of each feature computed by fit_transform()? </p>

<p>I tried: </p>

<pre><code>In [39]: vectorizer.idf_
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-39-5475eefe04c0&gt; in &lt;module&gt;()
----&gt; 1 vectorizer.idf_

AttributeError: 'TfidfVectorizer' object has no attribute 'idf_'
</code></pre>

<p>but this attribute is missing. </p>

<p>Thanks</p>
"
"Saving parts of a sklearn pipeline","<p>Some of my features in a model can take some time to generate, so to experiment with multiple features and parameters quickly it's a good idea to save these to disk for later use.</p>

<p>As a concrete example (taken from <a href=""http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html"" rel=""noreferrer"">here</a>), suppose I have the following pipeline:</p>

<pre><code>pipeline = Pipeline([
  ('extract_essays', EssayExractor()),
  ('features', FeatureUnion([
    ('ngram_tf_idf', Pipeline([
      ('counts', CountVectorizer()),
      ('tf_idf', TfidfTransformer())
    ])),
    ('essay_length', LengthTransformer()),
    ('misspellings', MispellingCountTransformer())
  ])),
  ('classifier', MultinomialNB())
])
</code></pre>

<p>And I would like to change <code>CountVectorizer()</code> to <code>CountVectorizer(max_features=1000)</code>, then only <code>CountVectorizer</code>, <code>MultinomialNB</code> need to be recomputed since the parameter or the transform before it has changed.</p>

<p>Can this be implemented somehow?</p>
"
"Obtain eigen values and vectors from sklearn PCA","<p>How I can get the the eigen values and eigen vectors of the PCA application? </p>

<pre><code>from sklearn.decomposition import PCA
clf=PCA(0.98,whiten=True)      #converse 98% variance
X_train=clf.fit_transform(X_train)
X_test=clf.transform(X_test)
</code></pre>

<p>I can't find it in <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.get_precision"" rel=""nofollow noreferrer"">docs</a>.</p>

<p>1.I am ""not"" able to comprehend the different results here.</p>

<p><strong>Edit</strong>:</p>

<pre><code>def pca_code(data):
    #raw_implementation
    var_per=.98
    data-=np.mean(data, axis=0)
    data/=np.std(data, axis=0)
    cov_mat=np.cov(data, rowvar=False)
    evals, evecs = np.linalg.eigh(cov_mat)
    idx = np.argsort(evals)[::-1]
    evecs = evecs[:,idx]
    evals = evals[idx]
    variance_retained=np.cumsum(evals)/np.sum(evals)
    index=np.argmax(variance_retained&gt;=var_per)
    evecs = evecs[:,:index+1]
    reduced_data=np.dot(evecs.T, data.T).T
    print(evals)
    print(""_""*30)
    print(evecs)
    print(""_""*30)
    #using scipy package
    clf=PCA(var_per)
    X_train=data.T
    X_train=clf.fit_transform(X_train)
    print(clf.explained_variance_)
    print(""_""*30)
    print(clf.components_)
    print(""__""*30)
</code></pre>

<ol start=""2"">
<li>I wish to obtain all the eigenvalues and eigenvectors instead of just the reduced set with the convergence condition.</li>
</ol>
"
"Recursive feature elimination and grid search using scikit-learn","<p>I would like to perform recursive feature elimination with nested grid search and cross-validation for each feature subset using scikit-learn. From the <strong>RFECV</strong> documentation it sounds like this type of operation is supported using the <code>estimator_params</code> parameter:</p>

<pre><code>estimator_params : dict

    Parameters for the external estimator. Useful for doing grid searches.
</code></pre>

<p>However, when I try to pass a grid of hyperparameters to the RFECV object </p>

<pre><code>from sklearn.datasets import make_friedman1
from sklearn.feature_selection import RFECV
from sklearn.svm import SVR
X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)
estimator = SVR(kernel=""linear"")
selector = RFECV(estimator, step=1, cv=5, estimator_params={'C': [0.1, 10, 100, 1000]})
selector = selector.fit(X, y)
</code></pre>

<p>I get an error like</p>

<pre><code>  File ""U:/My Documents/Code/ModelFeatures/bin/model_rcc_gene_features.py"", line 130, in &lt;module&gt;
    selector = selector.fit(X, y)
  File ""C:\Python27\lib\site-packages\sklearn\feature_selection\rfe.py"", line 336, in fit
    ranking_ = rfe.fit(X_train, y_train).ranking_
  File ""C:\Python27\lib\site-packages\sklearn\feature_selection\rfe.py"", line 146, in fit
    estimator.fit(X[:, features], y)
  File ""C:\Python27\lib\site-packages\sklearn\svm\base.py"", line 178, in fit
    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)
  File ""C:\Python27\lib\site-packages\sklearn\svm\base.py"", line 233, in _dense_fit
    max_iter=self.max_iter, random_seed=random_seed)
  File ""libsvm.pyx"", line 59, in sklearn.svm.libsvm.fit (sklearn\svm\libsvm.c:1628)
TypeError: a float is required
</code></pre>

<p>If anyone could show me what I'm doing wrong it would be greatly appreciated, thanks!</p>

<p><strong>EDIT:</strong></p>

<p>After Andreas' response things became clearer, below is a working example of RFECV combined with grid search.</p>

<pre><code>from sklearn.datasets import make_friedman1
from sklearn.feature_selection import RFECV
from sklearn.grid_search import GridSearchCV
from sklearn.svm import SVR
X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)
param_grid = [{'C': 0.01}, {'C': 0.1}, {'C': 1.0}, {'C': 10.0}, {'C': 100.0}, {'C': 1000.0}, {'C': 10000.0}]
estimator = SVR(kernel=""linear"")
selector = RFECV(estimator, step=1, cv=4)
clf = GridSearchCV(selector, {'estimator_params': param_grid}, cv=7)
clf.fit(X, y)
clf.best_estimator_.estimator_
clf.best_estimator_.grid_scores_
clf.best_estimator_.ranking_
</code></pre>
"
"what is the difference between 'transform' and 'fit_transform' in sklearn","<p>In the sklearn-python toolbox, there are two functions <code>transform</code> and <code>fit_transform</code> about <code>sklearn.decomposition.RandomizedPCA</code>. The description of two functions are as follows </p>

<p><img src=""https://i.stack.imgur.com/Oy8kD.png"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/JpZk6.png"" alt=""enter image description here""></p>

<p>But what is the difference between them ? </p>
"
"how to implement walk forward testing in sklearn?","<p>In sklearn, GridSearchCV can take a pipeline as a parameter to find the best estimator through cross validation. However, the usual cross validation is like this:<a href=""https://i.stack.imgur.com/1fXzJ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/1fXzJ.png"" alt=""enter image description here""></a></p>

<p>to cross validate a time series data, the training and testing data are often splitted like this:<a href=""https://i.stack.imgur.com/padg4.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/padg4.gif"" alt=""enter image description here""></a> </p>

<p>That is to say, the testing data should be always ahead of training data.</p>

<p>My thought is:</p>

<ol>
<li><p>Write my own version class of k-fold and passing it to GridSearchCV so I can enjoy the convenience of pipeline. The problem is that it seems difficult to let GridSearchCV to use an specified indices of training and testing data.</p></li>
<li><p>Write a new class GridSearchWalkForwardTest which is similar to GridSearchCV, I am studying the source code grid_search.py and find it is a little complicated.</p></li>
</ol>

<p>Any suggestion is welcome.</p>
"
"sklearn error ValueError: Input contains NaN, infinity or a value too large for dtype('float64')","<p>Im using sklearn and am having problems with the affinity propagation, I have built an input matrix, and i keep getting the following error. </p>

<pre><code>ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
</code></pre>

<p>I have run</p>

<pre><code>np.isnan(mat.any()) #and gets False
np.isfinite(mat.all()) #and gets True
</code></pre>

<p>I tried using</p>

<pre><code>mat[np.isfinite(mat) == True] = 0
</code></pre>

<p>to remove the infinite values but this did not work either. 
What can I do do to get rid of the infinite values in my matrix so I can use the affinity propagation algorithm?</p>

<p>I am using anaconda and python 2.7.9.</p>
"
"Scikit-learn: How to obtain True Positive, True Negative, False Positive and False Negative","<p>I am new in machine learning and in scikit-learn.</p>

<p><strong>My problem:</strong></p>

<p>(Please, correct any type of missconception)</p>

<p>I have a dataset which is a BIG JSON, I retrieve it and store it in a <code>trainList</code> variable.</p>

<p>I pre-process it in order to be able to work with it.</p>

<p>Once I have done that, I start the classification:</p>

<ol>
<li>I use kfold cross validation method in order to obtain the mean
accuracy and I train a classifier.</li>
<li>I make the predicctions and I obtain the accuracy and confusion matrix of that fold.</li>
<li>After this, I would like to obtain the True Positive(TP), True Negative(TN), False Positive(FP) and False Negative(FN) values. I would use these paramters to obtain the Sensitivity and the specificity and I would them and the total of the TPs to a HTML in order to show a chart with the TPs of each label.</li>
</ol>

<p><strong>Code:</strong></p>

<p>The variables I have for the moment:</p>

<pre><code>trainList #It is a list with all the data of my dataset in JSON form
labelList #It is a list with all the labels of my data 
</code></pre>

<p>Most part of the method:</p>

<pre><code>#I transform the data from JSON form to a numerical one
X=vec.fit_transform(trainList)

#I scale the matrix (don't know why but without it, it makes an error)
X=preprocessing.scale(X.toarray())

#I generate a KFold in order to make cross validation
kf = KFold(len(X), n_folds=10, indices=True, shuffle=True, random_state=1)

#I start the cross validation
for train_indices, test_indices in kf:
    X_train=[X[ii] for ii in train_indices]
    X_test=[X[ii] for ii in test_indices]
    y_train=[listaLabels[ii] for ii in train_indices]
    y_test=[listaLabels[ii] for ii in test_indices]

    #I train the classifier
    trained=qda.fit(X_train,y_train)

    #I make the predictions
    predicted=qda.predict(X_test)

    #I obtain the accuracy of this fold
    ac=accuracy_score(predicted,y_test)

    #I obtain the confusion matrix
    cm=confusion_matrix(y_test, predicted)

    #I should calculate the TP,TN, FP and FN 
    #I don't know how to continue
</code></pre>
"
"Error with Sklearn Random Forest Regressor","<p>When trying to fit a Random Forest Regressor model with y data that looks like this:</p>

<pre><code>[  0.00000000e+00   1.36094276e+02   4.46608221e+03   8.72660888e+03
   1.31375786e+04   1.73580193e+04   2.29420671e+04   3.12216341e+04
   4.11395711e+04   5.07972062e+04   6.14904935e+04   7.34275322e+04
   7.87333933e+04   8.46302456e+04   9.71074959e+04   1.07146672e+05
   1.17187952e+05   1.26953374e+05   1.37736003e+05   1.47239359e+05
   1.53943242e+05   1.78806710e+05   1.92657725e+05   2.08912711e+05
   2.22855152e+05   2.34532982e+05   2.41391255e+05   2.48699216e+05
   2.62421197e+05   2.79544300e+05   2.95550971e+05   3.13524275e+05
   3.23365158e+05   3.24069067e+05   3.24472999e+05   3.24804951e+05
</code></pre>

<p>And X data that looks like this:</p>

<pre><code>[ 735233.27082176  735234.27082176  735235.27082176  735236.27082176
  735237.27082176  735238.27082176  735239.27082176  735240.27082176
  735241.27082176  735242.27082176  735243.27082176  735244.27082176
  735245.27082176  735246.27082176  735247.27082176  735248.27082176
</code></pre>

<p>With the following code:</p>

<pre><code>regressor = RandomForestRegressor(n_estimators=150, min_samples_split=1)
rgr = regressor.fit(X,y) 
</code></pre>

<p>I get this error:</p>

<pre><code>ValueError: Number of labels=600 does not match number of samples=1
</code></pre>

<p>I assume one of my sets of values is in the wrong format but its not too clear to me from the documentation.</p>
"
"Using GridSearchCV with AdaBoost and DecisionTreeClassifier","<p>I am attempting to tune an AdaBoost Classifier (""ABT"") using a DecisionTreeClassifier (""DTC"") as the base_estimator.   I would like to tune <strong>both</strong> ABT and DTC parameters simultaneously, but am not sure how to accomplish this - pipeline shouldn't work, as I am not ""piping"" the output of DTC to ABT.     The idea would be to iterate hyper parameters for ABT and DTC in the GridSearchCV estimator. </p>

<p>How can I specify the tuning parameters correctly? </p>

<p>I tried the following, which generated an error below. </p>

<pre><code>[IN]
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.grid_search import GridSearchCV

param_grid = {dtc__criterion : [""gini"", ""entropy""],
              dtc__splitter :   [""best"", ""random""],
              abc__n_estimators: [none, 1, 2]
             }


DTC = DecisionTreeClassifier(random_state = 11, max_features = ""auto"", class_weight = ""auto"",max_depth = None)

ABC = AdaBoostClassifier(base_estimator = DTC)

# run grid search
grid_search_ABC = GridSearchCV(ABC, param_grid=param_grid, scoring = 'roc_auc')

[OUT]
ValueError: Invalid parameter dtc for estimator AdaBoostClassifier(algorithm='SAMME.R',
      base_estimator=DecisionTreeClassifier(class_weight='auto', criterion='gini', max_depth=None,
        max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,
        min_samples_split=2, min_weight_fraction_leaf=0.0,
        random_state=11, splitter='best'),
      learning_rate=1.0, n_estimators=50, random_state=11)
</code></pre>
"
"sklearn and large datasets","<p>I have a dataset of 22 GB. I would like to process it on my laptop. Of course I can't load it in memory. </p>

<p>I use a lot sklearn but for much smaller datasets. </p>

<p>In this situations the classical approach should be something like. </p>

<p>Read only part of the data -> Partial train your estimator -> delete the data -> read other part of the data -> continue to train your estimator.   </p>

<p>I have seen that some sklearn algorithm have the partial fit method that should allow us to train the estimator with various subsamples of the data.</p>

<p>Now I am wondering is there an easy why to do that in sklearn? 
I am looking for something like </p>

<pre><code>r = read_part_of_data('data.csv')
m = sk.my_model
`for i in range(n):
     x = r.read_next_chunk(20 lines)
     m.partial_fit(x)

m.predict(new_x)
</code></pre>

<p>Maybe sklearn is not the right tool for these kind of things?
Let me know.</p>
"
"Sklearn Pipeline - How to inherit get_params in custom Transformer (not Estimator)","<p>I have a pipeline in scikit-learn that uses a custom transformer I define like below:</p>

<pre><code>class MyPipelineTransformer(TransformerMixin):
</code></pre>

<p>which defines functions </p>

<pre><code>__init__, fit() and transform()
</code></pre>

<p>However, when I use the pipeline inside RandomizedSearchCV, I get the following error: </p>

<blockquote>
  <p>'MyPipelineTransformer' object has no attribute 'get_params'</p>
</blockquote>

<p>I've read online (e.g. links below) </p>

<p><a href=""https://stackoverflow.com/questions/27810855/python-sklearn-how-to-pass-parameters-to-the-customize-modeltransformer-clas"">(Python - sklearn) How to pass parameters to the customize ModelTransformer class by gridsearchcv</a></p>

<p><a href=""http://scikit-learn.org/stable/auto_examples/hetero_feature_union.html"" rel=""noreferrer"">http://scikit-learn.org/stable/auto_examples/hetero_feature_union.html</a></p>

<p>that I could get 'get_params' by inheriting from BaseEstimator, instead of my current code inheriting just from TransformerMixin. But my transformer is not an estimator. Is there any downside to having a non-estimator inherit from BaseEstimator? Or is that the recommended way to get get_params for any transformer (estimator or not) in a pipeline?</p>
"
"Scikit-learn cross val score: too many indices for array","<p>I have the following code</p>

<pre><code> from sklearn.ensemble import ExtraTreesClassifier
 from sklearn.cross_validation import cross_val_score
 #split the dataset for train and test
 combnum['is_train'] = np.random.uniform(0, 1, len(combnum)) &lt;= .75
 train, test = combnum[combnum['is_train']==True], combnum[combnum['is_train']==False]

 et = ExtraTreesClassifier(n_estimators=200, max_depth=None, min_samples_split=10, random_state=0)
 min_samples_split=10, random_state=0  )

 labels = train[list(label_columns)].values
 tlabels = test[list(label_columns)].values

 features = train[list(columns)].values
 tfeatures = test[list(columns)].values

 et_score = cross_val_score(et, features, labels, n_jobs=-1)
 print(""{0} -&gt; ET: {1})"".format(label_columns, et_score))
</code></pre>

<p>Checking the shape of the arrays:</p>

<pre><code> features.shape
 Out[19]:(43069, 34)
</code></pre>

<p>And</p>

<pre><code>labels.shape
Out[20]:(43069, 1)
</code></pre>

<p>and I'm getting:</p>

<pre><code>IndexError: too many indices for array
</code></pre>

<p>and this relevant part of the traceback:</p>

<pre><code>---&gt; 22 et_score = cross_val_score(et, features, labels, n_jobs=-1)
</code></pre>

<p>I'm creating the data from Pandas dataframes and I searched here and saw some reference to possible errors via this method but can't figure out how to correct?
What the data arrays look like:
features</p>

<pre><code>Out[21]:
array([[ 0.,  1.,  1., ...,  0.,  0.,  1.],
   [ 0.,  1.,  1., ...,  0.,  0.,  1.],
   [ 1.,  1.,  1., ...,  0.,  0.,  1.],
   ..., 
   [ 0.,  0.,  1., ...,  0.,  0.,  1.],
   [ 0.,  0.,  1., ...,  0.,  0.,  1.],
   [ 0.,  0.,  1., ...,  0.,  0.,  1.]])
</code></pre>

<p>labels</p>

<pre><code>Out[22]:
array([[1],
   [1],
   [1],
   ..., 
   [1],
   [1],
   [1]])
</code></pre>
"
"How to add another feature (length of text) to current bag of words classification? Scikit-learn","<p>I am using bag of words to classify text. It's working well but I am wondering how to add a feature which is not a word. </p>

<p>Here is my sample code.</p>

<pre><code>import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.multiclass import OneVsRestClassifier

X_train = np.array([""new york is a hell of a town"",
                    ""new york was originally dutch"",
                    ""new york is also called the big apple"",
                    ""nyc is nice"",
                    ""the capital of great britain is london. london is a huge metropolis which has a great many number of people living in it. london is also a very old town with a rich and vibrant cultural history."",
                    ""london is in the uk. they speak english there. london is a sprawling big city where it's super easy to get lost and i've got lost many times."",
                    ""london is in england, which is a part of great britain. some cool things to check out in london are the museum and buckingham palace."",
                    ""london is in great britain. it rains a lot in britain and london's fogs are a constant theme in books based in london, such as sherlock holmes. the weather is really bad there."",])
y_train = [[0],[0],[0],[0],[1],[1],[1],[1]]

X_test = np.array([""it's a nice day in nyc"",
                   'i loved the time i spent in london, the weather was great, though there was a nip in the air and i had to wear a jacket.'
                   ])   
target_names = ['Class 1', 'Class 2']

classifier = Pipeline([
    ('vectorizer', CountVectorizer(min_df=1,max_df=2)),
    ('tfidf', TfidfTransformer()),
    ('clf', OneVsRestClassifier(LinearSVC()))])
classifier.fit(X_train, y_train)
predicted = classifier.predict(X_test)
for item, labels in zip(X_test, predicted):
    print '%s =&gt; %s' % (item, ', '.join(target_names[x] for x in labels))
</code></pre>

<p>Now it is clear that the text about London tends to be much longer than the text about New York. How would I add length of the text as a feature? 
Do I have to use another way of classification and then combine the two predictions? Is there any way of doing it along with the bag of words? 
Some sample code would be great -- I'm very new to machine learning and scikit learn. </p>
"
"""No space left on device"" error while fitting Sklearn model","<p>I'm fitting a LDA model with lots of data using scikit-learn. Relevant code piece looks like this:</p>

<pre><code>lda = LatentDirichletAllocation(n_topics = n_topics, 
                                max_iter = iters,
                                learning_method = 'online',
                                learning_offset = offset,
                                random_state = 0,
                                evaluate_every = 5,
                                n_jobs = 3,
                                verbose = 0)
lda.fit(X)
</code></pre>

<p>(I guess the only possibly relevant detail here is that I'm using multiple jobs.)</p>

<p>After some time I'm getting ""No space left on device"" error, even though there is plenty of space on the disk and plenty of free memory. I tried the same code several times, on two different computers (on my local machine and on a remote server), first using python3, then using python2, and each time I ended up with the same error.</p>

<p>If I run the same code on a smaller sample of data everything works fine.</p>

<p>The entire stack trace:</p>

<pre><code>Failed to save &lt;type 'numpy.ndarray'&gt; to .npy file:
Traceback (most recent call last):
  File ""/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.py"", line 271, in save
    obj, filename = self._write_array(obj, filename)
  File ""/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.py"", line 231, in _write_array
    self.np.save(filename, array)
  File ""/home/ubuntu/anaconda2/lib/python2.7/site-packages/numpy/lib/npyio.py"", line 491, in save
    pickle_kwargs=pickle_kwargs)
  File ""/home/ubuntu/anaconda2/lib/python2.7/site-packages/numpy/lib/format.py"", line 584, in write_array
    array.tofile(fp)
IOError: 275500 requested and 210934 written


IOErrorTraceback (most recent call last)
&lt;ipython-input-7-6af7e7c9845f&gt; in &lt;module&gt;()
      7                                 n_jobs = 3,
      8                                 verbose = 0)
----&gt; 9 lda.fit(X)

/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.pyc in fit(self, X, y)
    509                     for idx_slice in gen_batches(n_samples, batch_size):
    510                         self._em_step(X[idx_slice, :], total_samples=n_samples,
--&gt; 511                                       batch_update=False, parallel=parallel)
    512                 else:
    513                     # batch update

/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.pyc in _em_step(self, X, total_samples, batch_update, parallel)
    403         # E-step
    404         _, suff_stats = self._e_step(X, cal_sstats=True, random_init=True,
--&gt; 405                                      parallel=parallel)
    406 
    407         # M-step

/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.pyc in _e_step(self, X, cal_sstats, random_init, parallel)
    356                                               self.mean_change_tol, cal_sstats,
    357                                               random_state)
--&gt; 358             for idx_slice in gen_even_slices(X.shape[0], n_jobs))
    359 
    360         # merge result

/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc in __call__(self, iterable)
    808                 # consumption.
    809                 self._iterating = False
--&gt; 810             self.retrieve()
    811             # Make sure that we get a last message telling us we are done
    812             elapsed_time = time.time() - self._start_time

/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc in retrieve(self)
    725                 job = self._jobs.pop(0)
    726             try:
--&gt; 727                 self._output.extend(job.get())
    728             except tuple(self.exceptions) as exception:
    729                 # Stop dispatching any new job in the async callback thread

/home/ubuntu/anaconda2/lib/python2.7/multiprocessing/pool.pyc in get(self, timeout)
    565             return self._value
    566         else:
--&gt; 567             raise self._value
    568 
    569     def _set(self, i, obj):

IOError: [Errno 28] No space left on device
</code></pre>
"
"TfidfVectorizer in scikit-learn : ValueError: np.nan is an invalid document","<p>I'm using TfidfVectorizer from scikit-learn to do some feature extraction from text data. I have a CSV file with a Score (can be +1 or -1) and a Review (text). I pulled this data into a DataFrame so I can run the Vectorizer.</p>

<p>This is my code: </p>

<pre><code>import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer

df = pd.read_csv(""train_new.csv"",
             names = ['Score', 'Review'], sep=',')

# x = df['Review'] == np.nan
#
# print x.to_csv(path='FindNaN.csv', sep=',', na_rep = 'string', index=True)
#
# print df.isnull().values.any()

v = TfidfVectorizer(decode_error='replace', encoding='utf-8')
x = v.fit_transform(df['Review'])
</code></pre>

<p>This is the traceback for the error I get: </p>

<pre><code>Traceback (most recent call last):
  File ""/home/PycharmProjects/Review/src/feature_extraction.py"", line 16, in &lt;module&gt;
x = v.fit_transform(df['Review'])
 File ""/home/b/hw1/local/lib/python2.7/site-   packages/sklearn/feature_extraction/text.py"", line 1305, in fit_transform
   X = super(TfidfVectorizer, self).fit_transform(raw_documents)
 File ""/home/b/work/local/lib/python2.7/site-packages/sklearn/feature_extraction/text.py"", line 817, in fit_transform
self.fixed_vocabulary_)
 File ""/home/b/work/local/lib/python2.7/site- packages/sklearn/feature_extraction/text.py"", line 752, in _count_vocab
   for feature in analyze(doc):
 File ""/home/b/work/local/lib/python2.7/site-packages/sklearn/feature_extraction/text.py"", line 238, in &lt;lambda&gt;
tokenize(preprocess(self.decode(doc))), stop_words)
 File ""/home/b/work/local/lib/python2.7/site-packages/sklearn/feature_extraction/text.py"", line 118, in decode
 raise ValueError(""np.nan is an invalid document, expected byte or ""
 ValueError: np.nan is an invalid document, expected byte or unicode string.
</code></pre>

<p>I checked the CSV file and DataFrame for anything that's being read as NaN but I can't find anything. There are 18000 rows, none of which return <code>isnan</code> as True. </p>

<p>This is what <code>df['Review'].head()</code> looks like: </p>

<pre><code>  0    This book is such a life saver.  It has been s...
  1    I bought this a few times for my older son and...
  2    This is great for basics, but I wish the space...
  3    This book is perfect!  I'm a first time new mo...
  4    During your postpartum stay at the hospital th...
  Name: Review, dtype: object
</code></pre>
"
"Scikit-Learn's Pipeline: A sparse matrix was passed, but dense data is required","<p>I'm finding it difficult to understand how to fix a Pipeline I created (read: largely pasted from a tutorial). It's python 3.4.2:</p>

<pre><code>df = pd.DataFrame
df = DataFrame.from_records(train)

test = [blah1, blah2, blah3]

pipeline = Pipeline([('vectorizer', CountVectorizer()), ('classifier', RandomForestClassifier())])

pipeline.fit(numpy.asarray(df[0]), numpy.asarray(df[1]))
predicted = pipeline.predict(test)
</code></pre>

<p>When I run it, I get:</p>

<pre><code>TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.
</code></pre>

<p>This is for the line <code>pipeline.fit(numpy.asarray(df[0]), numpy.asarray(df[1]))</code>.</p>

<p>I've experimented a lot with solutions through numpy, scipy, and so forth, but I still don't know how to fix it. And yes, similar questions have come up before, but not inside a pipeline.
Where is it that I have to apply <code>toarray</code> or <code>todense</code>?</p>
"
"TypeError: cannot perform reduce with flexible type","<p>I have been using the scikit-learn library. I'm trying to use the Gaussian Naive Bayes Module under the scikit-learn library but I'm running into the following error. TypeError: cannot perform reduce with flexible type</p>

<p>Below is the code snippet. </p>

<pre><code>training = GaussianNB()
training = training.fit(trainData, target)
prediction = training.predict(testData)
</code></pre>

<p>This is target</p>

<pre><code>['ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'ALL', 'AML', 'AML', 'AML', 'AML', 'AML', 'AML', 'AML', 'AML', 'AML', 'AML', 'AML']
</code></pre>

<p>This is trainData</p>

<pre><code>[['-214' '-153' '-58' ..., '36' '191' '-37']
['-139' '-73' '-1' ..., '11' '76' '-14']
['-76' '-49' '-307' ..., '41' '228' '-41']
..., 
['-32' '-49' '49' ..., '-26' '133' '-32']
['-124' '-79' '-37' ..., '39' '298' '-3']
['-135' '-186' '-70' ..., '-12' '790' '-10']]
</code></pre>

<p>Below is the stack trace</p>

<pre><code>Traceback (most recent call last):
File ""prediction.py"", line 90, in &lt;module&gt;
  gaussianNaiveBayes()
File ""prediction.py"", line 76, in gaussianNaiveBayes
  training = training.fit(trainData, target)
File ""/Library/Python/2.7/site-packages/sklearn/naive_bayes.py"", line 163, in fit
  self.theta_[i, :] = np.mean(Xi, axis=0)
File ""/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/ core/fromnumeric.py"", line 2716, in mean
  out=out, keepdims=keepdims)
File ""/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/core/_methods.py"", line 62, in _mean
  ret = um.add.reduce(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims)
TypeError: cannot perform reduce with flexible type
</code></pre>
"
"How would one use Kernel Density Estimation as a 1D clustering method in scikit learn?","<p>I need to cluster a simple univariate data set into a preset number of clusters. Technically it would closer to binning or sorting the data since it is only 1D, but my boss is calling it clustering, so I'm going to stick to that name. 
The current method used by the system I'm on is K-means, but that seems like overkill.</p>

<p>Is there a better way of performing this task?</p>

<p>Answers to some other posts are mentioning KDE (Kernel Density Estimation), but that is a density estimation method, how would that work? </p>

<p>I see how KDE returns a density, but how do I tell it to split the data into bins? </p>

<p>How do I have a fixed number of bins independent of the data (that's one of my requirements) ? </p>

<p>More specifically, how would one pull this off using scikit learn? </p>

<p>My input file looks like: </p>

<pre><code> str ID     sls
 1           10
 2           11 
 3            9
 4           23
 5           21
 6           11  
 7           45
 8           20
 9           11
 10          12
</code></pre>

<p>I want to group the sls number into clusters or bins, such that:</p>

<pre><code>Cluster 1: [10 11 9 11 11 12] 
Cluster 2: [23 21 20] 
Cluster 3: [45] 
</code></pre>

<p>And my output file will look like: </p>

<pre><code> str ID     sls    Cluster ID  Cluster centroid
    1        10       1               10.66
    2        11       1               10.66
    3         9       1               10.66 
    4        23       2               21.33   
    5        21       2               21.33
    6        11       1               10.66
    7        45       3               45
    8        20       2               21.33
    9        11       1               10.66 
    10       12       1               10.66
</code></pre>
"
"How to encode a categorical variable in sklearn?","<p>I'm trying to use the car evaluation dataset from the UCI repository and I wonder whether there is a convenient way to binarize categorical variables in sklearn. One approach would be to use the DictVectorizer of LabelBinarizer but here I'm getting k different features whereas you should have just k-1 in order to avoid collinearization. 
    I guess I could write my own function and drop one column but this bookkeeping is tedious, is there an easy way to perform such transformations and get as a result a sparse matrix? </p>
"
"Imbalance in scikit-learn","<p>I'm using scikit-learn in my Python program in order to perform some machine-learning operations. The problem is that my data-set has severe imbalance issues.</p>

<p>Is anyone familiar with a solution for imbalance in scikit-learn or in python in general? In Java there's the SMOTE mechanizm. Is there something parallel in python?</p>
"
"How to retain column headers of data frame after Pre-processing in scikit-learn","<p>I have a pandas data frame which has some rows and columns. Each column has a header. Now as long as I keep doing data manipulation operations in pandas, my variable headers are retained. But if I try some data pre-processing feature of Sci-kit-learn lib, I end up losing all my headers and the frame gets converted to just a matrix of numbers. </p>

<p>I understand why it happens because scikit-learn gives a numpy ndarray as output. And numpy ndarray being just matrix would not have column names. </p>

<p>But here is the thing. If I am building some model on my dataset, even after initial data pre-processing and trying some model, I might have to do some more data manipulation tasks to run some other model for better fit. Without being able to access column header makes it difficult to do data manipulation as I might not know what is the index of a particular variable, but it's easier to remember variable name or even look up by doing df.columns. </p>

<p>How to overcome that? </p>

<p>EDIT1: Editing with sample data snapshot. </p>

<pre><code>    Pclass  Sex Age SibSp   Parch   Fare    Embarked
0   3   0   22  1   0   7.2500  1
1   1   1   38  1   0   71.2833 2
2   3   1   26  0   0   7.9250  1
3   1   1   35  1   0   53.1000 1
4   3   0   35  0   0   8.0500  1
5   3   0   NaN 0   0   8.4583  3
6   1   0   54  0   0   51.8625 1
7   3   0   2   3   1   21.0750 1
8   3   1   27  0   2   11.1333 1
9   2   1   14  1   0   30.0708 2
10  3   1   4   1   1   16.7000 1
11  1   1   58  0   0   26.5500 1
12  3   0   20  0   0   8.0500  1
13  3   0   39  1   5   31.2750 1
14  3   1   14  0   0   7.8542  1
15  2   1   55  0   0   16.0000 1
</code></pre>

<p>The above is basically the pandas data frame. Now when I do this on this data frame it will strip the column headers. </p>

<pre><code>from sklearn import preprocessing 
X_imputed=preprocessing.Imputer().fit_transform(X_train) 
X_imputed
</code></pre>

<p>New data is of numpy array and hence the column names are stripped. </p>

<pre><code>array([[  3.        ,   0.        ,  22.        , ...,   0.        ,
          7.25      ,   1.        ],
       [  1.        ,   1.        ,  38.        , ...,   0.        ,
         71.2833    ,   2.        ],
       [  3.        ,   1.        ,  26.        , ...,   0.        ,
          7.925     ,   1.        ],
       ..., 
       [  3.        ,   1.        ,  29.69911765, ...,   2.        ,
         23.45      ,   1.        ],
       [  1.        ,   0.        ,  26.        , ...,   0.        ,
         30.        ,   2.        ],
       [  3.        ,   0.        ,  32.        , ...,   0.        ,
          7.75      ,   3.        ]])
</code></pre>

<p>So I want to retain the column names when I do some data manipulation on my pandas data frame. </p>
"
"import check_arrays from sklearn","<p>I'm trying to use a svm function from the scikit learn package for python but I get the error message:</p>

<pre><code>from sklearn.utils.validation import check_arrays
</code></pre>

<blockquote>
  <p>ImportError: cannot import name 'check_arrays'</p>
</blockquote>

<p>I'm using python 3.4. Can anyone give me an advice? Thanks in advance.</p>
"
"How to convert a Scikit-learn dataset to a Pandas dataset?","<p>How do I convert data from a Scikit-learn Bunch object to a Pandas DataFrame?</p>

<pre><code>from sklearn.datasets import load_iris
import pandas as pd
data = load_iris()
print(type(data))
data1 = pd. # Is there a Pandas method to accomplish this?
</code></pre>
"
"Passing categorical data to Sklearn Decision Tree","<p>There are several posts about how to encode categorical data to Sklearn Decission trees, but from Sklearn documentation, we got these </p>

<blockquote>
  <p>Some advantages of decision trees are:</p>
  
  <p>(...)</p>
  
  <p>Able to handle both numerical and categorical data. Other techniques are usually specialised in analysing datasets that have only one type of variable. See algorithms for more information.</p>
</blockquote>

<p>But running the following script
</p>

<pre><code>import pandas as pd
from sklearn.tree import DecisionTreeClassifier

data = pd.DataFrame()
data['A'] = ['a','a','b','a']
data['B'] = ['b','b','a','b']
data['C'] = [0, 0, 1, 0]
data['Class'] = ['n','n','y','n']

tree = DecisionTreeClassifier()
tree.fit(data[['A','B','C']], data['Class'])
</code></pre>

<p>outputs the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/usr/local/lib/python2.7/site-packages/sklearn/tree/tree.py"", line 154, in fit
    X = check_array(X, dtype=DTYPE, accept_sparse=""csc"")
  File ""/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py"", line 377, in check_array
    array = np.array(array, dtype=dtype, order=order, copy=copy)
ValueError: could not convert string to float: b
</code></pre>

<p>I know that in R it is possible to pass categorical data, with Sklearn, is it possible?</p>
"
"Training different scikit-learn classifiers on multiple CPUs for each iteration","<p>I have a script that randomly generates a set of data and trains several classifiers to compare them against each other (it's very similar to <a href=""http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"" rel=""noreferrer"">http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html</a>):</p>

<pre><code>from itertools import product

import numpy as np

from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB, MultinomialNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis

from sklearn.datasets import make_classification
from sklearn.preprocessing import StandardScaler
from sklearn.cross_validation import train_test_split

names = [""Linear SVM"", ""Decision Tree"",
     ""Random Forest"", ""AdaBoost"", ""Naive Bayes"", ""Linear Discriminant Analysis"",
     ""Quadratic Discriminant Analysis""]

def griddy_mcsearchface(num_samples, num_feats, num_feats_to_remove): 
    classifiers = [
        SVC(kernel=""linear"", C=0.025),
        DecisionTreeClassifier(max_depth=5),
        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
        AdaBoostClassifier(), GaussianNB(),
        LinearDiscriminantAnalysis(),
        QuadraticDiscriminantAnalysis()]

    classifiers2 = [
        SVC(kernel=""linear"", C=0.025),
        DecisionTreeClassifier(max_depth=5),
        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
        AdaBoostClassifier(), GaussianNB(),
        LinearDiscriminantAnalysis(),
        QuadraticDiscriminantAnalysis()]

    X, y = make_classification(n_samples=num_samples, n_features=num_feats, n_redundant=0, n_informative=2,
                           random_state=1, n_clusters_per_class=1)
    X = StandardScaler().fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)

    for name, clf, clf2 in zip(names, classifiers, classifiers2):
        clf.fit(X_train, y_train)
        score = clf.score(X_test, y_test)
        # Remove 40% of the features.
        clf2.fit(X_train[:,:-num_feats_to_remove], y_train)
        score2 = clf2.score(X_test[:,:-num_feats_to_remove], y_test)
        yield (num_samples, num_feats, num_feats_to_remove, name, score, score2)
</code></pre>

<p>And to run it:</p>

<pre><code>_samples = [100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000]
_feats = [10, 20, 50, 100, 200, 500, 10000]
_feats_to_rm = [5, 10, 25, 50, 100, 250]
for num_samples, num_feats, num_feats_to_remove in product(_samples, _feats, _feats_to_rm):
    if num_feats &lt;= num_feats_to_remove:
        continue
    for i in griddy_mcsearchface(num_samples, num_feats, num_feats_to_remove):
        print (i)
</code></pre>

<p>The script outputs something like:</p>

<pre><code>(100, 10, 5, 'Linear SVM', 1.0, 0.40000000000000002)
(100, 10, 5, 'Decision Tree', 1.0, 0.65000000000000002)
(100, 10, 5, 'Random Forest', 1.0, 0.90000000000000002)
(100, 10, 5, 'AdaBoost', 1.0, 0.65000000000000002)
(100, 10, 5, 'Naive Bayes', 1.0, 0.75)
(100, 10, 5, 'Linear Discriminant Analysis', 1.0, 0.40000000000000002)
(100, 10, 5, 'Quadratic Discriminant Analysis', 1.0, 0.84999999999999998)
(100, 20, 5, 'Linear SVM', 1.0, 1.0)
(100, 20, 5, 'Decision Tree', 0.94999999999999996, 0.94999999999999996)
(100, 20, 5, 'Random Forest', 0.80000000000000004, 0.75)
(100, 20, 5, 'AdaBoost', 1.0, 0.94999999999999996)
(100, 20, 5, 'Naive Bayes', 1.0, 1.0)
(100, 20, 5, 'Linear Discriminant Analysis', 1.0, 1.0)
(100, 20, 5, 'Quadratic Discriminant Analysis', 0.84999999999999998, 0.94999999999999996)
(100, 20, 10, 'Linear SVM', 0.94999999999999996, 0.65000000000000002)
(100, 20, 10, 'Decision Tree', 0.94999999999999996, 0.59999999999999998)
(100, 20, 10, 'Random Forest', 0.75, 0.69999999999999996)
(100, 20, 10, 'AdaBoost', 0.94999999999999996, 0.69999999999999996)
(100, 20, 10, 'Naive Bayes', 0.94999999999999996, 0.75)
</code></pre>

<p>but the <code>clf.fit()</code> is now single-threaded. </p>

<p>Assuming that I have enough threads to run all classifiers for each iteration,  <strong>How would I be able to train the classifiers using different threads for every iteration of <code>for num_samples, num_feats, num_feats_to_remove in product(_samples, _feats, _feats_to_rm)</code>?</strong></p>

<p><strong>And if I am restricted to 4 or 8 threads but I need to train >4 or >8 classifiers for each iteration, how is it done?</strong></p>
"
"Combining bag of words and other features in one model using sklearn and pandas","<p>I am trying to model the score that a post receives, based on both the text of the post, and other features (time of day, length of post, etc.)</p>

<p>I am wondering how to best combine these different types of features into one model. Right now, I have something like the following (stolen from <a href=""https://stackoverflow.com/questions/22687365/concatenate-custom-features-with-countvectorizer"">here</a> and <a href=""https://stackoverflow.com/questions/27993058/pandas-apply-to-dateframe-produces-built-in-method-values-of"">here</a>). </p>

<pre><code>import pandas as pd
...

def features(p):
    terms = vectorizer(p[0])
    d = {'feature_1': p[1], 'feature_2': p[2]}
    for t in terms:
        d[t] = d.get(t, 0) + 1
    return d

posts = pd.read_csv('path/to/csv')

# Create vectorizer for function to use
vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2)).build_tokenizer()
y = posts[""score""].values.astype(np.float32) 
vect = DictVectorizer()

# This is the part I want to fix
temp = zip(list(posts.message), list(posts.feature_1), list(posts.feature_2))
tokenized = map(lambda x: features(x), temp)
X = vect.fit_transform(tokenized)
</code></pre>

<p>It seems very silly to extract all of the features I want out of the pandas dataframe, just to zip them all back together. Is there a better way of doing this step?</p>

<p>The CSV looks something like the following:</p>

<pre><code>ID,message,feature_1,feature_2
1,'This is the text',4,7
2,'This is more text',3,2
...
</code></pre>
"
"OLS Regression: Scikit vs. Statsmodels?","<p><em>Short version</em>: I was using the scikit LinearRegression on some data, but I'm used to p-values so put the data into the statsmodels OLS, and although the R^2 is about the same the variable coefficients are all different by large amounts. This concerns me since the most likely problem is that I've made an error somewhere and now I don't feel confident in either output (since likely I have made one model incorrectly but don't know which one).</p>

<p><em>Longer version</em>: Because I don't know where the issue is, I don't know exactly which details to include, and including everything is probably too much. I am also not sure about including code or data. </p>

<p>I am under the impression that scikit's LR and statsmodels OLS should both be doing OLS, and as far as I know OLS is OLS so the results should be the same.</p>

<p>For scikit's LR, the results are (statistically) the same whether or not I set normalize=True or =False, which I find somewhat strange.</p>

<p>For statsmodels OLS, I normalize the data using StandardScaler from sklearn. I add a column of ones so it includes an intercept (since scikit's output includes an intercept). More on that here: <a href=""http://statsmodels.sourceforge.net/devel/examples/generated/example_ols.html"" rel=""nofollow noreferrer"">http://statsmodels.sourceforge.net/devel/examples/generated/example_ols.html</a> (Adding this column did not change the variable coefficients to any notable degree and the intercept was very close to zero.) StandardScaler didn't like that my ints weren't floats, so I tried this: <a href=""https://github.com/scikit-learn/scikit-learn/issues/1709"" rel=""nofollow noreferrer"">https://github.com/scikit-learn/scikit-learn/issues/1709</a>
That makes the warning go away but the results are exactly the same.</p>

<p>Granted I'm using 5-folds cv for the sklearn approach (R^2 are consistent for both test and training data each time), and for statsmodels I just throw it all the data.</p>

<p>R^2 is about 0.41 for both sklearn and statsmodels (this is good for social science). This could be a good sign or just a coincidence.</p>

<p>The data is observations of avatars in WoW (from <a href=""http://mmnet.iis.sinica.edu.tw/dl/wowah/"" rel=""nofollow noreferrer"">http://mmnet.iis.sinica.edu.tw/dl/wowah/</a>) which I munged about to make it weekly with some different features. Originally this was a class project for a data science class.</p>

<p>Independent variables include number of observations in a week (int), character level (int), if in a guild (Boolean), when seen (Booleans on weekday day, weekday eve, weekday late, and the same three for weekend), a dummy for character class (at the time for the data collection, there were only 8 classes in WoW, so there are 7 dummy vars and the original string categorical variable is dropped), and others.</p>

<p>The dependent variable is how many levels each character gained during that week (int).</p>

<p>Interestingly, some of the relative order within like variables is maintained across statsmodels and sklearn. So, rank order of ""when seen"" is the same although the loadings are very different, and rank order for the character class dummies is the same although again the loadings are very different.</p>

<p>I think this question is similar to this one: <a href=""https://stackoverflow.com/questions/11495051/difference-in-python-statsmodels-ols-and-rs-lm"">Difference in Python statsmodels OLS and R&#39;s lm</a></p>

<p>I am good enough at Python and stats to make a go of it, but then not good enough to figure something like this out. I tried reading the sklearn docs and the statsmodels docs, but if the answer was there staring me in the face I did not understand it. </p>

<p>I would love to know:</p>

<ol>
<li>Which output might be accurate? (Granted they might both be if I missed a kwarg.)</li>
<li>If I made a mistake, what is it and how to fix it?</li>
<li>Could I have figured this out without asking here, and if so how?</li>
</ol>

<p>I know this question has some rather vague bits (no code, no data, no output), but I am thinking it is more about the general processes of the two packages. Sure, one seems to be more stats and one seems to be more machine learning, but they're both OLS so I don't understand why the outputs aren't the same.</p>

<p>(I even tried some other OLS calls to triangulate, one gave a much lower R^2, one looped for five minutes and I killed it, and one crashed.)</p>

<p>Thanks!</p>
"
"graph.write_pdf(""iris.pdf"") AttributeError: 'list' object has no attribute 'write_pdf'","<p>My code is follow the class of machine learning of google.The two code are same.I don't know why it show error.May be the type of variable is error.But google's code is same to me.Who has ever had this problem?</p>

<p>This is error</p>

<pre><code>[0 1 2]
[0 1 2]
Traceback (most recent call last):
  File ""/media/joyce/oreo/python/machine_learn/VisualizingADecisionTree.py"", line 34, in &lt;module&gt;
    graph.write_pdf(""iris.pdf"")
AttributeError: 'list' object has no attribute 'write_pdf'
[Finished in 0.4s with exit code 1]
[shell_cmd: python -u ""/media/joyce/oreo/python/machine_learn/VisualizingADecisionTree.py""]
[dir: /media/joyce/oreo/python/machine_learn]
[path: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games]
</code></pre>

<p>This is code</p>

<pre><code>import numpy as np
from sklearn.datasets import load_iris
from sklearn import tree

iris = load_iris()
test_idx = [0, 50, 100]

# training data
train_target = np.delete(iris.target, test_idx)
train_data = np.delete(iris.data, test_idx, axis=0)

# testing data
test_target = iris.target[test_idx]
test_data = iris.data[test_idx]

clf = tree.DecisionTreeClassifier()
clf.fit(train_data, train_target)

print test_target
print clf.predict(test_data) 

# viz code
from sklearn.externals.six import StringIO
import pydot
dot_data = StringIO()
tree.export_graphviz(clf,
        out_file=dot_data,
        feature_names=iris.feature_names,
        class_names=iris.target_names,
        filled=True, rounded=True,
        impurity=False)

graph = pydot.graph_from_dot_data(dot_data.getvalue())
graph.write_pdf(""iris.pdf"")
</code></pre>
"
"Understanding max_features parameter in RandomForestRegressor","<p>While constructing each tree in the random forest using bootstrapped samples, for each terminal node, we select m variables at random from p variables to find the best split (p is the total number of features in your data). My questions (for RandomForestRegressor) are:</p>

<p>1) What does max_features correspond to (m or p or something else)?</p>

<p>2) Are m variables selected at random from max_features variables (what is the value of m)?</p>

<p>3) If max_features corresponds to m, then why would I want to set it equal to p for regression (the default)? Where is the randomness with this setting (i.e., how is it different from bagging)?</p>

<p>Thanks.</p>
"
"Clustering cosine similarity matrix","<p>A few questions on stackoverflow mention this problem, but I haven't found a concrete solution.</p>

<p>I have a square matrix which consists of cosine similarities (values between 0 and 1), for example:</p>

<pre><code>  |  A  |  B  |  C  |  D
A | 1.0 | 0.1 | 0.6 |  0.4
B | 0.1 | 1.0 | 0.1 |  0.2
C | 0.6 | 0.1 | 1.0 |  0.7
D | 0.4 | 0.2 | 0.7 |  1.0
</code></pre>

<p>The square matrix can be of any size. I want to get clusters (I don't know how many) which maximize the values between the elements in the cluster. I.e. for the above example I should get two clusters:</p>

<ol>
<li>B</li>
<li>A, C, D</li>
</ol>

<p>The reason being because C &amp; D have the highest value between them, and A &amp; C also have the highest value between them.</p>

<p>An item can be in only one cluster.</p>

<p>Recall is not that important for this problem, but precision is very important. It is acceptable to output three clusters: 1) B, 2) A, 3) C, D . But it is not acceptable to output any solution where B is in a cluster with another element.</p>

<p>I think the diagonal (1.0) is confusing me. My data is guaranteed to have at least one cluster of 2+ elements, and I want to find as many clusters as possible without sacrificing precision.</p>

<p>I will have to implement this in Python.</p>
"
"How to reverse sklearn.OneHotEncoder transform to recover original data?","<p>Excuse my lack of knowledge. I have only been dallying with Python for less than a month. I encoded my categorical data using <code>sklearn.OneHotEncoder</code> and fed them to a random forest classifier. Everything seems to work and I got my predicted output back. Is there a way to reverse the encoding and convert my output back to its original state?</p>
"
"How to compute precision, recall, accuracy and f1-score for the multiclass case with scikit learn?","<p>I'm working in a sentiment analysis problem the data looks like this:</p>

<pre><code>label instances
    5    1190
    4     838
    3     239
    1     204
    2     127
</code></pre>

<p>So my data is unbalanced since 1190 <code>instances</code> are labeled with <code>5</code>. For the classification Im using scikit's <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"" rel=""noreferrer"">SVC</a>. The problem is I do not know how to balance my data in the right way in order to compute accurately the precision, recall, accuracy and f1-score for the multiclass case. So I tried the following approaches:</p>

<p>First:</p>

<pre><code>    wclf = SVC(kernel='linear', C= 1, class_weight={1: 10})
    wclf.fit(X, y)
    weighted_prediction = wclf.predict(X_test)

print 'Accuracy:', accuracy_score(y_test, weighted_prediction)
print 'F1 score:', f1_score(y_test, weighted_prediction,average='weighted')
print 'Recall:', recall_score(y_test, weighted_prediction,
                              average='weighted')
print 'Precision:', precision_score(y_test, weighted_prediction,
                                    average='weighted')
print '\n clasification report:\n', classification_report(y_test, weighted_prediction)
print '\n confussion matrix:\n',confusion_matrix(y_test, weighted_prediction)
</code></pre>

<p>Second:</p>

<pre><code>auto_wclf = SVC(kernel='linear', C= 1, class_weight='auto')
auto_wclf.fit(X, y)
auto_weighted_prediction = auto_wclf.predict(X_test)

print 'Accuracy:', accuracy_score(y_test, auto_weighted_prediction)

print 'F1 score:', f1_score(y_test, auto_weighted_prediction,
                            average='weighted')

print 'Recall:', recall_score(y_test, auto_weighted_prediction,
                              average='weighted')

print 'Precision:', precision_score(y_test, auto_weighted_prediction,
                                    average='weighted')

print '\n clasification report:\n', classification_report(y_test,auto_weighted_prediction)

print '\n confussion matrix:\n',confusion_matrix(y_test, auto_weighted_prediction)
</code></pre>

<p>Third:</p>

<pre><code>clf = SVC(kernel='linear', C= 1)
clf.fit(X, y)
prediction = clf.predict(X_test)


from sklearn.metrics import precision_score, \
    recall_score, confusion_matrix, classification_report, \
    accuracy_score, f1_score

print 'Accuracy:', accuracy_score(y_test, prediction)
print 'F1 score:', f1_score(y_test, prediction)
print 'Recall:', recall_score(y_test, prediction)
print 'Precision:', precision_score(y_test, prediction)
print '\n clasification report:\n', classification_report(y_test,prediction)
print '\n confussion matrix:\n',confusion_matrix(y_test, prediction)


F1 score:/usr/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=""f1_weighted"" instead of scoring=""f1"".
  sample_weight=sample_weight)
/usr/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1172: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=""f1_weighted"" instead of scoring=""f1"".
  sample_weight=sample_weight)
/usr/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1082: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=""f1_weighted"" instead of scoring=""f1"".
  sample_weight=sample_weight)
 0.930416613529
</code></pre>

<p>However, Im getting warnings like this:</p>

<pre><code>/usr/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1172:
DeprecationWarning: The default `weighted` averaging is deprecated,
and from version 0.18, use of precision, recall or F-score with 
multiclass or multilabel data or pos_label=None will result in an 
exception. Please set an explicit value for `average`, one of (None, 
'micro', 'macro', 'weighted', 'samples'). In cross validation use, for 
instance, scoring=""f1_weighted"" instead of scoring=""f1""
</code></pre>

<p>How can I deal correctly with my unbalanced data in order to compute in the right way classifier's metrics?</p>
"
"How to get Best Estimator on GridSearchCV (Random Forest Classifier Scikit)","<p>I'm running GridSearch CV to optimize the parameters of a classifier in scikit. Once I'm done, I'd like to know which parameters were chosen as the best.</p>

<p>Whenever I do so I get a <code>AttributeError: 'RandomForestClassifier' object has no attribute 'best_estimator_'</code>, and can't tell why, as it seems to be a legitimate attribute on the <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html"">documentation</a>. </p>

<pre><code>from sklearn.grid_search import GridSearchCV

X = data[usable_columns]
y = data[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) 

param_grid = {
    'n_estimators': [200, 700],
    'max_features': ['auto', 'sqrt', 'log2']
}

CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)

print '\n',CV_rfc.best_estimator_
</code></pre>

<p>Yields: </p>

<pre><code>`AttributeError: 'GridSearchCV' object has no attribute 'best_estimator_'
</code></pre>
"
"Why am I not seeing speed up via multiprocessing in Python?","<p>I am trying to parallelize an embarrassingly parallel for loop (<a href=""https://stackoverflow.com/questions/46391191/embarrassingly-parallel-for-loop-with-complex-outputs-in-each-iteration"">previously asked here</a>) and settled on <a href=""https://github.com/raamana/neuropredict/blob/master/neuropredict/rhst.py#L764"" rel=""nofollow noreferrer"">this implementation</a> that fit my parameters:</p>

<pre class=""lang-py prettyprint-override""><code>    with Manager() as proxy_manager:
        shared_inputs = proxy_manager.list([datasets, train_size_common, feat_sel_size, train_perc,
                                            total_test_samples, num_classes, num_features, label_set,
                                            method_names, pos_class_index, out_results_dir, exhaustive_search])
        partial_func_holdout = partial(holdout_trial_compare_datasets, *shared_inputs)

        with Pool(processes=num_procs) as pool:
            cv_results = pool.map(partial_func_holdout, range(num_repetitions))
</code></pre>

<p>The reason I need to use a <a href=""https://docs.python.org/3/library/multiprocessing.html#proxy-objects"" rel=""nofollow noreferrer"">proxy object</a> (shared between processes) is the first element in the shared proxy list <code>datasets</code> that is a list of large objects (each about 200-300MB). This <code>datasets</code> list usually has 5-25 elements. I typically need to run this program on a HPC cluster.</p>

<p>Here is the question, when I run this program with 32 processes and 50GB of memory (num_repetitions=200, with datasets being a list of 10 objects, each 250MB), I do not see a speedup even by factor of 16 (with 32 parallel processes). I do not understand why - any clues? Any obvious mistakes, or bad choices? Where can I improve this implementation? Any alternatives?</p>

<p>I am sure this has been discussed before, and the reasons can be varied and very specific to implementation - hence I request you to provide me your 2 cents. Thanks.</p>

<p><strong>Update</strong>: I did some profiling with cProfile to get a better idea - here is some info, sorted by cumulative time.</p>

<pre><code>In [19]: p.sort_stats('cumulative').print_stats(50)
Mon Oct 16 16:43:59 2017    profiling_log.txt

         555404 function calls (543552 primitive calls) in 662.201 seconds

   Ordered by: cumulative time
   List reduced from 4510 to 50 due to restriction &lt;50&gt;

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    897/1    0.044    0.000  662.202  662.202 {built-in method builtins.exec}
        1    0.000    0.000  662.202  662.202 test_rhst.py:2(&lt;module&gt;)
        1    0.001    0.001  661.341  661.341 test_rhst.py:70(test_chance_classifier_binary)
        1    0.000    0.000  661.336  661.336 /Users/Reddy/dev/neuropredict/neuropredict/rhst.py:677(run)
        4    0.000    0.000  661.233  165.308 /Users/Reddy/anaconda/envs/py36/lib/python3.6/threading.py:533(wait)
        4    0.000    0.000  661.233  165.308 /Users/Reddy/anaconda/envs/py36/lib/python3.6/threading.py:263(wait)
       23  661.233   28.749  661.233   28.749 {method 'acquire' of '_thread.lock' objects}
        1    0.000    0.000  661.233  661.233 /Users/Reddy/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py:261(map)
        1    0.000    0.000  661.233  661.233 /Users/Reddy/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py:637(get)
        1    0.000    0.000  661.233  661.233 /Users/Reddy/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py:634(wait)
    866/8    0.004    0.000    0.868    0.108 &lt;frozen importlib._bootstrap&gt;:958(_find_and_load)
    866/8    0.003    0.000    0.867    0.108 &lt;frozen importlib._bootstrap&gt;:931(_find_and_load_unlocked)
    720/8    0.003    0.000    0.865    0.108 &lt;frozen importlib._bootstrap&gt;:641(_load_unlocked)
    596/8    0.002    0.000    0.865    0.108 &lt;frozen importlib._bootstrap_external&gt;:672(exec_module)
   1017/8    0.001    0.000    0.863    0.108 &lt;frozen importlib._bootstrap&gt;:197(_call_with_frames_removed)
   522/51    0.001    0.000    0.765    0.015 {built-in method builtins.__import__}
</code></pre>

<p>The profiling info now sorted by <code>time</code></p>

<pre><code>In [20]: p.sort_stats('time').print_stats(20)
Mon Oct 16 16:43:59 2017    profiling_log.txt

         555404 function calls (543552 primitive calls) in 662.201 seconds

   Ordered by: internal time
   List reduced from 4510 to 20 due to restriction &lt;20&gt;

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       23  661.233   28.749  661.233   28.749 {method 'acquire' of '_thread.lock' objects}
   115/80    0.177    0.002    0.211    0.003 {built-in method _imp.create_dynamic}
      595    0.072    0.000    0.072    0.000 {built-in method marshal.loads}
        1    0.045    0.045    0.045    0.045 {method 'acquire' of '_multiprocessing.SemLock' objects}
    897/1    0.044    0.000  662.202  662.202 {built-in method builtins.exec}
        3    0.042    0.014    0.042    0.014 {method 'read' of '_io.BufferedReader' objects}
2037/1974    0.037    0.000    0.082    0.000 {built-in method builtins.__build_class__}
      286    0.022    0.000    0.061    0.000 /Users/Reddy/anaconda/envs/py36/lib/python3.6/site-packages/scipy/misc/doccer.py:12(docformat)
     2886    0.021    0.000    0.021    0.000 {built-in method posix.stat}
       79    0.016    0.000    0.016    0.000 {built-in method posix.read}
      597    0.013    0.000    0.021    0.000 &lt;frozen importlib._bootstrap_external&gt;:830(get_data)
      276    0.011    0.000    0.013    0.000 /Users/Reddy/anaconda/envs/py36/lib/python3.6/sre_compile.py:250(_optimize_charset)
      108    0.011    0.000    0.038    0.000 /Users/Reddy/anaconda/envs/py36/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:626(_construct_argparser)
     1225    0.011    0.000    0.050    0.000 &lt;frozen importlib._bootstrap_external&gt;:1233(find_spec)
     7179    0.009    0.000    0.009    0.000 {method 'splitlines' of 'str' objects}
       33    0.008    0.000    0.008    0.000 {built-in method posix.waitpid}
      283    0.008    0.000    0.015    0.000 /Users/Reddy/anaconda/envs/py36/lib/python3.6/site-packages/scipy/misc/doccer.py:128(indentcount_lines)
        3    0.008    0.003    0.008    0.003 {method 'poll' of 'select.poll' objects}
     7178    0.008    0.000    0.008    0.000 {method 'expandtabs' of 'str' objects}
      597    0.007    0.000    0.007    0.000 {method 'read' of '_io.FileIO' objects}
</code></pre>

<p>More profiling info sorted by <code>percall</code> info:
<a href=""https://i.stack.imgur.com/EWxFi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EWxFi.png"" alt=""profiling info sorted by percall""></a></p>

<p><strong>Update 2</strong></p>

<p>The elements in the large list <code>datasets</code> I mentioned earlier are not usually as big - they are typically 10-25MB each. But depending on the floating point precision used, number of samples and features, this can easily grow to 500MB-1GB per element also. hence I'd prefer a solution that can scale.</p>

<p><strong>Update 3:</strong></p>

<p>The code inside holdout_trial_compare_datasets uses method GridSearchCV of scikit-learn, which internally uses joblib library if we set n_jobs > 1 (or whenever we even set it). This might lead to some bad interactions between multiprocessing and joblib. So trying another config where I do not set n_jobs at all (which should to default no parallelism within scikit-learn). Will keep you posted.</p>
"
"Pandas dataset into an array for modelling in Scikit-Learn","<p>Can we run scikit-learn models on Pandas DataFrames or do we need to convert DataFrames into NumPy arrays?</p>
"
"Understanding the `ngram_range` argument in a CountVectorizer in sklearn","<p>I'm a little confused about how to use ngrams in the scikit-learn library in Python, specifically, how the <code>ngram_range</code> argument works in a CountVectorizer.  </p>

<p>Running this code:  </p>

<pre><code>from sklearn.feature_extraction.text import CountVectorizer
vocabulary = ['hi ', 'bye', 'run away']
cv = CountVectorizer(vocabulary=vocabulary, ngram_range=(1, 2))
print cv.vocabulary_
</code></pre>

<p>gives me:  </p>

<pre><code>{'hi ': 0, 'bye': 1, 'run away': 2}
</code></pre>

<p>Where I was under the (obviously mistaken) impression that I would get unigrams and bigrams, like this:  </p>

<pre><code>{'hi ': 0, 'bye': 1, 'run away': 2, 'run': 3, 'away': 4}
</code></pre>

<p>I am working with the documentation here:  <a href=""http://scikit-learn.org/stable/modules/feature_extraction.html"">http://scikit-learn.org/stable/modules/feature_extraction.html</a></p>

<p>Clearly there is something terribly wrong with my understanding of how to use ngrams.  Perhaps the argument is having no effect or I have some conceptual issue with what an actual bigram is!  I'm stumped.  If anyone has a word of advice to throw my way, I'd be grateful.  </p>

<p><strong>UPDATE:</strong><br>
I have realized the folly of my ways. I was under the impression that the <code>ngram_range</code> would affect the vocabulary, not the corpus.</p>
"
"List the words in a vocabulary according to occurrence in a text corpus , Scikit-Learn","<p>I have fitted a <code>CountVectorizer</code> to some documents in <code>scikit-learn</code>. I would like to see all the terms and their corresponding frequency in the text corpus, in order to select stop-words. For example</p>

<pre class=""lang-none prettyprint-override""><code>'and' 123 times, 'to' 100 times, 'for' 90 times, ... and so on
</code></pre>

<p>Is there any built-in function for this?</p>
"
"Inversing PCA transform with sklearn (with whiten=True)","<p>Usually PCA transform is easily inversed:</p>

<pre><code>import numpy as np
from sklearn import decomposition

x = np.zeros((500, 10))
x[:, :5] = random.rand(500, 5)
x[:, 5:] = x[:, :5] # so that using PCA would make sense

p = decomposition.PCA()
p.fit(x)

a = x[5, :]

print p.inverse_transform(p.transform(a)) - a  # this yields small numbers (about 10**-16)
</code></pre>

<p>Now, if we try to add whiten=True parameter the result will be entirely different:</p>

<pre><code>p = decomposition.PCA(whiten=True)
p.fit(x)

a = x[5, :]

print p.inverse_transform(p.transform(a)) - a  # now yields numbers about 10**15
</code></pre>

<p>So, as I didn't find any other methods that would do the trick, I wounder how is it possible to obtain the original value of a? Or is it even possible at all? Thanks a lot for any help.</p>
"
"How to interpret scikit's learn confusion matrix and classification report?","<p>I have a sentiment analysis task, for this Im using this <a href=""http://pastebin.com/ikbKQcsc"" rel=""noreferrer"">corpus</a> the opinions have 5 classes (<code>very neg</code>, <code>neg</code>, <code>neu</code>, <code>pos</code>, <code>very pos</code>), from 1 to 5. So I do the classification as follows:</p>

<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
tfidf_vect= TfidfVectorizer(use_idf=True, smooth_idf=True,
                            sublinear_tf=False, ngram_range=(2,2))
from sklearn.cross_validation import train_test_split, cross_val_score

import pandas as pd

df = pd.read_csv('/corpus.csv',
                     header=0, sep=',', names=['id', 'content', 'label'])

X = tfidf_vect.fit_transform(df['content'].values)
y = df['label'].values


from sklearn import cross_validation
X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,
                                                    y, test_size=0.33)


from sklearn.svm import SVC
svm_1 = SVC(kernel='linear')
svm_1.fit(X, y)
svm_1_prediction = svm_1.predict(X_test)
</code></pre>

<p>Then with the metrics I obtained the following confusion matrix and classification report, as follows:</p>

<pre><code>print '\nClasification report:\n', classification_report(y_test, svm_1_prediction)
print '\nConfussion matrix:\n',confusion_matrix(y_test, svm_1_prediction)
</code></pre>

<p>Then, this is the result:</p>

<pre><code>Clasification report:
             precision    recall  f1-score   support

          1       1.00      0.76      0.86        71
          2       1.00      0.84      0.91        43
          3       1.00      0.74      0.85        89
          4       0.98      0.95      0.96       288
          5       0.87      1.00      0.93       367

avg / total       0.94      0.93      0.93       858


Confussion matrix:
[[ 54   0   0   0  17]
 [  0  36   0   1   6]
 [  0   0  66   5  18]
 [  0   0   0 273  15]
 [  0   0   0   0 367]]
</code></pre>

<p>How can I interpret the above confusion matrix and classification report. I tried reading the <a href=""http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"" rel=""noreferrer"">documentation</a> and this <a href=""https://stats.stackexchange.com/questions/95209/how-can-i-interpret-sklearn-confusion-matrix"">question</a>. But still can interpretate what happened here particularly with this data?. Wny this matrix is somehow ""diagonal""?. By the other hand what means the recall, precision, f1score and support for this data?. What can I say about this data?. Thanks in advance guys</p>
"
"Scikit-learn train_test_split with indices","<p>How do I get the original indices of the data when using train_test_split()?</p>

<p>What I have is the following</p>

<pre><code>from sklearn.cross_validation import train_test_split
import numpy as np
data = np.reshape(np.randn(20),(10,2)) # 10 training examples
labels = np.random.randint(2, size=10) # 10 labels
x1, x2, y1, y2 = train_test_split(data, labels, size=0.2)
</code></pre>

<p>But this does not give the indices of the original data. 
One workaround is to add indices to data (e.g. <code>data = [(i, d) for i, d in enumerate(data)]</code>) and then pass them inside <code>train_test_split</code> and then expand again. 
Is there any cleaner solution?</p>
"
"Get U, Sigma, V* matrix from Truncated SVD in scikit-learn","<p>I am using truncated SVD from <code>scikit-learn</code> package.</p>

<p>In the definition of SVD, an original matrix <strong>A</strong> is approxmated as a product <strong>A</strong> ≈ <strong>UΣV*</strong> where <strong>U</strong> and <strong>V</strong> have orthonormal columns, and <strong>Σ</strong> is non-negative diagonal.</p>

<p>I need to get the <strong>U</strong>, <strong>Σ</strong> and <strong>V*</strong> matrices. </p>

<p>Looking at the source code <a href=""https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/decomposition/truncated_svd.py#L174"">here</a> I found out that <strong>V*</strong> is stored in <code>self.compoments_</code> field after calling <code>fit_transform</code>.</p>

<p>Is it possible to get <strong>U</strong> and <strong>Σ</strong> matrices?</p>

<p>My code: </p>

<pre><code>import sklearn.decomposition as skd
import numpy as np

matrix = np.random.random((20,20))
trsvd = skd.TruncatedSVD(n_components=15)
transformed = trsvd.fit_transform(matrix)
VT = trsvd.components_
</code></pre>
"
"Fitting data vs. transforming data in scikit-learn","<p>In <a href=""http://www.astroml.org/sklearn_tutorial/general_concepts.html"" rel=""noreferrer"">scikit-learn</a>, all estimators have a <code>fit()</code> method, and depending on whether they are supervised or unsupervised, they also have a <code>predict()</code> or <code>transform()</code> method.</p>

<p>I am in the process of writing a <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html"" rel=""noreferrer"">transformer</a> for an unsupervised learning task and was wondering if there is a rule of thumb where to put which kind of learning logic. The official documentation is not very helpful in this regard:</p>

<blockquote>
  <p><code>fit_transform(X, y=None, **fit_params)</code><br>
  Fit to data, then transform it.</p>
</blockquote>

<p>In this context, what is meant by both <em>fitting data</em> and <em>transforming data</em>?</p>
"
"Sklearn, gridsearch: how to print out progress during the execution?","<p>I am using <code>GridSearch</code> from <code>sklearn</code> to optimize parameters of the classifier. There is a lot of data, so the whole process of optimization takes a while: more than a day. I would like to watch the performance of the already-tried combinations of parameters during the execution. Is it possible? </p>
"
"Recursive feature elimination on Random Forest using scikit-learn","<p>I'm trying to preform recursive feature elimination using <code>scikit-learn</code> and a random forest classifier, with OOB ROC as the method of scoring each subset created during the recursive process.</p>

<p>However, when I try to use the <code>RFECV</code> method, I get an error saying <code>AttributeError: 'RandomForestClassifier' object has no attribute 'coef_'</code>  </p>

<p>Random Forests don't have coefficients per se, but they do have rankings by Gini score.  So, I'm wondering how to get arround this problem.</p>

<p>Please note that I want to use a method that will explicitly tell me what features from my <code>pandas</code> DataFrame were selected in the optimal grouping as I am using recursive feature selection to try to minimize the amount of data I will input into the final classifier. </p>

<p>Here's some example code: </p>

<pre><code>from sklearn import datasets
import pandas as pd
from pandas import Series
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFECV

iris = datasets.load_iris()
x=pd.DataFrame(iris.data, columns=['var1','var2','var3', 'var4'])
y=pd.Series(iris.target, name='target')
rf = RandomForestClassifier(n_estimators=500, min_samples_leaf=5, n_jobs=-1)
rfecv = RFECV(estimator=rf, step=1, cv=10, scoring='ROC', verbose=2)
selector=rfecv.fit(x, y)

Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/Users/bbalin/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/rfe.py"", line 336, in fit
    ranking_ = rfe.fit(X_train, y_train).ranking_
  File ""/Users/bbalin/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/rfe.py"", line 148, in fit
    if estimator.coef_.ndim &gt; 1:
AttributeError: 'RandomForestClassifier' object has no attribute 'coef_'
</code></pre>
"
"Scikit-learn cross validation scoring for regression","<p>How can one use <code>cross_val_score</code> for regression? The default scoring seems to be accuracy, which is not very meaningful for regression. Supposedly I would like to use mean squared error, is it possible to specify that in <code>cross_val_score</code>?</p>

<p>Tried the following two but doesn't work:</p>

<pre><code>scores = cross_validation.cross_val_score(svr, diabetes.data, diabetes.target, cv=5, scoring='mean_squared_error') 
</code></pre>

<p>and  </p>

<pre><code>scores = cross_validation.cross_val_score(svr, diabetes.data, diabetes.target, cv=5, scoring=metrics.mean_squared_error)
</code></pre>

<p>The first one generates a list of negative numbers while mean squared error should always be non-negative. The second one complains that:</p>

<pre><code>mean_squared_error() takes exactly 2 arguments (3 given)
</code></pre>
"
"Create Bayesian Network and learn parameters with Python3.x","<p>I'm searching for the most appropriate tool for python3.x on Windows to create a Bayesian Network, learn its parameters from data and perform the inference.</p>

<p>The network structure I want to define myself as follows:
<img src=""https://i.stack.imgur.com/iscKX.jpg"" alt=""enter image description here""></p>

<p>It is taken from <a href=""http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=6697180&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D6697180"" rel=""noreferrer"">this</a> paper. </p>

<p>All the variables are discrete (and can take only 2 possible states) except ""Size"" and ""GraspPose"", which are continuous and should be modeled as Mixture of Gaussians.</p>

<p>Authors use <em>Expectation-Maximization algorithm</em> to learn the parameters for conditional probability tables and <em>Junction-Tree algorithm</em> to compute the exact inference.</p>

<p>As I understand all is realised in MatLab with Bayes Net Toolbox by Murphy.</p>

<p>I tried to search something similar in python and here are my results:</p>

<ol>
<li>Python Bayesian Network Toolbox <a href=""http://sourceforge.net/projects/pbnt.berlios/"" rel=""noreferrer"">http://sourceforge.net/projects/pbnt.berlios/</a> (<a href=""http://pbnt.berlios.de/"" rel=""noreferrer"">http://pbnt.berlios.de/</a>). Web-site doesn't work, project doesn't seem to be supported. </li>
<li>BayesPy <a href=""https://github.com/bayespy/bayespy"" rel=""noreferrer"">https://github.com/bayespy/bayespy</a>
I think this is what I actually need, but I fail to find some examples similar to my case, to understand how to approach construction of the network structure.</li>
<li><p>PyMC seems to be a powerful module, but I have problems with importing it on Windows 64, python 3.3. I get error when I install development version </p>

<p>WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.</p></li>
</ol>

<p>UPDATE:</p>

<ol start=""4"">
<li>libpgm (<a href=""http://pythonhosted.org/libpgm/"" rel=""noreferrer"">http://pythonhosted.org/libpgm/</a>). Exactly what I need, unfortunately not supported by python 3.x</li>
<li>Very interesting actively developing library: PGMPY. Unfortunately continuous variables and learning from data is not supported yet. <a href=""https://github.com/pgmpy/pgmpy/"" rel=""noreferrer"">https://github.com/pgmpy/pgmpy/</a> </li>
</ol>

<p>Any advices and concrete examples will be highly appreciated.</p>
"
"Clustering Based On Distance Matrix","<p>My objective is to cluster words based on how similar they are with respect to a corpus of text documents. I have computed Jaccard Similarity between every pair of words. In other words, I have a sparse distance matrix available with me. Can anyone point me to any clustering algorithm (and possibly its library in Python) which takes distance matrix as input ? I also do not know the number of clusters beforehand. I only want to cluster these words and obtain which words are clustered together.</p>
"
"pip: pulling updates from remote git repository","<p>I installed <a href=""https://github.com/scikit-learn/scikit-learn"" rel=""noreferrer"">scikit-learn</a> from GitHub a couple of weeks ago:</p>

<pre><code>pip install git+git://github.com/scikit-learn/scikit-learn@master
</code></pre>

<p>I went to GitHub and there have been several changes to the master branch since then.</p>

<p>How can I update my local installation of <code>scikit-learn</code>?</p>

<p>I tried <code>pip install scikit-learn --upgrade</code> but I got:</p>

<pre><code>Requirement already up-to-date
Cleaning up ...
</code></pre>
"
"scikits learn and nltk: Naive Bayes classifier performance highly different","<p>I am comparing two Naive Bayes classifiers: one <a href=""http://nltk.googlecode.com/svn/trunk/doc/api/nltk.classify.naivebayes.NaiveBayesClassifier-class.html"" rel=""noreferrer"">from NLTK</a> and and one <a href=""http://scikit-learn.org/0.10/modules/naive_bayes.html"" rel=""noreferrer"">from scikit-learn</a>. I'm dealing with a multi-class classification problem (3 classes: positive (1), negative (-1), and neutral (0)). </p>

<p>Without performing any feature selection (that is, using all features available), and using a training dataset of 70,000 instances (noisy-labeled, with an instance distribution of  17% positive, 4%  negative and 78% neutral), I train two classifiers, the first one is a nltk.NaiveBayesClassifier, and the second one is a sklearn.naive_bayes.MultinomialNB (with <code>fit_prior=True</code>).</p>

<p>After training, I evaluated the classifiers on my test set of 30,000 instances and I get the following results:</p>

<pre><code>**NLTK's NaiveBayes**
accuracy: 0.568740
class: 1
     precision: 0.331229
     recall: 0.331565
     F-Measure: 0.331355
class: -1
     precision: 0.079253 
     recall: 0.446331 
     F-Measure: 0.134596 
class: 0
     precision: 0.849842 
     recall: 0.628126 
     F-Measure: 0.722347 


**Scikit's MultinomialNB (with fit_prior=True)**
accuracy: 0.834670
class: 1
     precision: 0.400247
     recall: 0.125359
     F-Measure: 0.190917
class: -1
     precision: 0.330836
     recall: 0.012441
     F-Measure: 0.023939
class: 0
     precision: 0.852997
     recall: 0.973406
     F-Measure: 0.909191

**Scikit's MultinomialNB (with fit_prior=False)**
accuracy: 0.834680
class: 1
     precision: 0.400380
     recall: 0.125361
     F-Measure: 0.190934
class: -1
     precision: 0.330836
     recall: 0.012441
     F-Measure: 0.023939
class: 0
     precision: 0.852998
     recall: 0.973418
     F-Measure: 0.909197
</code></pre>

<p>I have noticed that while Scikit's classifier has better overall accuracy and precision, its recall is very low compared to the NLTK one, at least with my data. Taking into account that they might be (almost) the same classifiers, isn't this strange?</p>
"
"How to Find Documents That are in the same Cluster with KMeans","<p>I have clustered various articles together with the Scikit-learn framework. Below are the top 15 words in each cluster:</p>

<pre><code>Cluster 0: whales islands seaworld hurricane whale odile storm tropical kph mph pacific mexico orca coast cabos
Cluster 1: ebola outbreak vaccine africa usaid foundation virus cdc gates disease health vaccines experimental centers obama
Cluster 2: jones bobo sanford children carolina mississippi alabama lexington bodies crumpton mccarty county hyder tennessee sheriff
Cluster 3: isis obama iraq syria president isil airstrikes islamic li strategy terror military war threat al
Cluster 4: yosemite wildfire park evacuation dome firefighters blaze hikers cobb helicopter backcountry trails homes california evacuate
</code></pre>

<p>I create the ""bag of words"" matrix like so:</p>

<pre><code>hasher = TfidfVectorizer(max_df=0.5,
                             min_df=2, stop_words='english',
                             use_idf=1)
vectorizer = make_pipeline(hasher, TfidfTransformer())
# document_text_list is a list of all text in a given article
X_train_tfidf = vectorizer.fit_transform(document_text_list)
</code></pre>

<p>And then run KMeans like so:</p>

<pre><code>km = sklearn.cluster.KMeans(init='k-means++', max_iter=10000, n_init=1,
                verbose=0, n_clusters=25)
km.fit(X_train_tfidf)
</code></pre>

<p>I am printing out the clusters like so:</p>

<pre><code>print(""Top terms per cluster:"")
order_centroids = km.cluster_centers_.argsort()[:, ::-1]
terms = hasher.get_feature_names()
for i in range(25):
    print(""Cluster %d:"" % i, end='')
    for ind in order_centroids[i, :15]:
        print(' %s' % terms[ind], end='')
    print()
</code></pre>

<p>However, I would like to know how to figure out which documents all belong in the same cluster, and ideally, their respective distance to the center of the centroid (cluster). </p>

<p>I know that each row of the generated matrix (<code>X_train_tfidf</code>) corresponds to a document, but there is no obvious way to get back this information after performing the KMeans algorithm. How would I go about doing this with scikit-learn?</p>

<p><code>X_train_tfidf</code> looks like:</p>

<pre><code>X_train_tfidf:   (0, 4661)  0.0405014425985
  (0, 19271)    0.0914545222775
  (0, 20393)    0.287636818634
  (0, 56027)    0.116893929188
  (0, 30872)    0.137815327338
  (0, 35256)    0.0343461345507
  (0, 31291)    0.209804679792
  (0, 66008)    0.0643776635222
  (0, 3806) 0.0967713285061
  (0, 66338)    0.0532881852791
  (0, 65023)    0.0702918299573
  (0, 41785)    0.197672720592
  (0, 29774)    0.120772893833
  (0, 61409)    0.0268609667042
  (0, 55527)    0.134102682463
  (0, 40011)    0.0582437010271
  (0, 19667)    0.0234843097048
  (0, 51667)    0.128270976476
  (0, 52791)    0.57198926651
  (0, 15014)    0.149195054799
  (0, 18805)    0.0277497826525
  (0, 35939)    0.170775938672
  (0, 5808) 0.0473913910636
  (0, 24922)    0.0126531527875
  (0, 10346)    0.0200098997901
  : :
  (23945, 56927)    0.0595132327966
  (23945, 23259)    0.0100977769025
  (23945, 12515)    0.0482102583442
  (23945, 49709)    0.210139450446
  (23945, 28742)    0.0190221880312
  (23945, 16628)    0.137692798005
  (23945, 53424)    0.157029848335
  (23945, 30647)    0.104485375827
  (23945, 57512)    0.0569754813269
  (23945, 39389)    0.0158180459761
  (23945, 26093)    0.0153713768922
  (23945, 9787) 0.0963777149738
  (23945, 23260)    0.158336452835
  (23945, 50595)    0.0527243936945
  (23945, 42447)    0.0527515904547
  (23945, 2829) 0.0351677269698
  (23945, 2832) 0.0175929392039
  (23945, 52079)    0.0849796887889
  (23945, 13523)    0.0878730969786
  (23945, 57849)    0.133869666381
  (23945, 25064)    0.128424780903
  (23945, 31129)    0.0919760384953
  (23945, 65601)    0.0388718258746
  (23945, 1428) 0.391477289626
  (23945, 2152) 0.655211469073
  X_train_tfidf shape: (23946, 67816)
</code></pre>

<p><strong>In Response to ttttthomasssss's Answer:</strong></p>

<p>When I try to run the following:</p>

<pre><code>X_cluster_0 = X_train_tfidf[cluster_0]
</code></pre>

<p>I get the error:</p>

<pre><code>File ""cluster.py"", line 52, in main
    X_cluster_0 = X_train_tfidf[cluster_0]
File ""/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/scipy/sparse/csr.py"", line 226, in __getitem__
    col = key[1]
IndexError: tuple index out of range
</code></pre>

<p>Looking at the structure of <code>cluster_0</code>:</p>

<pre><code>(array([  858,  2012,  2256,  2762,  2920,  3770,  6052,  6174,  8296,
9494,  9966, 10085, 11914, 12117, 12633, 12727, 12993, 13527,
13754, 14186, 14669, 14713, 14973, 15071, 15157, 15208, 15926,
16300, 16301, 17138, 17556, 17775, 18236, 19057, 20106, 21014, 21080]),)
</code></pre>

<p>It's a tuple structure that has content in the 0th position so I changed the line to the following:</p>

<pre><code>X_cluster_0 = X_train_tfidf[cluster_0[0]]
</code></pre>

<p>I am pulling ""documents"" from a database that I can easily obtain the index from (iterate the provided array until I find the respective document [assuming of course that scikit doesn't alter orderings of documents in the matrix]). So I don't understand exactly what <code>X_cluster_0</code> represents. <code>X_cluster_0</code> has the following structure:</p>

<pre><code>  X_cluster_0:   (0, 42726) 0.741747456202
  (0, 13535)    0.115880661286
  (0, 17447)    0.117608794277
  (0, 44849)    0.414829246262
  (0, 14574)    0.10214258736
  (0, 17317)    0.0634383214735
  (0, 17935)    0.0591234431875
  : :
  (17, 33867)   0.0174155914371
  (17, 48916)   0.0227046046275
  (17, 59132)   0.0168864861723
  (17, 40860)   0.0485813219503
  (17, 63725)   0.0271415763987
  (18, 45019)   0.490135684209
  (18, 36168)   0.14595160766
  (18, 52304)   0.139590524213
  (18, 63586)   0.16501953796
  (18, 28709)   0.15075416279
  (18, 11495)   0.0926490431993
  (18, 40860)   0.124236878928
</code></pre>

<p><strong>Calculating Distance to Centroid</strong></p>

<p>Currently running the suggested code (<code>distance = euclidean(X_cluster_0[0], km.cluster_centers_[0])</code>) results in the following error:</p>

<pre><code>File ""cluster.py"", line 68, in main
    distance = euclidean(X_cluster_0[0], km.cluster_centers_[0])
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/scipy/spatial/distance.py"", line 211, in euclidean
    dist = norm(u - v)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/scipy/sparse/compressed.py"", line 197, in __sub__
    raise NotImplementedError('adding a nonzero scalar to a '
NotImplementedError: adding a nonzero scalar to a sparse matrix is not supported
</code></pre>

<p>Here is what <code>km.cluster_centers</code> looks like:</p>

<pre><code>km.cluster_centers: [  9.47080802e-05   2.53907413e-03   0.00000000e+00 ...,   0.00000000e+00
   0.00000000e+00   0.00000000e+00]
</code></pre>

<p>I guess the problem I am having now is how to extract the ith item of a matrix (assuming traversal of the matrix from left to right). Any level of index nesting I specify makes no difference (i.e. <code>X_cluster_0[0]</code>, <code>X_cluster_0[0][0]</code>, and <code>X_cluster_0[0][0][0]</code> all give me the same printed out matrix structure depicted above).</p>
"
"pandas dataframe columns scaling with sklearn","<p>I have a pandas dataframe with mixed type columns, and I'd like to apply sklearn's min_max_scaler to some of the columns.  Ideally, I'd like to do these transformations in place, but haven't figured out a way to do that yet.  I've written the following code that works:</p>

<pre><code>import pandas as pd
import numpy as np
from sklearn import preprocessing

scaler = preprocessing.MinMaxScaler()

dfTest = pd.DataFrame({'A':[14.00,90.20,90.95,96.27,91.21],'B':[103.02,107.26,110.35,114.23,114.68], 'C':['big','small','big','small','small']})
min_max_scaler = preprocessing.MinMaxScaler()

def scaleColumns(df, cols_to_scale):
    for col in cols_to_scale:
        df[col] = pd.DataFrame(min_max_scaler.fit_transform(pd.DataFrame(dfTest[col])),columns=[col])
    return df

dfTest

    A   B   C
0    14.00   103.02  big
1    90.20   107.26  small
2    90.95   110.35  big
3    96.27   114.23  small
4    91.21   114.68  small

scaled_df = scaleColumns(dfTest,['A','B'])
scaled_df

A   B   C
0    0.000000    0.000000    big
1    0.926219    0.363636    small
2    0.935335    0.628645    big
3    1.000000    0.961407    small
4    0.938495    1.000000    small
</code></pre>

<p>I'm curious if this is the preferred/most efficient way to do this transformation.  Is there a way I could use df.apply that would be better?  </p>

<p>I'm also surprised I can't get the following code to work:</p>

<p><code>bad_output = min_max_scaler.fit_transform(dfTest['A'])</code></p>

<p>If I pass an entire dataframe to the scaler it works:</p>

<p><code>dfTest2 = dfTest.drop('C', axis = 1)
good_output = min_max_scaler.fit_transform(dfTest2)
good_output</code></p>

<p>I'm confused why passing a series to the scaler fails.  In my full working code above I had hoped to just pass a series to the scaler then set the dataframe column = to the scaled series.  I've seen this question asked a few other places, but haven't found a good answer.  Any help understanding what's going on here would be greatly appreciated!</p>
"
"Missing values in scikits machine learning","<p>Is it possible to have missing values in scikit-learn ? How should they be represented? I couldn't find any documentation about that.</p>
"
"How to find the corresponding class in clf.predict_proba()","<p>I have a number of classes and corresponding feature vectors, and when I run predict_proba() I will get this:</p>

<pre><code>classes = ['one','two','three','one','three']

feature = [[0,1,1,0],[0,1,0,1],[1,1,0,0],[0,0,0,0],[0,1,1,1]]

from sklearn.naive_bayes import BernoulliNB

clf = BernoulliNB()
clf.fit(feature,classes)
clf.predict_proba([0,1,1,0])
&gt;&gt; array([[ 0.48247836,  0.40709111,  0.11043053]])
</code></pre>

<p>I would like to get what probability that corresponds to what class. On this page it says that they are ordered by arithmetical order, i'm not 100% sure of what that means: <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict_proba"">http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict_proba</a></p>

<p>Does it mean that I have go trough my training examples assign the corresponding index to the first encounter of a class, or is there a command like </p>

<p><code>clf.getClasses() = ['one','two','three']?</code></p>
"
"Sci-kit and Regression Summary","<p>As an R user, I have been wanted to also get up to speed on scikit. </p>

<p>Started off with Linear, Ridge and Lasso. I have gone through the examples. Below is for the basic OLS. </p>

<p>To set up the model(s) seems reasonable enough- but can't seem to find a reasonable way to get a standard set of regression output. </p>

<p>Example in my code:</p>

<pre><code># Linear Regression
import numpy as np
from sklearn import datasets
from sklearn.linear_model import LinearRegression
# load the diabetes datasets
dataset = datasets.load_diabetes()
# fit a linear regression model to the data
model = LinearRegression()
model.fit(dataset.data, dataset.target)
print(model)
# make predictions
expected = dataset.target
predicted = model.predict(dataset.data)
# summarize the fit of the model
mse = np.mean((predicted-expected)**2)
print model.intercept_, model.coef_, mse, 
print(model.score(dataset.data, dataset.target))
</code></pre>

<p>Seems like intercept and coef is built into the model, and I just type print (second to last line) to see them. What about all the other standard regression output like R^2, adjusted R^2, p values, etc. If I read the examples correctly, seems like you have to write a function/equation for each of these and then print it. </p>

<p>So, is there no standard summary output for lin reg models?</p>

<p>Also, in my printed array of outputs of coefficients, there are no variable names associated with each of these? I just get the numeric array. Is there a way to print these where I get an output of the coefficients and the variable they go with? </p>

<p>My printed output</p>

<pre><code>LinearRegression(copy_X=True, fit_intercept=True, normalize=False)
152.133484163 [ -10.01219782 -239.81908937  519.83978679  324.39042769 -792.18416163
  476.74583782  101.04457032  177.06417623  751.27932109   67.62538639] 2859.69039877
0.517749425413
</code></pre>

<p>Thanks to the scilearn users.</p>
"
"Converting LinearSVC's decision function to probabilities (Scikit learn python )","<p>I use linear SVM from scikit learn (LinearSVC) for binary classification problem. I understand that LinearSVC can give me the predicted labels, and the decision scores but I wanted probability estimates (confidence in the label). I want to continue using LinearSVC because of speed (as compared to sklearn.svm.SVC with linear kernel) Is it reasonable to use a logistic function to convert the decision scores to probabilities? </p>

<pre><code>import sklearn.svm as suppmach
# Fit model:
svmmodel=suppmach.LinearSVC(penalty='l1',C=1)
predicted_test= svmmodel.predict(x_test)
predicted_test_scores= svmmodel.decision_function(x_test) 
</code></pre>

<p>I want to check if it makes sense to obtain Probability estimates simply as [1 / (1 + exp(-x)) ]  where x is the decision score. </p>

<p>Alternately, are there other options wrt classifiers that I can use to do this efficiently? </p>

<p>Thanks. </p>
"
"Multidimensional Scaling Fitting in Numpy, Pandas and Sklearn (ValueError)","<p>I'm trying out multidimensional scaling with sklearn, pandas and numpy.  The data file Im using has 10 numerical columns and no missing values.  I am trying to take this ten dimensional data and visualize it in 2 dimensions with sklearn.manifold's multidimensional scaling as follows:</p>

<pre><code>import numpy as np
import pandas as pd
from sklearn import manifold
from sklearn.metrics import euclidean_distances

seed = np.random.RandomState(seed=3)
data = pd.read_csv('data/big-file.csv')

#  start small dont take all the data, 
#  its about 200k records
subset = data[:10000]
similarities = euclidean_distances(subset)

mds = manifold.MDS(n_components=2, max_iter=3000, eps=1e-9, 
      random_state=seed, dissimilarity=""precomputed"", n_jobs=1)

pos = mds.fit(similarities).embedding_
</code></pre>

<p>But I get this value error:</p>

<pre><code>Traceback (most recent call last):
  File ""demo/mds-demo.py"", line 18, in &lt;module&gt;
    pos = mds.fit(similarities).embedding_
  File ""/Users/dwilliams/Desktop/Anaconda/lib/python2.7/site-packages/sklearn/manifold/mds.py"", line 360, in fit
    self.fit_transform(X, init=init)
  File ""/Users/dwilliams/Desktop/Anaconda/lib/python2.7/site-packages/sklearn/manifold/mds.py"", line 395, in fit_transform
eps=self.eps, random_state=self.random_state)
  File ""/Users/dwilliams/Desktop/Anaconda/lib/python2.7/site-packages/sklearn/manifold/mds.py"", line 242, in smacof
eps=eps, random_state=random_state)
  File ""/Users/dwilliams/Desktop/Anaconda/lib/python2.7/site-packages/sklearn/manifold/mds.py"", line 73, in _smacof_single
raise ValueError(""similarities must be symmetric"")
ValueError: similarities must be symmetric
</code></pre>

<p>I thought euclidean_distances returned a symmetric matrix.  What am I doing wrong and how do I fix it?</p>
"
"Scalable or online out-of-core multi-label classifiers","<p>I have been blowing my brains out over the past 2-3 weeks on this problem.
I have a multi-label (not multi-class) problem where each sample can belong to several of the labels.</p>

<p>I have around 4.5 million text documents as training data and around 1 million as test data. The labels are around 35K.</p>

<p>I am using <strong>scikit-learn</strong>. For feature extraction I was previously using TfidfVectorizer which didn't scale at all, now I am using HashVectorizer which is better but not that scalable given the number of documents that I have.</p>

<pre><code>vect = HashingVectorizer(strip_accents='ascii', analyzer='word', stop_words='english', n_features=(2 ** 10))
</code></pre>

<p>SKlearn provides a OneVsRestClassifier into which I can feed any estimator. For multi-label I found LinearSVC &amp; SGDClassifier only to be working correctly. Acc to my benchmarks SGD outperforms LinearSVC both in memory &amp; time. So, I have something like this</p>

<pre><code>clf = OneVsRestClassifier(SGDClassifier(loss='log', penalty='l2', n_jobs=-1), n_jobs=-1)
</code></pre>

<p>But this suffers from some serious issues:</p>

<ol>
<li>OneVsRest does not have a partial_fit method which makes it impossible for out-of-core learning. Are there any alternatives for that?</li>
<li>HashingVectorizer/Tfidf both work on a single core and don't have any n_jobs parameter. It's taking too much time to hash the documents. Any alternatives/suggestions? Also is the value of n_features correct?</li>
<li>I tested on 1 million documents. The Hashing takes 15 minutes and when it comes to clf.fit(X, y), I receive a MemoryError because OvR internally uses LabelBinarizer and it tries to allocate a matrix of dimensions (y x classes) which is fairly impossible to allocate. What should I do?</li>
<li>Any other libraries out there which have reliable &amp; scalable multi-label algorithms? I know of genism &amp; mahout but both of them don't have anything for multi-label situations?</li>
</ol>
"
"Grid search for hyperparameter evaluation of clustering in scikit-learn","<p>I'm clustering a sample of about 100 records (unlabelled) and trying to use grid_search to evaluate the clustering algorithm with various hyperparameters. I'm scoring using <code>silhouette_score</code> which works fine.</p>

<p>My problem here is that I don't need to use the cross-validation aspect of the <code>GridSearchCV</code>/<code>RandomizedSearchCV</code>, but I can't find a simple <code>GridSearch</code>/<code>RandomizedSearch</code>. I can write my own but the <code>ParameterSampler</code> and <code>ParameterGrid</code> objects are very useful.</p>

<p>My next step will be to subclass <code>BaseSearchCV</code> and implement my own <code>_fit()</code> method, but thought it was worth asking is there a simpler way to do this, for example by passing something to the <code>cv</code> parameter?</p>

<pre><code>def silhouette_score(estimator, X):
    clusters = estimator.fit_predict(X)
    score = metrics.silhouette_score(distance_matrix, clusters, metric='precomputed')
    return score

ca = KMeans()
param_grid = {""n_clusters"": range(2, 11)}

# run randomized search
search = GridSearchCV(
    ca,
    param_distributions=param_dist,
    n_iter=n_iter_search,
    scoring=silhouette_score,
    cv= # can I pass something here to only use a single fold?
    )
search.fit(distance_matrix)
</code></pre>
"
"Parameter ""stratify"" from method ""train_test_split"" (scikit Learn)","<p>I am trying to use <code>train_test_split</code> from package scikit Learn, but I am having trouble with parameter <code>stratify</code>. Hereafter is the code:</p>

<pre><code>from sklearn import cross_validation, datasets 

X = iris.data[:,:2]
y = iris.target

cross_validation.train_test_split(X,y,stratify=y)
</code></pre>

<p>However, I keep getting the following problem:</p>

<pre><code>raise TypeError(""Invalid parameters passed: %s"" % str(options))
TypeError: Invalid parameters passed: {'stratify': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])}
</code></pre>

<p>Does someone have an idea what is going on? Below is the function documentation.</p>

<blockquote>
  <p>[...]</p>
  
  <p><strong>stratify</strong> : array-like or None (default is None)</p>
  
  <p>If not None, data is split in a stratified fashion, using this as the labels array.</p>
  
  <p><em>New in version 0.17: stratify</em> splitting</p>
  
  <p>[...]</p>
</blockquote>
"
"What is a good range of values for the svm.SVC() hyperparameters to be explored via GridSearchCV()?","<p>I am running into the problem that the hyperparameters of my <code>svm.SVC()</code> are too wide such that the <code>GridSearchCV()</code> never gets completed! One idea is to use <code>RandomizedSearchCV()</code> instead. But again, my dataset is relative big such that 500 iterations take about 1 hour! </p>

<p>My question is, what is a good set-up (in terms of the range of values for each hyperparameter) in GridSearchCV ( or RandomizedSearchCV ) in order to stop wasting resources?</p>

<p>In other words, how to decide whether or not e.g. <strong><code>C</code></strong> values above 100 make sense and/or step of 1 is neither big not small? Any help is very much appreciated. This is the set-up am currently using:</p>

<pre><code>parameters = {
    'C':            np.arange( 1, 100+1, 1 ).tolist(),
    'kernel':       ['linear', 'rbf'],                   # precomputed,'poly', 'sigmoid'
    'degree':       np.arange( 0, 100+0, 1 ).tolist(),
    'gamma':        np.arange( 0.0, 10.0+0.0, 0.1 ).tolist(),
    'coef0':        np.arange( 0.0, 10.0+0.0, 0.1 ).tolist(),
    'shrinking':    [True],
    'probability':  [False],
    'tol':          np.arange( 0.001, 0.01+0.001, 0.001 ).tolist(),
    'cache_size':   [2000],
    'class_weight': [None],
    'verbose':      [False],
    'max_iter':     [-1],
    'random_state': [None],
    }

model = grid_search.RandomizedSearchCV( n_iter              = 500,
                                        estimator           = svm.SVC(),
                                        param_distributions = parameters,
                                        n_jobs              = 4,
                                        iid                 = True,
                                        refit               = True,
                                        cv                  = 5,
                                        verbose             = 1,
                                        pre_dispatch        = '2*n_jobs'
                                        )         # scoring = 'accuracy'
model.fit( train_X, train_Y )
print( model.best_estimator_ )
print( model.best_score_ )
print( model.best_params_ )
</code></pre>
"
"use scikit-learn to classify into multiple categories","<p>Im trying to use on of scikit-learn's supervised learning methods to classify pieces of text into one or more categories. The predict function of all the algorithms i tried just returns one match.</p>

<p>For example I have a piece of text
""Theaters in New York compared to those in London""
And I have trained the algorithm to pick a place for every text snippet i feed it.</p>

<p>In the above example I would want it to return New York and London, but it only returns New York.</p>

<p>Is it possible to use Scikit-learn to return multiple results? Or even return the label with the next highest probability? </p>

<p>Thanks for your help</p>

<p>---Update </p>

<p>I tried using OneVsRestClassifier but I still only get one option back  per piece of text. Below is the sample code i am using</p>

<pre><code>y_train = ('New York','London')


train_set = (""new york nyc big apple"", ""london uk great britain"")
vocab = {'new york' :0,'nyc':1,'big apple':2,'london' : 3, 'uk': 4, 'great britain' : 5}
count = CountVectorizer(analyzer=WordNGramAnalyzer(min_n=1, max_n=2),vocabulary=vocab)
test_set = ('nice day in nyc','london town','hello welcome to the big apple. enjoy it here and london too')

X_vectorized = count.transform(train_set).todense()
smatrix2  = count.transform(test_set).todense()


base_clf = MultinomialNB(alpha=1)

clf = OneVsRestClassifier(base_clf).fit(X_vectorized, y_train)
Y_pred = clf.predict(smatrix2)
print Y_pred
</code></pre>

<p>Result: ['New York' 'London' 'London']</p>
"
"LogisticRegression: Unknown label type: 'continuous' using sklearn in python","<p>I have the following code to test some of most popular ML algorithms of sklearn python library:</p>

<pre><code>import numpy as np
from sklearn                        import metrics, svm
from sklearn.linear_model           import LinearRegression
from sklearn.linear_model           import LogisticRegression
from sklearn.tree                   import DecisionTreeClassifier
from sklearn.neighbors              import KNeighborsClassifier
from sklearn.discriminant_analysis  import LinearDiscriminantAnalysis
from sklearn.naive_bayes            import GaussianNB
from sklearn.svm                    import SVC

trainingData    = np.array([ [2.3, 4.3, 2.5],  [1.3, 5.2, 5.2],  [3.3, 2.9, 0.8],  [3.1, 4.3, 4.0]  ])
trainingScores  = np.array( [3.4, 7.5, 4.5, 1.6] )
predictionData  = np.array([ [2.5, 2.4, 2.7],  [2.7, 3.2, 1.2] ])

clf = LinearRegression()
clf.fit(trainingData, trainingScores)
print(""LinearRegression"")
print(clf.predict(predictionData))

clf = svm.SVR()
clf.fit(trainingData, trainingScores)
print(""SVR"")
print(clf.predict(predictionData))

clf = LogisticRegression()
clf.fit(trainingData, trainingScores)
print(""LogisticRegression"")
print(clf.predict(predictionData))

clf = DecisionTreeClassifier()
clf.fit(trainingData, trainingScores)
print(""DecisionTreeClassifier"")
print(clf.predict(predictionData))

clf = KNeighborsClassifier()
clf.fit(trainingData, trainingScores)
print(""KNeighborsClassifier"")
print(clf.predict(predictionData))

clf = LinearDiscriminantAnalysis()
clf.fit(trainingData, trainingScores)
print(""LinearDiscriminantAnalysis"")
print(clf.predict(predictionData))

clf = GaussianNB()
clf.fit(trainingData, trainingScores)
print(""GaussianNB"")
print(clf.predict(predictionData))

clf = SVC()
clf.fit(trainingData, trainingScores)
print(""SVC"")
print(clf.predict(predictionData))
</code></pre>

<p>The first two works ok, but I got the following error in <code>LogisticRegression</code> call:</p>

<pre><code>root@ubupc1:/home/ouhma# python stack.py 
LinearRegression
[ 15.72023529   6.46666667]
SVR
[ 3.95570063  4.23426243]
Traceback (most recent call last):
  File ""stack.py"", line 28, in &lt;module&gt;
    clf.fit(trainingData, trainingScores)
  File ""/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py"", line 1174, in fit
    check_classification_targets(y)
  File ""/usr/local/lib/python2.7/dist-packages/sklearn/utils/multiclass.py"", line 172, in check_classification_targets
    raise ValueError(""Unknown label type: %r"" % y_type)
ValueError: Unknown label type: 'continuous'
</code></pre>

<p>The input data is the same as in the previous calls, so what is going on here? </p>

<p>And by the way, why there is a huge diference in the first prediction of <code>LinearRegression()</code> and <code>SVR()</code> algorithms <code>(15.72 vs 3.95)</code>?</p>
"
"Fitting a scikits.learn.hmm.GaussianHMM to variable length training sequences","<p>I'd like to fit a scikits.learn.hmm.GaussianHMM to training sequences of different length. The fit method, however, prevents using sequences of different length by doing </p>

<pre><code>obs = np.asanyarray(obs)
</code></pre>

<p>which only works on a list of equally shaped arrays. 
Does anyone have a hint on how to proceed?</p>
"
"DBSCAN in scikit-learn of Python: save the cluster points in an array","<p>following the example <a href=""http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#example-cluster-plot-dbscan-py"" rel=""noreferrer"">Demo of DBSCAN clustering algorithm</a> of Scikit Learning i am trying to store in an array the x, y of each clustering class </p>

<pre><code>import numpy as np
from sklearn.cluster import DBSCAN
from sklearn import metrics
from sklearn.datasets.samples_generator import make_blobs
from sklearn.preprocessing import StandardScaler
from pylab import *

# Generate sample data
centers = [[1, 1], [-1, -1], [1, -1]]
X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4, random_state=0)
X = StandardScaler().fit_transform(X) 

xx, yy = zip(*X)
scatter(xx,yy)
show()
</code></pre>

<p><img src=""https://i.stack.imgur.com/raKX2.png"" alt=""enter image description here"">   </p>

<pre><code>db = DBSCAN(eps=0.3, min_samples=10).fit(X)
core_samples = db.core_sample_indices_
labels = db.labels_
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
print n_clusters_
3
</code></pre>

<p><img src=""https://i.stack.imgur.com/Xwzp3.png"" alt=""enter image description here""></p>

<p>I'm trying to understand the DBSCAN implementation by scikit-learn, but from this point I'm having trouble. The number of cluster is 3 (n_clusters_) and I wish to store the x, y of each cluster in an array </p>
"
"How do you access tree depth in Python's scikit-learn?","<p>I'm using scikit-learn to create a Random Forest. However, I want to find the individual depths of each tree. It seems like a simple attribute to have but according to the documentation, (<a href=""http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</a>) there is no way of accessing it. </p>

<p>If this isn't possible, is there a way of accessing the tree depth from a Decision Tree model? </p>

<p>Any help would be appreciated. Thank you.</p>
"
"What's the difference between KFold and ShuffleSplit CV?","<p>It seems like KFold generates the same values every time the object is iterated over, while Shuffle Split generates different indices every time. Is this correct? If so, what are the uses for one over the other?</p>

<pre><code>cv = cross_validation.KFold(10, n_folds=2,shuffle=True,random_state=None)
cv2 = cross_validation.ShuffleSplit(10,n_iter=2,test_size=0.5)
print(list(iter(cv)))
print(list(iter(cv)))
print(list(iter(cv2)))
print(list(iter(cv2)))
</code></pre>

<p>Yields the following output:</p>

<pre><code>[(array([1, 3, 5, 8, 9]), array([0, 2, 4, 6, 7])), (array([0, 2, 4, 6, 7]), array([1, 3, 5, 8, 9]))]                                     
[(array([1, 3, 5, 8, 9]), array([0, 2, 4, 6, 7])), (array([0, 2, 4, 6, 7]), array([1, 3, 5, 8, 9]))]                                     
[(array([4, 6, 3, 2, 7]), array([8, 1, 9, 0, 5])), (array([3, 6, 7, 0, 5]), array([9, 1, 8, 4, 2]))]                                     
[(array([3, 0, 2, 1, 7]), array([5, 6, 9, 4, 8])), (array([0, 7, 1, 3, 8]), array([6, 2, 5, 4, 9]))]    
</code></pre>
"
"ValueError: Data is not binary and pos_label is not specified","<p>I am trying to calculate <code>roc_auc_score</code>, but I am getting following error.</p>

<pre><code>""ValueError: Data is not binary and pos_label is not specified""
</code></pre>

<p>My code snippet is as follows:</p>

<pre><code>import numpy as np
from sklearn.metrics import roc_auc_score
y_scores=np.array([ 0.63, 0.53, 0.36, 0.02, 0.70 ,1 , 0.48, 0.46, 0.57])
y_true=np.array(['0', '1', '0', '0', '1', '1', '1', '1', '1'])
roc_auc_score(y_true, y_scores)
</code></pre>

<p>Please tell me what is wrong with it.</p>
"
"Scikit Learn - K-Means - Elbow - criterion","<p>Today i'm trying to learn something about K-means. I Have understand the algorithm and i know how it works. Now i'm looking for the right k... I found the elbow criterion as a method to detect the right k but i do not understand how to use it with scikit learn?! In scikit learn i'm clustering things in this way</p>

<pre><code>kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10) 
kmeans.fit(data)
</code></pre>

<p>So should i do this several times for n_clusters = 1...n and watch at the Error rate to get the right k ? think this would be stupid and would take a lot of time?!</p>
"
"Python RandomForest - Unknown label Error","<p>I have trouble using RandomForest fit function</p>

<p>This is my training set</p>

<pre><code>         P1      Tp1           IrrPOA     Gz          Drz2
0        0.0     7.7           0.0       -1.4        -0.3
1        0.0     7.7           0.0       -1.4        -0.3
2        ...     ...           ...        ...         ...
3        49.4    7.5           0.0       -1.4        -0.3
4        47.4    7.5           0.0       -1.4        -0.3
... (10k rows)
</code></pre>

<p>I want to predict P1 thanks to all the other variables using sklearn.ensemble RandomForest</p>

<pre><code>colsRes = ['P1']
X_train = train.drop(colsRes, axis = 1)
Y_train = pd.DataFrame(train[colsRes])
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, Y_train)
</code></pre>

<p>Here is the error I get:</p>

<pre><code>ValueError: Unknown label type: array([[  0. ],
       [  0. ],
       [  0. ],
       ..., 
       [ 49.4],
       [ 47.4],
</code></pre>

<p>I did not find anything about this label error, I use Python 3.5.
Any advice would be a great help !</p>
"
"How to use a custom SVM kernel?","<p>I'd like to implement my own Gaussian kernel in Python, just for exercise. I'm using:
<code>sklearn.svm.SVC(kernel=my_kernel)</code> but I really don't understand what is going on.</p>

<p>I expect the function my_kernel to be called with the columns of the <code>X</code> matrix as parameters, instead I got it called with <code>X</code>, <code>X</code> as arguments. Looking at the examples things are not clearer.</p>

<p>What am I missing?</p>

<p>This is my code:</p>

<pre><code>'''
Created on 15 Nov 2014

@author: Luigi
'''
import scipy.io
import numpy as np
from sklearn import svm
import matplotlib.pyplot as plt

def svm_class(fileName):

    data = scipy.io.loadmat(fileName)
    X = data['X']
    y = data['y']

    f = svm.SVC(kernel = 'rbf', gamma=50, C=1.0)
    f.fit(X,y.flatten())
    plotData(np.hstack((X,y)), X, f)

    return

def plotData(arr, X, f):

    ax = plt.subplot(111)

    ax.scatter(arr[arr[:,2]==0][:,0], arr[arr[:,2]==0][:,1], c='r', marker='o', label='Zero')
    ax.scatter(arr[arr[:,2]==1][:,0], arr[arr[:,2]==1][:,1], c='g', marker='+', label='One')

    h = .02  # step size in the mesh
    # create a mesh to plot in
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))


    # Plot the decision boundary. For that, we will assign a color to each
    # point in the mesh [x_min, m_max]x[y_min, y_max].
    Z = f.predict(np.c_[xx.ravel(), yy.ravel()])

    # Put the result into a color plot
    Z = Z.reshape(xx.shape)
    plt.contour(xx, yy, Z)



    plt.xlim(np.min(arr[:,0]), np.max(arr[:,0]))
    plt.ylim(np.min(arr[:,1]), np.max(arr[:,1]))
    plt.show()
    return


def gaussian_kernel(x1,x2):
    sigma = 0.5
    return np.exp(-np.sum((x1-x2)**2)/(2*sigma**2))

if __name__ == '__main__':

    fileName = 'ex6data2.mat'
    svm_class(fileName)
</code></pre>
"
"why does scikitlearn says F1 score is ill-defined with FN bigger than 0?","<p>I run a python program that calls <code>sklearn.metrics</code>'s methods to calculate precision and F1 score. Here is the output when there is no predicted sample:</p>

<pre><code>/xxx/py2-scikit-learn/0.15.2-comp6/lib/python2.6/site-packages/sklearn/metr\
ics/metrics.py:1771: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)

/xxx/py2-scikit-learn/0.15.2-comp6/lib/python2.6/site-packages/sklearn/metr\
ics/metrics.py:1771: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
</code></pre>

<p>When there is no predicted sample, it means that TP+FP is 0, so </p>

<ul>
<li>precision (defined as TP/(TP+FP)) is 0/0, not defined, </li>
<li>F1 score (defined as 2TP/(2TP+FP+FN)) is 0 if FN is not zero.</li>
</ul>

<p>In my case, <code>sklearn.metrics</code> also returns the accuracy as 0.8, and recall as 0. So FN is not zero.</p>

<p>But why does scikilearn says F1 is ill-defined?</p>

<p>What is the definition of F1 used by Scikilearn?</p>
"
"sklearn.ensemble.AdaBoostClassifier cannot accecpt SVM as base_estimator?","<p>I am doing a text classification task. Now I want to use <code>ensemble.AdaBoostClassifier</code> with <code>LinearSVC</code> as <code>base_estimator</code>. However, when I try to run the code </p>

<pre><code>clf = AdaBoostClassifier(svm.LinearSVC(),n_estimators=50, learning_rate=1.0,    algorithm='SAMME.R')
clf.fit(X, y)
</code></pre>

<p>An error occurred. <code>TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method</code></p>

<p><strong>The first question is</strong> Cannot the <code>svm.LinearSVC()</code> calculate the class probabilities ? How to make it calculate the probabilities?</p>

<p>Then I Change the parameter <code>algorithm</code> and run the code again.</p>

<pre><code>clf = AdaBoostClassifier(svm.LinearSVC(),n_estimators=50, learning_rate=1.0, algorithm='SAMME')
clf.fit(X, y)
</code></pre>

<p>This time <code>TypeError: fit() got an unexpected keyword argument 'sample_weight'</code> happens. As is said in <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier"" rel=""noreferrer"">AdaBoostClassifier</a>, <code>Sample weights. If None, the sample weights are initialized to 1 / n_samples.</code> Even if I assign an integer to <code>n_samples</code>, error also occurred. </p>

<p><strong>The second question is</strong> What does <code>n_samples</code> mean? How to solve this problem? </p>

<p>Hope anyone could help me.</p>

<p>According to @jme 's comment, however, after trying</p>

<pre><code>clf = AdaBoostClassifier(svm.SVC(kernel='linear',probability=True),n_estimators=10,  learning_rate=1.0, algorithm='SAMME.R')
clf.fit(X, y)
</code></pre>

<p>The program cannot get a result and the memory used on the server keeps unchanged.</p>

<p><strong>The third question is</strong> how I can make <code>AdaBoostClassifier</code> work with <code>SVC</code> as base_estimator?</p>
"
"sklearn plot confusion matrix with labels","<p>I want to plot a confusion matrix to visualize the classifer's performance, but it shows only the numbers of the labels, not the labels themselves:</p>

<pre><code>from sklearn.metrics import confusion_matrix
import pylab as pl
y_test=['business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business']

pred=array(['health', 'business', 'business', 'business', 'business',
       'business', 'health', 'health', 'business', 'business', 'business',
       'business', 'business', 'business', 'business', 'business',
       'health', 'health', 'business', 'health'], 
      dtype='|S8')

cm = confusion_matrix(y_test, pred)
pl.matshow(cm)
pl.title('Confusion matrix of the classifier')
pl.colorbar()
pl.show()
</code></pre>

<p>How can I add the labels (health, business..etc) to the confusion matrix?</p>
"
"How to avoid one Spark Streaming window blocking another window with both running some native Python code","<p>I'm running Spark Streaming with two different windows (on window for training a model with SKLearn and the other for predicting values based on that model) and I'm wondering how I can avoid one window (the ""slow"" training window) to train a model, without ""blocking"" the ""fast"" prediction window.<br>
My simplified code looks as follows:</p>

<pre><code>conf = SparkConf()
conf.setMaster(""local[4]"")
sc = SparkContext(conf=conf)
ssc = StreamingContext(sc, 1)

stream = ssc.socketTextStream(""localhost"", 7000)


import Custom_ModelContainer

### Window 1 ###
### predict data based on model computed in window 2 ###

def predict(time, rdd):
    try:
       # ... rdd conversion to df, feature extraction etc...

       # regular python code 
       X = np.array(df.map(lambda lp: lp.features.toArray()).collect())
       pred = Custom_ModelContainer.getmodel().predict(X)

       # send prediction to GUI

    except Exception, e: print e

predictionStream = stream.window(60,60)
predictionStream.foreachRDD(predict)


### Window 2 ###
### fit new model ###

def trainModel(time, rdd):
try:
    # ... rdd conversion to df, feature extraction etc...

    X = np.array(df.map(lambda lp: lp.features.toArray()).collect())
    y = np.array(df.map(lambda lp: lp.label).collect())

    # train test split etc...

    model = SVR().fit(X_train, y_train)
    Custom_ModelContainer.setModel(model)

except Exception, e: print e

modelTrainingStream = stream.window(600,600)
modelTrainingStream.foreachRDD(trainModel)
</code></pre>

<p>(Note: The Custom_ModelContainer is a class I wrote to save and retrieve the trained model)</p>

<p>My setup generally works fine, with the exception that every time a new model is trained in the second window (which takes about a minute), the first windows does not compute predictions until model training is finished. Actually, I guess that this makes sense, since model fitting and predictions are both computed on the master node (in a non-distributed setting - due to SKLearn).</p>

<p>So my question is the following: Would it be possible to train the model on a single worker node (instead of the master node)? If so, how could I achieve the latter and would that actually resolve my issue?</p>

<p>If not, any other suggestion on how I could make such a setup work without delaying computations in window 1?</p>

<p>Any help is greatly appreciated.</p>

<p>EDIT: I guess the more general question would be:
How can I run two different task on two different workers in parallel?</p>
"
"scikit-learn: One hot encoding of string categorical features","<p>I'm trying to perform a one hot encoding of a trivial dataset. </p>

<pre><code>data = [['a', 'dog', 'red']
        ['b', 'cat', 'green']]
</code></pre>

<p>What's the best way to preprocess this data using Scikit-Learn?</p>

<p>On first instinct, you'd look towards Scikit-Learn's <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder"" rel=""noreferrer"">OneHotEncoder</a>. But the one hot encoder doesn't support strings as features; it only discretizes integers.</p>

<p>So then you would use a <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"" rel=""noreferrer"">LabelEncoder</a>, which would encode the strings into integers. But then you have to apply the label encoder into each of the columns and store each one of these label encoders (as well as the columns they were applied on). And this feels extremely clunky.</p>

<p>So, what's the <strong>best</strong> way to do it in Scikit-Learn?</p>

<p>Please don't suggest <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html"" rel=""noreferrer"">pandas.get_dummies</a>. That's what I generally use nowadays for one hot encodings. However, its limited in the fact that you can't encode your training / test set separately.</p>
"
"Web application that uses scikit-learn","<p>I have locally trained a <a href=""http://scikits.appspot.com/scikit-learn"">sklearn</a> classifier and I have to create a simple web application that demonstrate its use. I'm a complete noob on web app development and I don't want to waste hours on creating a web app using a framework that doesn't support the modules I'm using. </p>

<ol>
<li>What do you suggest would be a good approach for this task?</li>
<li>What web app development framework should I use (if any)?</li>
<li>Do I have to dive into things like <code>Heoku</code> , <code>django</code> etc. or is there more simple and quicker solutions for a simple scientific demo?</li>
</ol>

<p>My thought was to take the classifier I trained, pickle it and un-pickle it on the server, then to run <code>classify</code> from the server, but I'm not sure where to begin.</p>
"
"Distinguishing overfitting vs good prediction","<p>These are questions on how to calculate &amp; reduce overfitting in machine learning. I think many new to machine learning will have the same questions, so I tried to be clear with my examples and questions in hope that answers here can help others.</p>

<p>I have a very small sample of texts and I'm trying to predict values associated with them. I've used sklearn to calculate tf-idf, and insert those into a regression model for prediction. This gives me 26 samples with 6323 features - not a lot.. I know:</p>

<pre><code>&gt;&gt; count_vectorizer = CountVectorizer(min_n=1, max_n=1)
&gt;&gt; term_freq = count_vectorizer.fit_transform(texts)
&gt;&gt; transformer = TfidfTransformer()
&gt;&gt; X = transformer.fit_transform(term_freq) 
&gt;&gt; print X.shape

(26, 6323)
</code></pre>

<p>Inserting those 26 samples of 6323 features (X) and associated scores (y), into a <code>LinearRegression</code> model, gives good predictions. These are obtained using leave-one-out cross validation, from <code>cross_validation.LeaveOneOut(X.shape[0], indices=True)</code> :</p>

<pre><code>using ngrams (n=1):
     human  machine  points-off  %error
      8.67    8.27    0.40       1.98
      8.00    7.33    0.67       3.34
      ...     ...     ...        ...
      5.00    6.61    1.61       8.06
      9.00    7.50    1.50       7.50
mean: 7.59    7.64    1.29       6.47
std : 1.94    0.56    1.38       6.91
</code></pre>

<p>Pretty good! Using ngrams (n=300) instead of unigrams (n=1), similar results occur, which is obviously not right. No 300-words occur in any of the texts, so the prediction should fail, but it doesn't:</p>

<pre><code>using ngrams (n=300):
      human  machine  points-off  %error
       8.67    7.55    1.12       5.60
       8.00    7.57    0.43       2.13
       ...     ...     ...        ...
mean:  7.59    7.59    1.52       7.59
std :  1.94    0.08    1.32       6.61
</code></pre>

<p><em><strong>Question 1:</em></strong> This might mean that the prediction model is <strong>overfitting</strong> the data. I only know this because I chose an extreme value for the ngrams (n=300) which I KNOW can't produce good results. But if I didn't have this knowledge, how would you normally tell that the model is over-fitting? In other words, if a reasonable measure (n=1) were used, how would you know that the good prediction was a result of being overfit vs. the model just working well?</p>

<p><em><strong>Question 2:</em></strong> What is the best way of preventing over-fitting (in this situation) to be sure that the prediction results are good or not? </p>

<p><em><strong>Question 3:</em></strong> If <code>LeaveOneOut</code> cross validation is used, how can the model possibly over-fit with good results? Over-fitting means the prediction accuracy will suffer - so why doesn't it suffer on the prediction for the text being left out? The only reason I can think of: in a tf-idf sparse matrix of mainly 0s, there is strong overlap between texts because so many terms are 0s - the regression then thinks the texts correlate highly.</p>

<p>Please answer any of the questions even if you don't know them all. Thanks! </p>
"
"How is Elastic Net used?","<p>This is a beginner question on regularization with regression. Most information about Elastic Net and Lasso Regression online replicates the information from Wikipedia or the original 2005 paper by Zou and Hastie (Regularization and variable selection via the elastic net). </p>

<p><strong><em>Resource for simple theory?</em></strong> Is there a simple and easy explanation somewhere about what it does, when and why reguarization is neccessary, and how to use it - for those who are not statistically inclined? I understand that the original paper is the ideal source if you can understand it, but is there somewhere that more simply the problem and solution?</p>

<p><strong><em>How to use in sklearn?</em></strong> Is there a step by step example showing why elastic net is chosen (over ridge, lasso, or just simple OLS) and how the parameters are calculated? Many of the <a href=""http://scikit-learn.org/0.11/auto_examples/index.html"" rel=""noreferrer"">examples on sklearn</a> just include alpha and rho parameters directly into the prediction model, for <a href=""http://scikit-learn.org/0.11/auto_examples/linear_model/plot_lasso_and_elasticnet.html"" rel=""noreferrer"">example</a>:</p>

<pre><code>from sklearn.linear_model import ElasticNet
alpha = 0.1
enet = ElasticNet(alpha=alpha, rho=0.7)
y_pred_enet = enet.fit(X_train, y_train).predict(X_test)
</code></pre>

<p>However, they don't explain how these were calculated. How do you calculate the parameters for the lasso or net?</p>
"
"scikit-learn: Finding the features that contribute to each KMeans cluster","<p>Say you have 10 features you are using to create 3 clusters. Is there a way to see the level of contribution each of the features have for each of the clusters?</p>

<p>What I want to be able to say is that for cluster k1, features 1,4,6 were the primary features where as cluster k2's primary features were 2,5,7.</p>

<p>This is the basic setup of what I am using:</p>

<pre class=""lang-py prettyprint-override""><code>k_means = KMeans(init='k-means++', n_clusters=3, n_init=10)
k_means.fit(data_features)
k_means_labels = k_means.labels_
</code></pre>
"
"A progress bar for scikit-learn?","<p>Is there any way to have a progress bar to the fit method in scikit-learn ? </p>

<p>Is it possible to include a custom one with something like <a href=""https://github.com/rasbt/pyprind"" rel=""noreferrer"">Pyprind</a> ?</p>
"
"In scikit learn, how to deal with the data mixed with numerical and nominal value?","<p>I know that the computation in scikit-learn is based on NumPy so everything is a matrix or array.</p>

<p>How does this package handle mixed data (numerical and nominal values)?</p>

<p>For example, a product could have the attribute 'color' and 'price', where color is nominal and price is numerical. I notice there is a model called 'DictVectorizer' to numerate the nominal data. For example, two products  are:</p>

<pre><code>products = [{'color':'black','price':10}, {'color':'green','price':5}]
</code></pre>

<p>And the result from 'DictVectorizer' could be:</p>

<pre><code>[[1,0,10],
 [0,1,5]]
</code></pre>

<p>If there are lots of different values for the attribute 'color', the matrix would be very sparse. And long features will degrade the performance of some algorithms, such as decision trees. </p>

<p><strong>Is there any way to use the nominal value without the need to create dummy codes?</strong></p>
"
"Scikit and Pandas: Fitting Large Data","<p><strong>How do I use scikit-learn to train a model on a large csv data (~75MB) without running into memory problems?</strong></p>

<p>I'm using IPython notebook as the programming environment, and pandas+sklearn packages to analyze data from kaggle's digit recognizer tutorial.</p>

<p>The data is available on the <a href=""http://www.kaggle.com/c/digit-recognizer/data"" rel=""nofollow noreferrer"">webpage</a> , link to <a href=""http://pastie.org/4351884"" rel=""nofollow noreferrer"">my code</a> , and here is the <a href=""http://pastie.org/4351918"" rel=""nofollow noreferrer"">error message</a>: </p>

<p><code>KNeighborsClassifier</code> is used for the prediction.</p>

<p><strong>Problem:</strong></p>

<blockquote>
  <p>""MemoryError"" occurs when loading large dataset using read_csv
  function. To bypass this problem temporarily, I have to restart the
  kernel, which then read_csv function successfully loads the file, but
  the same error occurs when I run the same cell again.</p>
</blockquote>

<p>When the <code>read_csv</code> function loads the file successfully, after making changes to the <code>dataframe</code>, I can pass the features and labels to the KNeighborsClassifier's fit() function. At this point, similar memory error occurs.</p>

<p><strong>I tried the following:</strong></p>

<p>Iterate through the CSV file in chunks, and fit the data accordingly, but the problem is that the predictive model is overwritten every time for a chunk of data.</p>

<p><strong>What do you think I can do to successfully train my model without running into memory problems?</strong></p>
"
"What does `sample_weight` do to the way a `DecisionTreeClassifier` works in sklearn?","<p>I've read from <a href=""http://scikit-learn.org/stable/modules/tree.html#classification"" rel=""noreferrer"">this documentation</a> that :  </p>

<p>""Class balancing can be done by sampling an equal number of samples from each class, or preferably by normalizing the sum of the sample weights (sample_weight) for each class to the same value."" </p>

<p>But, it is still unclear to me how this works.  If I set <code>sample_weight</code> with an array of only two possible values, <code>1</code>'s and <code>2</code>'s, does this mean that the samples with <code>2</code>'s will get sampled twice as often as the samples with <code>1</code>'s when doing the bagging?  I cannot think of a practical example for this.  </p>
"
"Python List of Ngrams with frequencies","<p>I need to get most popular ngrams from text. Ngrams length must be from 1 to 5 words. </p>

<p>I know how to get bigrams and trigrams. For example:</p>

<pre><code>bigram_measures = nltk.collocations.BigramAssocMeasures()
finder = nltk.collocations.BigramCollocationFinder.from_words(words)
finder.apply_freq_filter(3)
finder.apply_word_filter(filter_stops)
matches1 = finder.nbest(bigram_measures.pmi, 20)
</code></pre>

<p>However, i found out that scikit-learn can get ngrams with various length. For example I can get ngrams with length from 1 to 5.</p>

<pre><code>v = CountVectorizer(analyzer=WordNGramAnalyzer(min_n=1, max_n=5))
</code></pre>

<p>But WordNGramAnalyzer is now deprecated. My question is: <em>How can i get N best word collocations from my text, with collocations length from 1 to 5. Also i need to get FreqList of this collocations/ngrams.</em></p>

<p>Can i do that with nltk/scikit ? I need to get combinations of ngrams with various lengths from one text ? </p>

<p>For example using NLTK bigrams and trigrams where many situations in which my trigrams include my bitgrams, or my trigrams are part of bigger 4-grams. For example:</p>

<p>bitgrams: <strong>hello my</strong>
trigrams: <strong>hello my name</strong></p>

<p>I know how to exclude bigrams from trigrams, but i need better solutions.</p>
"
"How to allow sklearn K Nearest Neighbors to take custom distance metric?","<p>I have a custom distance metric that I need to use for <code>KNN</code>, <code>K Nearest Neighbors</code>.  </p>

<p>I tried following <a href=""https://stackoverflow.com/questions/21052509/sklearn-knn-usage-with-a-user-defined-metric"">this</a>, but I cannot get it to work for some reason.  </p>

<p>I would assume that the distance metric is supposed to take two vectors/arrays of the same length, as I have written below:</p>

<pre><code>import sklearn 
from sklearn.neighbors import NearestNeighbors
import numpy as np
import pandas as pd

def d(a,b,L):
    # Inputs: a and b are rows from a data matrix   
    return a+b+2+L

knn=NearestNeighbors(n_neighbors=1,
                 algorithm='auto',
                 metric='pyfunc',
                 func=lambda a,b: d(a,b,L)
                 )


X=pd.DataFrame({'b':[0,3,2],'c':[1.0,4.3,2.2]})
knn.fit(X)
</code></pre>

<p>However, when I call: <code>knn.kneighbors()</code>, it doesn't seem to like the custom function.  Here is the bottom of the error stack:</p>

<pre><code>ValueError: Unknown metric pyfunc. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski'], or 'precomputed', or a callable
</code></pre>

<p>However, I see the exact same in the question I cited.  Any ideas on how to make this work on <code>sklearn version 0.14</code>?  I'm not aware of any differences in the versions.  </p>

<p>Thanks.</p>
"
"Simple example using BernoulliNB (naive bayes classifier) scikit-learn in python - cannot explain classification","<p>Using scikit-learn 0.10</p>

<p>Why does the following trivial code snippet:</p>

<pre><code>from sklearn.naive_bayes import *

import sklearn
from sklearn.naive_bayes import *

print sklearn.__version__

X = np.array([ [1, 1, 1, 1, 1], 
               [0, 0, 0, 0, 0] ])
print ""X: "", X
Y = np.array([ 1, 2 ])
print ""Y: "", Y

clf = BernoulliNB()
clf.fit(X, Y)
print ""Prediction:"", clf.predict( [0, 0, 0, 0, 0] )    
</code></pre>

<p>Print out an answer of ""1"" ?  Having trained the model on [0,0,0,0,0] => 2 I was expecting ""2"" as the answer.</p>

<p>And why does replacing Y with</p>

<pre><code>Y = np.array([ 3, 2 ])
</code></pre>

<p>Give a different class ""2"" as an answer (the correct one) ?  Isn't this just a class label?</p>

<p>Can someone shed some light on this?</p>
"
"What does clf mean in machine learning?","<p>When doing fitting, I always come across code like</p>

<pre><code>clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
</code></pre>

<p>(from <a href=""http://scikit-learn.org/stable/modules/cross_validation.html#k-fold"">http://scikit-learn.org/stable/modules/cross_validation.html#k-fold</a>)</p>

<p>What does <code>clf</code> stands for? I googled around but didn't find any clues.</p>
"
"How to get most informative features for scikit-learn classifiers?","<p>The classifiers in machine learning packages like liblinear and nltk offer a method <code>show_most_informative_features()</code>, which is really helpful for debugging features:</p>

<pre><code>viagra = None          ok : spam     =      4.5 : 1.0
hello = True           ok : spam     =      4.5 : 1.0
hello = None           spam : ok     =      3.3 : 1.0
viagra = True          spam : ok     =      3.3 : 1.0
casino = True          spam : ok     =      2.0 : 1.0
casino = None          ok : spam     =      1.5 : 1.0
</code></pre>

<p>My question is if something similar is implemented for the classifiers in scikit-learn. I searched the documentation, but couldn't find anything the like.</p>

<p>If there is no such function yet, does somebody know a workaround how to get to those values?</p>

<p>Thanks alot!</p>
"
"Combining text stemming and removal of punctuation in NLTK and scikit-learn","<p>I am using a combination of NLTK and <code>scikit-learn</code>'s <code>CountVectorizer</code> for stemming words and tokenization.</p>

<p>Below is an example of the plain usage of the <code>CountVectorizer</code>:</p>

<pre><code>from sklearn.feature_extraction.text import CountVectorizer

vocab = ['The swimmer likes swimming so he swims.']
vec = CountVectorizer().fit(vocab)

sentence1 = vec.transform(['The swimmer likes swimming.'])
sentence2 = vec.transform(['The swimmer swims.'])

print('Vocabulary: %s' %vec.get_feature_names())
print('Sentence 1: %s' %sentence1.toarray())
print('Sentence 2: %s' %sentence2.toarray())
</code></pre>

<p>Which will print</p>

<pre><code>Vocabulary: ['he', 'likes', 'so', 'swimmer', 'swimming', 'swims', 'the']
Sentence 1: [[0 1 0 1 1 0 1]]
Sentence 2: [[0 0 0 1 0 1 1]]
</code></pre>

<p>Now, let's say I want to remove stop words and stem the words. One option would be to do it like so:</p>

<pre><code>from nltk import word_tokenize          
from nltk.stem.porter import PorterStemmer

#######
# based on http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html
stemmer = PorterStemmer()
def stem_tokens(tokens, stemmer):
    stemmed = []
    for item in tokens:
        stemmed.append(stemmer.stem(item))
    return stemmed

def tokenize(text):
    tokens = nltk.word_tokenize(text)
    stems = stem_tokens(tokens, stemmer)
    return stems
######## 

vect = CountVectorizer(tokenizer=tokenize, stop_words='english') 

vect.fit(vocab)

sentence1 = vect.transform(['The swimmer likes swimming.'])
sentence2 = vect.transform(['The swimmer swims.'])

print('Vocabulary: %s' %vect.get_feature_names())
print('Sentence 1: %s' %sentence1.toarray())
print('Sentence 2: %s' %sentence2.toarray())
</code></pre>

<p>Which prints:</p>

<pre><code>Vocabulary: ['.', 'like', 'swim', 'swimmer']
Sentence 1: [[1 1 1 1]]
Sentence 2: [[1 0 1 1]]
</code></pre>

<p>But how would I best get rid of the punctuation characters in this second version?</p>
"
"sklearn agglomerative clustering linkage matrix","<p>I'm trying to draw a complete-link <a href=""http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html""><code>scipy.cluster.hierarchy.dendrogram</code></a>, and I found that <a href=""http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.linkage.html""><code>scipy.cluster.hierarchy.linkage</code></a> is slower than <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html""><code>sklearn.AgglomerativeClustering</code></a>.</p>

<p>However, <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html""><code>sklearn.AgglomerativeClustering</code></a> doesn't return the distance between clusters and the number of original observations, which <code>scipy.cluster.hierarchy.dendrogram</code> needs. Is there a way to take them?</p>
"
"Cross Validation and Grid Search","<p>Is there someone who can explain me in really simple words what's the difference between cross validation and grid search? How does it work and should I do first a cross validation and then a grid search?</p>

<p>My question comes from reading this doc: <a href=""http://scikit-learn.org/dev/auto_examples/grid_search_digits.html"" rel=""nofollow noreferrer"">sklearn</a></p>
"
"TypeError: only integer arrays with one element can be converted to an index","<p>I'm getting the following error when performing recursive feature selection with cross-validation:</p>

<pre><code>Traceback (most recent call last):
  File ""/Users/.../srl/main.py"", line 32, in &lt;module&gt;
    argident_sys.train_classifier()
  File ""/Users/.../srl/identification.py"", line 194, in train_classifier
    feat_selector.fit(train_argcands_feats,train_argcands_target)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/feature_selection/rfe.py"", line 298, in fit
    ranking_ = rfe.fit(X[train], y[train]).ranking_
TypeError: only integer arrays with one element can be converted to an index
</code></pre>

<p>The code that generates the error is the following:</p>

<pre><code>def train_classifier(self):

    # Get the argument candidates
    argcands = self.get_argcands(self.reader)

    # Extract the necessary features from the argument candidates
    train_argcands_feats = []
    train_argcands_target = []

    for argcand in argcands:
        train_argcands_feats.append(self.extract_features(argcand))
        if argcand[""info""][""label""] == ""NULL"":
            train_argcands_target.append(""NULL"")
        else:
            train_argcands_target.append(""ARG"")

    # Transform the features to the format required by the classifier
    self.feat_vectorizer = DictVectorizer()
    train_argcands_feats = self.feat_vectorizer.fit_transform(train_argcands_feats)

    # Transform the target labels to the format required by the classifier
    self.target_names = list(set(train_argcands_target))
    train_argcands_target = [self.target_names.index(target) for target in train_argcands_target]

    ## Train the appropriate supervised model      

    # Recursive Feature Elimination
    self.classifier = LogisticRegression()
    feat_selector = RFECV(estimator=self.classifier, step=1, cv=StratifiedKFold(train_argcands_target, 10))

    feat_selector.fit(train_argcands_feats,train_argcands_target)

    print feat_selector.n_features_
    print feat_selector.support_
    print feat_selector.ranking_
    print feat_selector.cv_scores_

    return
</code></pre>

<p>I know I should also perform GridSearch for the parameters of the LogisticRegression classifier, but I don't think that's the source of the error (or is it?). </p>

<p>I should mention that I'm testing with around 50 features, and almost all of them are categoric (that's why I use the DictVectorizer to transform them appropriately). </p>

<p>Any help or guidance you could give me is more than welcome. Thanks!</p>

<p><strong>EDIT</strong></p>

<p>Here's some training data examples:</p>

<pre><code>train_argcands_feats = [{'head_lemma': u'Bras\xedlia', 'head': u'Bras\xedlia', 'head_postag': u'PROP'}, {'head_lemma': u'Pesquisa_Datafolha', 'head': u'Pesquisa_Datafolha', 'head_postag': u'N'}, {'head_lemma': u'dado', 'head': u'dado', 'head_postag': u'N'}, {'head_lemma': u'postura', 'head': u'postura', 'head_postag': u'N'}, {'head_lemma': u'maioria', 'head': u'maioria', 'head_postag': u'N'}, {'head_lemma': u'querer', 'head': u'quer', 'head_postag': u'V-FIN'}, {'head_lemma': u'PT', 'head': u'PT', 'head_postag': u'PROP'}, {'head_lemma': u'participar', 'head': u'participando', 'head_postag': u'V-GER'}, {'head_lemma': u'surpreendente', 'head': u'supreendente', 'head_postag': u'ADJ'}, {'head_lemma': u'Bras\xedlia', 'head': u'Bras\xedlia', 'head_postag': u'PROP'}, {'head_lemma': u'Pesquisa_Datafolha', 'head': u'Pesquisa_Datafolha', 'head_postag': u'N'}, {'head_lemma': u'revelar', 'head': u'revela', 'head_postag': u'V-FIN'}, {'head_lemma': u'recusar', 'head': u'recusando', 'head_postag': u'V-GER'}, {'head_lemma': u'maioria', 'head': u'maioria', 'head_postag': u'N'}, {'head_lemma': u'PT', 'head': u'PT', 'head_postag': u'PROP'}, {'head_lemma': u'participar', 'head': u'participando', 'head_postag': u'V-GER'}, {'head_lemma': u'surpreendente', 'head': u'supreendente', 'head_postag': u'ADJ'}, {'head_lemma': u'Bras\xedlia', 'head': u'Bras\xedlia', 'head_postag': u'PROP'}, {'head_lemma': u'Pesquisa_Datafolha', 'head': u'Pesquisa_Datafolha', 'head_postag': u'N'}, {'head_lemma': u'revelar', 'head': u'revela', 'head_postag': u'V-FIN'}, {'head_lemma': u'governo', 'head': u'Governo', 'head_postag': u'N'}, {'head_lemma': u'de', 'head': u'de', 'head_postag': u'PRP'}, {'head_lemma': u'governo', 'head': u'Governo', 'head_postag': u'N'}, {'head_lemma': u'recusar', 'head': u'recusando', 'head_postag': u'V-GER'}, {'head_lemma': u'maioria', 'head': u'maioria', 'head_postag': u'N'}, {'head_lemma': u'querer', 'head': u'quer', 'head_postag': u'V-FIN'}, {'head_lemma': u'PT', 'head': u'PT', 'head_postag': u'PROP'}, {'head_lemma': u'surpreendente', 'head': u'supreendente', 'head_postag': u'ADJ'}, {'head_lemma': u'Bras\xedlia', 'head': u'Bras\xedlia', 'head_postag': u'PROP'}, {'head_lemma': u'Pesquisa_Datafolha', 'head': u'Pesquisa_Datafolha', 'head_postag': u'N'}, {'head_lemma': u'revelar', 'head': u'revela', 'head_postag': u'V-FIN'}, {'head_lemma': u'muito', 'head': u'Muitas', 'head_postag': u'PRON-DET'}, {'head_lemma': u'prioridade', 'head': u'prioridades', 'head_postag': u'N'}, {'head_lemma': u'com', 'head': u'com', 'head_postag': u'PRP'}, {'head_lemma': u'prioridade', 'head': u'prioridades', 'head_postag': u'N'}]

train_argcands_target = ['NULL', 'ARG', 'ARG', 'ARG', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'ARG', 'ARG', 'ARG', 'ARG', 'NULL', 'NULL', 'NULL', 'NULL', 'ARG', 'NULL', 'NULL', 'NULL', 'NULL', 'NULL', 'ARG', 'NULL', 'NULL', 'NULL', 'NULL', 'ARG', 'ARG', 'NULL', 'NULL']
</code></pre>
"
"Possibility to apply online algorithms on big data files with sklearn?","<p>I would like to apply fast online dimensionality reduction techniques such as (online/mini-batch) Dictionary Learning on big text corpora.
My input data naturally do not fit in the memory (this is why i want to use an online algorithm) so i am looking for an implementation that can iterate over a file rather than loading everything in memory.
Is it possible to do this with sklearn ? are there alternatives ?</p>

<p>Thanks
register</p>
"
"scikit-learn - ROC curve with confidence intervals","<p>I am able to get a ROC curve using <code>scikit-learn</code> with
<code>fpr</code>, <code>tpr</code>, <code>thresholds = metrics.roc_curve(y_true,y_pred, pos_label=1)</code>, where <code>y_true</code> is a list of values based on my gold standard (i.e., <code>0</code> for negative and <code>1</code> for positive cases) and <code>y_pred</code> is a corresponding list of scores (e.g., <code>0.053497243</code>, <code>0.008521122</code>, <code>0.022781548</code>, <code>0.101885263</code>, <code>0.012913795</code>, <code>0.0</code>, <code>0.042881547</code> [...])</p>

<p>I am trying to figure out how to add confidence intervals to that curve, but didn't find any easy way to do that with sklearn.</p>
"
"What to do first: Feature Selection or Model Parameters Setting?","<p>This is more of a ""theoretical"" question. I'm working with the scikit-learn package to perform some NLP task. Sklearn provides many methods to perform both feature selection and setting of a model parameters. I'm wondering what I should do first.</p>

<p>If I use <a href=""http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection"">univariate feature selection</a>, it's pretty obvious that I should do feature selection first and, with the selected features, I then tunne the parameters of the estimator. </p>

<p>But what if I want to use <a href=""http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination"">recursive feature elimination</a>? Should I first set the parameters with <a href=""http://scikit-learn.org/stable/modules/grid_search.html"">grid search</a> using ALL the original features and just then perform feature selection? Or perhaps I should select the features first (with the estimator's default parameters) and then set the parameters with the selected features?</p>

<p>Thanks in advance for any help you could give me.</p>

<p><strong>EDIT</strong></p>

<p>I'm having pretty much the same problem stated <a href=""http://www.mail-archive.com/scikit-learn-general@lists.sourceforge.net/msg02355.html"">here</a>. By that time, there wasn't a solution to it. Does anyone know if it exists one now?</p>
"
"Sklearn How to Save a Model Created From a Pipeline and GridSearchCV Using Joblib or Pickle?","<p>After identifying the best parameters using a <code>pipeline</code> and <code>GridSearchCV</code>, how do I <code>pickle</code>/<code>joblib</code> this process to re-use later? I see how to do this when it's a single classifier...</p>

<pre><code>from sklearn.externals import joblib
joblib.dump(clf, 'filename.pkl') 
</code></pre>

<p>But how do I save this overall <code>pipeline</code> with the best parameters after performing and completing a <code>gridsearch</code>?</p>

<p>I tried:</p>

<ul>
<li><code>joblib.dump(grid, 'output.pkl')</code> - But that dumped every gridsearch
attempt (many files)</li>
<li><code>joblib.dump(pipeline, 'output.pkl')</code> - But I
don't think that contains the best parameters</li>
</ul>

<hr>

<pre><code>X_train = df['Keyword']
y_train = df['Ad Group']

pipeline = Pipeline([
  ('tfidf', TfidfVectorizer()),
  ('sgd', SGDClassifier())
  ])

parameters = {'tfidf__ngram_range': [(1, 1), (1, 2)],
              'tfidf__use_idf': (True, False),
              'tfidf__max_df': [0.25, 0.5, 0.75, 1.0],
              'tfidf__max_features': [10, 50, 100, 250, 500, 1000, None],
              'tfidf__stop_words': ('english', None),
              'tfidf__smooth_idf': (True, False),
              'tfidf__norm': ('l1', 'l2', None),
              }

grid = GridSearchCV(pipeline, parameters, cv=2, verbose=1)
grid.fit(X_train, y_train)

#These were the best combination of tuning parameters discovered
##best_params = {'tfidf__max_features': None, 'tfidf__use_idf': False,
##               'tfidf__smooth_idf': False, 'tfidf__ngram_range': (1, 2),
##               'tfidf__max_df': 1.0, 'tfidf__stop_words': 'english',
##               'tfidf__norm': 'l2'}
</code></pre>
"
"AdaBoostClassifier with different base learners","<p>I am trying to use AdaBoostClassifier with a base learner other than DecisionTree. I have tried SVM and KNeighborsClassifier but I get errors. Can some one point out the classifiers that can be used with AdaBoostClassifier?</p>
"
"Why is pydot unable to find GraphViz's executables in Windows 8?","<p>I have GraphViz 2.32 installed in Windows 8 and have added C:\Program Files (x86)\Graphviz2.32\bin to the System PATH variable. Still pydot is unable to find its executables.</p>

<pre><code>Traceback (most recent call last):
  File ""&lt;pyshell#26&gt;"", line 1, in &lt;module&gt;
    graph.write_png('example1_graph.png')
  File ""build\bdist.win32\egg\pydot.py"", line 1809, in &lt;lambda&gt;
    lambda path, f=frmt, prog=self.prog : self.write(path, format=f, prog=prog))
  File ""build\bdist.win32\egg\pydot.py"", line 1911, in write
    dot_fd.write(self.create(prog, format))
  File ""build\bdist.win32\egg\pydot.py"", line 1953, in create
    'GraphViz\'s executables not found' )
InvocationException: GraphViz's executables not found
</code></pre>

<p>I found this <a href=""https://code.google.com/p/pydot/issues/detail?id=65"" rel=""noreferrer"">https://code.google.com/p/pydot/issues/detail?id=65</a> but am unable to get the problem solved.</p>
"
"Is it possible to specify your own distance function using scikit-learn K-Means Clustering?","<p>Is it possible to specify your own distance function using scikit-learn K-Means Clustering?</p>
"
"SciPy and scikit-learn - ValueError: Dimension mismatch","<p>I use <a href=""http://scipy.org/"">SciPy</a> and <a href=""http://scikit-learn.org/stable/"">scikit-learn</a> to train and apply a Multinomial Naive Bayes Classifier for binary text classification. Precisely, I use the module <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer""><code>sklearn.feature_extraction.text.CountVectorizer</code></a> for creating sparse matrices that hold word feature counts from text and the module <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB""><code>sklearn.naive_bayes.MultinomialNB</code></a> as the classifier implementation for training the classifier on training data and applying it on test data.</p>

<p>The input to the <code>CountVectorizer</code> is a list of text documents represented as unicode strings. The training data is much larger than the test data. My code looks like this (simplified):</p>

<pre><code>vectorizer = CountVectorizer(**kwargs)

# sparse matrix with training data
X_train = vectorizer.fit_transform(list_of_documents_for_training)

# vector holding target values (=classes, either -1 or 1) for training documents
# this vector has the same number of elements as the list of documents
y_train = numpy.array([1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, ...])

# sparse matrix with test data
X_test = vectorizer.fit_transform(list_of_documents_for_testing)

# Training stage of NB classifier
classifier = MultinomialNB()
classifier.fit(X=X_train, y=y_train)

# Prediction of log probabilities on test data
X_log_proba = classifier.predict_log_proba(X_test)
</code></pre>

<p><strong>Problem:</strong> As soon as <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.predict_log_proba""><code>MultinomialNB.predict_log_proba()</code></a> is called, I get <code>ValueError: dimension mismatch</code>. According to the IPython stacktrace below, the error occurs in SciPy:</p>

<pre><code>/path/to/my/code.pyc
--&gt; 177         X_log_proba = classifier.predict_log_proba(X_test)

/.../sklearn/naive_bayes.pyc in predict_log_proba(self, X)
    76             in the model, where classes are ordered arithmetically.
    77         """"""
--&gt; 78         jll = self._joint_log_likelihood(X)
    79         # normalize by P(x) = P(f_1, ..., f_n)
    80         log_prob_x = logsumexp(jll, axis=1)

/.../sklearn/naive_bayes.pyc in _joint_log_likelihood(self, X)
    345         """"""Calculate the posterior log probability of the samples X""""""
    346         X = atleast2d_or_csr(X)
--&gt; 347         return (safe_sparse_dot(X, self.feature_log_prob_.T)
    348                + self.class_log_prior_)
    349 

/.../sklearn/utils/extmath.pyc in safe_sparse_dot(a, b, dense_output)
    71     from scipy import sparse
    72     if sparse.issparse(a) or sparse.issparse(b):
--&gt; 73         ret = a * b
    74         if dense_output and hasattr(ret, ""toarray""):
    75             ret = ret.toarray()

/.../scipy/sparse/base.pyc in __mul__(self, other)
    276 
    277             if other.shape[0] != self.shape[1]:
--&gt; 278                 raise ValueError('dimension mismatch')
    279 
    280             result = self._mul_multivector(np.asarray(other))
</code></pre>

<p>I have no idea why this error occurs. Can anybody please explain it to me and provide a solution for this problem? Thanks a lot in advance!</p>
"
"Best Machine Learning package for Python 3x?","<p>I was bummed out to see that scikit-learn does not support Python 3...Is there a comparable package anyone can recommend for Python 3?</p>
"
"TF*IDF for Search Queries","<p>Okay, so I have been following these two posts on TF*IDF but am little confused : <a href=""http://css.dzone.com/articles/machine-learning-text-feature"">http://css.dzone.com/articles/machine-learning-text-feature</a></p>

<p>Basically, I want to create a search query that contains searches through multiple documents. I would like to use the scikit-learn toolkit as well as the NLTK library for Python</p>

<p>The problem is that I don't see where the two TF*IDF vectors come from. I need one search query and multiple documents to search. I figured that I calculate the TF*IDF scores of each document against each query and find the cosine similarity between them, and then rank them by sorting the scores in descending order. However, the code doesn't seem to come up with the right vectors.</p>

<p>Whenever I reduce the query to only one search, it is returning a huge list of 0's which is really strange. </p>

<p><strong>Here is the code:</strong></p>

<pre><code>from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from nltk.corpus import stopwords

train_set = (""The sky is blue."", ""The sun is bright."") #Documents
test_set = (""The sun in the sky is bright."") #Query
stopWords = stopwords.words('english')

vectorizer = CountVectorizer(stop_words = stopWords)
transformer = TfidfTransformer()

trainVectorizerArray = vectorizer.fit_transform(train_set).toarray()
testVectorizerArray = vectorizer.transform(test_set).toarray()
print 'Fit Vectorizer to train set', trainVectorizerArray
print 'Transform Vectorizer to test set', testVectorizerArray

transformer.fit(trainVectorizerArray)
print transformer.transform(trainVectorizerArray).toarray()

transformer.fit(testVectorizerArray)

tfidf = transformer.transform(testVectorizerArray)
print tfidf.todense()
</code></pre>
"
"Python: UnicodeDecodeError: 'utf8' codec can't decode byte","<p>I'm reading a bunch of RTF files into python strings.
On SOME texts, I get this error:</p>

<pre><code>Traceback (most recent call last):
  File ""11.08.py"", line 47, in &lt;module&gt;
    X = vectorizer.fit_transform(texts)
  File ""C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py"", line
716, in fit_transform
    X = super(TfidfVectorizer, self).fit_transform(raw_documents)
  File ""C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py"", line
398, in fit_transform
    term_count_current = Counter(analyze(doc))
  File ""C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py"", line
313, in &lt;lambda&gt;
    tokenize(preprocess(self.decode(doc))), stop_words)
  File ""C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py"", line
224, in decode
    doc = doc.decode(self.charset, self.charset_error)
  File ""C:\Python27\lib\encodings\utf_8.py"", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0x92 in position 462: invalid
 start byte
</code></pre>

<p>I've tried: </p>

<ol>
<li>Copying and pasting the text of the files to new files</li>
<li>saving the rtf files as txt files</li>
<li>Openin the txt files in Notepad++ and choosing 'convert to utf-8' and also setting the encoding to utf-8</li>
<li>Opening the files with Microsoft Word and saving them as new files</li>
</ol>

<p>Nothing works. Any ideas?</p>

<p>It's probably not related, but here's the code incase you are wondering:</p>

<pre><code>f = open(dir+location, ""r"")
doc = Rtf15Reader.read(f)
t = PlaintextWriter.write(doc).getvalue()
texts.append(t)
f.close()
vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')
X = vectorizer.fit_transform(texts)     
</code></pre>
"
"Preprocessing in scikit learn - single sample - Depreciation warning","<p>On a fresh installation of Anaconda under Ubuntu... I am preprocessing my data in various ways prior to a classification task using Scikit-Learn.</p>

<pre><code>from sklearn import preprocessing

scaler = preprocessing.MinMaxScaler().fit(train)
train = scaler.transform(train)    
test = scaler.transform(test)
</code></pre>

<p>This all works fine but if I have a new sample (temp below) that I want to classify (and thus I want to preprocess in the same way then I get</p>

<pre><code>temp = [1,2,3,4,5,5,6,....................,7]
temp = scaler.transform(temp)
</code></pre>

<p>Then I get a deprecation warning...</p>

<pre><code>DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 
and will raise ValueError in 0.19. Reshape your data either using 
X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1)
if it contains a single sample. 
</code></pre>

<p>So the question is how should I be rescaling a single sample like this?</p>

<p>I suppose an alternative (not very good one) would be...</p>

<pre><code>temp = [temp, temp]
temp = scaler.transform(temp)
temp = temp[0]
</code></pre>

<p>But I'm sure there are better ways.</p>
"
"Alternative for r's Exponential smoothing state space model in python/scikit/numpy","<p>In R we have one good forecasting model like:</p>

<pre><code>ets(y, model=""ZZZ"", damped=NULL, alpha=NULL, beta=NULL, gamma=NULL, 

phi=NULL, additive.only=FALSE, lambda=NULL, 

lower=c(rep(0.0001,3), 0.8), upper=c(rep(0.9999,3),0.98), 

opt.crit=c(""lik"",""amse"",""mse"",""sigma"",""mae""), nmse=3, 

bounds=c(""both"",""usual"",""admissible""), ic=c(""aicc"",""aic"",""bic""),

restrict=TRUE, allow.multiplicative.trend=FALSE, use.initial.values=FALSE, ...)
</code></pre>

<p>In this method if we assign any variable, it  automatically gets <em>season type,trend &amp; error type</em> like  <code>model=""ZZZ""/""AMA""/""MMZ""</code> and some of the factors are auto adjusted to get accurate results.</p>

<ul>
<li><p>In python do we have anything similar to <code>ets</code> in either
pandas/numpy/scipy/scikit?</p>

<p><strong>By my research:</strong><br>
<a href=""http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.ewma.html"" rel=""noreferrer""><code>Ewma</code></a> in pandas is similar, but we need to hardcode all the parameters to fixed ones.<br>
In Holtwinter we need to write detailed methods for all the trend and season types.</p></li>
<li><p>So instead of that do we have any ready-made functions which takes
dataframes as input and provides forecasting values, without writing
any inner functions for parameters ourselves?</p></li>
<li><p>Any Fine tuned regression models scikit/statsmodels?</p></li>
</ul>
"
"XGBoost XGBClassifier Defaults in Python","<p>I am attempting to use XGBoosts classifier to classify some binary data. When I do the simplest thing and just use the defaults (as follows)</p>

<pre><code>clf = xgb.XGBClassifier()
metLearn=CalibratedClassifierCV(clf, method='isotonic', cv=2)
metLearn.fit(train, trainTarget)
testPredictions = metLearn.predict(test)
</code></pre>

<p>I get reasonably good classification results.</p>

<p>My next step was to try tuning my parameters. Guessing from the parameters guide at...
<a href=""https://github.com/dmlc/xgboost/blob/master/doc/parameter.md"" rel=""noreferrer"">https://github.com/dmlc/xgboost/blob/master/doc/parameter.md</a>
I wanted to start from the default and work from there...</p>

<pre><code># setup parameters for xgboost
param = {}
param['booster'] = 'gbtree'
param['objective'] = 'binary:logistic'
param[""eval_metric""] = ""error""
param['eta'] = 0.3
param['gamma'] = 0
param['max_depth'] = 6
param['min_child_weight']=1
param['max_delta_step'] = 0
param['subsample']= 1
param['colsample_bytree']=1
param['silent'] = 1
param['seed'] = 0
param['base_score'] = 0.5

clf = xgb.XGBClassifier(params)
metLearn=CalibratedClassifierCV(clf, method='isotonic', cv=2)
metLearn.fit(train, trainTarget)
testPredictions = metLearn.predict(test)
</code></pre>

<p>The result is everything being predicted to be one of the conditions and not the other.</p>

<p>curiously if I set </p>

<pre><code>params={}
</code></pre>

<p>which I expected to give me the same defaults as not feeding any parameters, I get the same thing happening</p>

<p>So does anyone know what the defaults for XGBclassifier is? so that I can start tuning?</p>
"
"Multiprocessing scikit-learn","<p>I got linearsvc working against training set and test set using <code>load_file</code> method i am trying to get It working on Multiprocessor enviorment.</p>

<p>How can i get multiprocessing work on <code>LinearSVC().fit()</code> <code>LinearSVC().predict()</code>? I am not really familiar  with datatypes of scikit-learn yet.</p>

<p>I am also thinking about splitting samples into multiple arrays but i am not familiar with numpy arrays and scikit-learn data structures. </p>

<p>Doing this it will be easier to put into multiprocessing.pool() , with that , split samples into chunks , train them and combine trained set  back later , would it work ? </p>

<p>EDIT:
Here is my scenario:</p>

<p>lets say , we have 1 million files in training sample set , when we want to distribute processing of Tfidfvectorizer on several processors we have to split those samples (for my case it will only have two categories , so lets say 500000 each samples to train) . My server have 24 cores with 48 GB , so i want to split each topics into number of chunks 1000000 / 24 and process Tfidfvectorizer on them. Like that i would do to Testing sample set , as well as SVC.fit() and decide(). Does it make sense? </p>

<p>Thanks. </p>

<p>PS: Please do not close this .</p>
"
"Scikit Learn: Logistic Regression model coefficients: Clarification","<p>I need to know how to return the logistic regression coefficients in such a manner that I can generate the predicted probabilities myself.</p>

<p>My code looks like this:</p>

<pre><code>lr = LogisticRegression()
lr.fit(training_data, binary_labels)

# Generate probabities automatically
predicted_probs = lr.predict_proba(binary_labels)
</code></pre>

<p>I had assumed the lr.coeff_ values would follow typical logistic regression, so that I could return the predicted probabilities like this:</p>

<pre><code>sigmoid( dot([val1, val2, offset], lr.coef_.T) )
</code></pre>

<p>But this is not the appropriate formulation. Does anyone have the proper format for generating predicted probabilities from Scikit Learn LogisticRegression?
Thanks!</p>
"
"How to get SVMs to play nicely with missing data in scikit-learn?","<p>I am using scikit-learn for some data analysis, and my dataset has some missing values (represented by <code>NA</code>).  I load the data in with <code>genfromtxt</code> with <code>dtype='f8'</code> and go about training my classifier.</p>

<p>The classification is fine on <code>RandomForestClassifier</code> and <code>GradientBoostingClassifier</code> objects, but using <code>SVC</code> from <code>sklearn.svm</code> causes the following error:</p>

<pre><code>    probas = classifiers[i].fit(train[traincv], target[traincv]).predict_proba(train[testcv])
  File ""C:\Python27\lib\site-packages\sklearn\svm\base.py"", line 409, in predict_proba
    X = self._validate_for_predict(X)
  File ""C:\Python27\lib\site-packages\sklearn\svm\base.py"", line 534, in _validate_for_predict
    X = atleast2d_or_csr(X, dtype=np.float64, order=""C"")
  File ""C:\Python27\lib\site-packages\sklearn\utils\validation.py"", line 84, in atleast2d_or_csr
    assert_all_finite(X)
  File ""C:\Python27\lib\site-packages\sklearn\utils\validation.py"", line 20, in assert_all_finite
    raise ValueError(""array contains NaN or infinity"")
ValueError: array contains NaN or infinity
</code></pre>

<p>What gives?  How can I make the SVM play nicely with the missing data?  Keeping in mind that the missing data works fine for random forests and other classifiers..</p>
"
"sklearn Logistic Regression ""ValueError: Found array with dim 3. Estimator expected <= 2.""","<p>I attempt to solve this problem 6 in this notebook. The question is to train a simple model on this data using 50, 100, 1000 and 5000 training samples by using the LogisticRegression model from sklearn.linear_model. 
<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/1_notmnist.ipynb"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/1_notmnist.ipynb</a></p>

<pre><code>lr = LogisticRegression()
lr.fit(train_dataset,train_labels)
</code></pre>

<p>This is the code i trying to do and it give me the error. ValueError: Found array with dim 3. Estimator expected &lt;= 2.</p>

<p>Any idea?</p>
"
"scikit's GridSearch and Python in general are not freeing memory","<p>I made some weird observations that my GridSearches keep failing after a couple of hours and I initially couldn't figure out why. I monitored the memory usage then over time and saw that it it started with a few gigabytes (~6 Gb) and kept increasing until it crashed the node when it reached the max. 128 Gb the hardware can take. 
I was experimenting with random forests for classification of a large number of text documents. For simplicity -- to figure out what's going on -- I went back to naive Bayes.</p>

<p>The versions I am using are </p>

<ul>
<li>Python 3.4.2 </li>
<li>scikit-learn 0.15.2</li>
</ul>

<p>I found some related discussion on the scikit-issue list on GitHub about this topic: <a href=""https://github.com/scikit-learn/scikit-learn/issues/565"" rel=""noreferrer"">https://github.com/scikit-learn/scikit-learn/issues/565</a> and
<a href=""https://github.com/scikit-learn/scikit-learn/pull/770"" rel=""noreferrer"">https://github.com/scikit-learn/scikit-learn/pull/770</a></p>

<p>And it sounds like it was already successfully addressed!</p>

<p>So, the relevant code that I am using is</p>

<pre><code>grid_search = GridSearchCV(pipeline, 
                           parameters, 
                           n_jobs=1, # 
                           cv=5, 
                           scoring='roc_auc',
                           verbose=2,
                           pre_dispatch='2*n_jobs',
                           refit=False)  # tried both True and False

grid_search.fit(X_train, y_train)  
print('Best score: {0}'.format(grid_search.best_score_))  
print('Best parameters set:') 
</code></pre>

<p>Just out of curiosity, I later decided to do the grid search the quick &amp; dirty way via nested for loop</p>

<pre><code>for p1 in parameterset1:
    for p2 in parameterset2:
        ...
            pipeline = Pipeline([
                        ('vec', CountVectorizer(
                                   binary=True,
                                   tokenizer=params_dict[i][0][0],
                                   max_df=params_dict[i][0][1],
                                   max_features=params_dict[i][0][2],
                                   stop_words=params_dict[i][0][3],
                                   ngram_range=params_dict[i][0][4],)),
                         ('tfidf', TfidfTransformer(
                                      norm=params_dict[i][0][5],
                                      use_idf=params_dict[i][0][6],
                                      sublinear_tf=params_dict[i][0][7],)),
                         ('clf', MultinomialNB())])

            scores = cross_validation.cross_val_score(
                                        estimator=pipeline,
                                        X=X_train, 
                                        y=y_train, 
                                        cv=5, 
                                        scoring='roc_auc',
                                        n_jobs=1)

           params_dict[i][1] = '%s,%0.4f,%0.4f' % (params_dict[i][1], scores.mean(), scores.std())
           sys.stdout.write(params_dict[i][1] + '\n')
</code></pre>

<p>So far so good. The grid search runs and writes the results to stdout. However, after some time it exceeds the memory cap of 128 Gb again. Same problem as with the GridSearch in scikit. After some experimentation, I finally found out that </p>

<pre><code>gc.collect()
len(gc.get_objects()) # particularly this part!
</code></pre>

<p>in the for loop solves the problem and the memory usage stays constantly at 6.5 Gb over the run time of ~10 hours.</p>

<p>Eventually, I got it to work with the above fix, however, I am curious to hear your ideas about what might be causing this issue and your tips &amp; suggestions!</p>
"
"how to extract the decision rules from scikit-learn decision-tree?","<p>Can I extract the underlying decision-rules (or 'decision paths') from a trained tree in a decision tree - as a textual list ? <br/>
something like: <code>""if A&gt;0.4 then if B&lt;0.2 then if C&gt;0.8 then class='X'</code> etc... <br/>
If anyone knows of a simple way to do so, it will be very helpful. </p>
"
"Understanding min_df and max_df in scikit CountVectorizer","<p>I have five text files that I input to a CountVectorizer. When specifying min_df and max_df to the CountVectorizer instance what does the min/max document frequency exactly means? Is it the frequency of a word in its particular text file or is it the frequency of the word in the entire overall corpus (5 txt files)?</p>

<p>How is it different when min_df and max_df are provided as integers or as floats?</p>

<p>The documentation doesn't seem to provide a thorough explanation nor does it supply an example to demonstrate the use of min_df and/or max_df. Could someone provide an explanation or example demonstrating min_df or max_df.</p>
"
"Scikit-Learn PCA","<p>I am using input data from <a href=""http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf"">here</a> (see Section 3.1).</p>

<p>I am trying to reproduce their covariance matrix, eigenvalues, and eigenvectors using scikit-learn. However, I am unable to reproduce the results as presented in the data source. I've also seen this input data elsewhere but I can't discern whether it's a problem with scikit-learn, my steps, or the data source.</p>

<pre><code>data = np.array([[2.5,2.4],
                 [0.5,0.7],
                 [2.2,2.9],
                 [1.9,2.2],
                 [3.1,3.0],
                 [2.3,2.7],
                 [2.0,1.6],
                 [1.0,1.1],
                 [1.5,1.6],
                 [1.1,0.9],
                 ]) 

centered_data = data-data.mean(axis=0)
pca = PCA()
pca.fit(centered_data)
print(pca.get_covariance()) #Covariance Matrix

array([[ 0.5549,  0.5539],
   [ 0.5539,  0.6449]])

print(pca.explained_variance_ratio_) #Eigenvalues (normalized)

[ 0.96318131  0.03681869]

print(pca.components_) #Eigenvectors

[[-0.6778734  -0.73517866]
 [ 0.73517866 -0.6778734 ]]
</code></pre>

<p>Surprisingly, the projections matches the results from the data source described above.</p>

<pre><code>print(pca.transform(centered_data)) #Projections

array([[-0.82797019,  0.17511531],
   [ 1.77758033, -0.14285723],
   [-0.99219749, -0.38437499],
   [-0.27421042, -0.13041721],
   [-1.67580142,  0.20949846],
   [-0.9129491 , -0.17528244],
   [ 0.09910944,  0.3498247 ],
   [ 1.14457216, -0.04641726],
   [ 0.43804614, -0.01776463],
   [ 1.22382056,  0.16267529]])
</code></pre>

<p>Here is what I don't understand:</p>

<ol>
<li>Why is the covariance matrix is different?</li>
<li><strong>Updated</strong>: How do I get eigenvalues from scikit-learn that are not already normalized? </li>
</ol>
"
"What is the difference between SVC and SVM in scikit-learn?","<p>From the <a href=""http://scikit-learn.org/stable/modules/svm.html"">documentation</a> scikit-learn implements SVC, NuSVC and LinearSVC which are classes capable of performing multi-class classification on a dataset. By the other hand I also read about that scikit learn also uses libsvm for support vector machine algorithm. I'm a bit confused about what's the difference between SVC and libsvm versions, by now I guess the difference is that SVC is the support vector machine algorithm fot the multiclass problem and libsvm is for the binary class problem. Could anybody help me to understad the difference between this?.</p>
"
"(Python - sklearn) How to pass parameters to the customize ModelTransformer class by gridsearchcv","<p>Below is my pipeline and it seems that I can't pass the parameters to my models by using the ModelTransformer class, which I take it from the link (<a href=""http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html"">http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html</a>)</p>

<p>The error message makes sense to me, but I don't know how to fix this. Any idea how to fix this? Thanks.</p>

<pre><code># define a pipeline
pipeline = Pipeline([
('vect', DictVectorizer(sparse=False)),
('scale', preprocessing.MinMaxScaler()),
('ess', FeatureUnion(n_jobs=-1, 
                     transformer_list=[
     ('rfc', ModelTransformer(RandomForestClassifier(n_jobs=-1, random_state=1,  n_estimators=100))),
     ('svc', ModelTransformer(SVC(random_state=1))),],
                     transformer_weights=None)),
('es', EnsembleClassifier1()),
])

# define the parameters for the pipeline
parameters = {
'ess__rfc__n_estimators': (100, 200),
}

# ModelTransformer class. It takes it from the link
(http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html)
class ModelTransformer(TransformerMixin):
    def __init__(self, model):
        self.model = model
    def fit(self, *args, **kwargs):
        self.model.fit(*args, **kwargs)
        return self
    def transform(self, X, **transform_params):
        return DataFrame(self.model.predict(X))

grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, refit=True)
</code></pre>

<p>Error Message:
ValueError: Invalid parameter n_estimators for estimator ModelTransformer.</p>
"
"Visualizing decision tree in scikit-learn","<p>I am trying to design a simple Decision Tree using scikit-learn in Python (I am using Anaconda's Ipython Notebook with Python 2.7.3 on Windows OS) and visualize it as follows:</p>

<pre><code>from pandas import read_csv, DataFrame
from sklearn import tree
from os import system

data = read_csv('D:/training.csv')
Y = data.Y
X = data.ix[:,""X0"":""X33""]

dtree = tree.DecisionTreeClassifier(criterion = ""entropy"")
dtree = dtree.fit(X, Y)

dotfile = open(""D:/dtree2.dot"", 'w')
dotfile = tree.export_graphviz(dtree, out_file = dotfile, feature_names = X.columns)
dotfile.close()
system(""dot -Tpng D:.dot -o D:/dtree2.png"")
</code></pre>

<p>However, I get the following error:</p>

<pre><code>AttributeError: 'NoneType' object has no attribute 'close'
</code></pre>

<p>I use the following blog post as reference: <a href=""http://statcompute.wordpress.com/2012/12/05/learning-decision-tree-in-scikit-learn-package/"" rel=""noreferrer"">Blogpost link</a></p>

<p>The following stackoverflow question doesn't seem to work for me as well: <a href=""https://stackoverflow.com/questions/10570042/visualizing-a-decision-tree-example-from-scikit-learn"">Question</a></p>

<p>Could someone help me with how to visualize the decision tree in scikit-learn?</p>
"
"Scikit-Learn: Predicting new points with DBSCAN","<p>I am using DBSCAN to cluster some data using Scikit-Learn (Python 2.7):</p>

<pre><code>from sklearn.cluster import DBSCAN
dbscan = DBSCAN(random_state=0)
dbscan.fit(X)
</code></pre>

<p>However, I found that there was no built-in function (aside from ""fit_predict"") that could assign the new data points, Y, to the clusters identified in the original data, X. The K-means method has a ""predict"" function but I want to be able to do the same with DBSCAN. Something like this:</p>

<pre><code>dbscan.predict(X, Y)
</code></pre>

<p>So that the density can be inferred from X but the return values (cluster assignments/labels) are only for Y. From what I can tell, this capability is available in R so I assume that it is also somehow available in Python. I just can't seem to find any documentation for this.</p>

<p>Also, I have tried searching for reasons as to why DBSCAN may not be used for labeling new data but I haven't found any justifications.</p>
"
"Python scikit learn MLPClassifier ""hidden_layer_sizes""","<p>I am lost in the scikit learn 0.18 user manual (<a href=""http://scikit-learn.org/dev/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"">http://scikit-learn.org/dev/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier</a>):</p>

<pre><code>   hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)
   The ith element represents the number of neurons in the ith hidden layer.
</code></pre>

<p>If I am looking for only 1 hidden layer and 7 hidden units in my model, should I put like this?  Thanks!</p>

<pre><code>    hidden_layer_sizes=(7, 1)
</code></pre>
"
"Tensorflow Precision / Recall / F1 score and Confusion matrix","<p>I would like to know if there is a way to implement the different score function from the scikit learn package like this one :</p>

<pre><code>from sklearn.metrics import confusion_matrix
confusion_matrix(y_true, y_pred)
</code></pre>

<p>into a tensorflow model to get the different score.</p>

<pre><code>with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
init = tf.initialize_all_variables()
sess.run(init)
for epoch in xrange(1):
        avg_cost = 0.
        total_batch = len(train_arrays) / batch_size
        for batch in range(total_batch):
                train_step.run(feed_dict = {x: train_arrays, y: train_labels})
                avg_cost += sess.run(cost, feed_dict={x: train_arrays, y: train_labels})/total_batch
        if epoch % display_step == 0:
                print ""Epoch:"", '%04d' % (epoch+1), ""cost="", ""{:.9f}"".format(avg_cost)

print ""Optimization Finished!""
correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
# Calculate accuracy
accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))
print ""Accuracy:"", batch, accuracy.eval({x: test_arrays, y: test_labels})
</code></pre>

<p>Will i have to run the session again to get the prediction ?</p>
"
"Clustering text documents using scikit-learn kmeans in Python","<p>I need to implement <a href=""http://scikit-learn.org/stable/auto_examples/document_clustering.html#example-document-clustering-py"" rel=""noreferrer"">scikit-learn's kMeans</a> for clustering text documents. The <a href=""http://scikit-learn.org/stable/auto_examples/document_clustering.html#example-document-clustering-py"" rel=""noreferrer"">example code</a> works fine as it is but takes some 20newsgroups data as input. I want to use the same code for clustering a list of documents as shown below:</p>

<pre><code>documents = [""Human machine interface for lab abc computer applications"",
             ""A survey of user opinion of computer system response time"",
             ""The EPS user interface management system"",
             ""System and human system engineering testing of EPS"",
             ""Relation of user perceived response time to error measurement"",
             ""The generation of random binary unordered trees"",
             ""The intersection graph of paths in trees"",
             ""Graph minors IV Widths of trees and well quasi ordering"",
             ""Graph minors A survey""]
</code></pre>

<p>What changes do i need to do in <a href=""http://scikit-learn.org/stable/auto_examples/document_clustering.html#example-document-clustering-py"" rel=""noreferrer"">kMeans example code</a> to use this list as input? (Simply taking 'dataset = documents' doesn't work)</p>
"
"how to check which version of nltk, scikit learn installed?","<p>In shell script I am checking whether this packages are installed or not, if not installed then install it. So withing shell script:</p>

<pre><code>import nltk
echo nltk.__version__
</code></pre>

<p>but it stops shell script at <code>import</code> line</p>

<p>in linux terminal tried to see in this manner:</p>

<pre><code>which nltk
</code></pre>

<p>which gives nothing thought it is installed.</p>

<p>Is there any other way to verify this package installation in shell script, if not installed, also install it.</p>
"
"How can I plot a confusion matrix?","<p>I am using scikit-learn for classification of text documents(22000) to 100 classes. I use scikit-learn's confusion matrix method for computing the confusion matrix.</p>

<pre><code>model1 = LogisticRegression()
model1 = model1.fit(matrix, labels)
pred = model1.predict(test_matrix)
cm=metrics.confusion_matrix(test_labels,pred)
print(cm)
plt.imshow(cm, cmap='binary')
</code></pre>

<p>This is how my confusion matrix looks like:</p>

<pre><code>[[3962  325    0 ...,    0    0    0]
 [ 250 2765    0 ...,    0    0    0]
 [   2    8   17 ...,    0    0    0]
 ..., 
 [   1    6    0 ...,    5    0    0]
 [   1    1    0 ...,    0    0    0]
 [   9    0    0 ...,    0    0    9]]
</code></pre>

<p>However, I do not receive a clear or legible plot. Is there a better way to do this?</p>
"
"python scikit-learn clustering with missing data","<p>I want to cluster data with missing columns. Doing it manually I would calculate the distance in case of a missing column simply without this column.</p>

<p>With scikit-learn, missing data is not possible. There is also no chance to specify a user distance function.</p>

<p>Is there any chance to cluster with missing data?</p>

<p>Example data:</p>

<pre><code>n_samples = 1500
noise = 0.05  
X, _ = make_swiss_roll(n_samples, noise)

rnd = np.random.rand(X.shape[0],X.shape[1]) 
X[rnd&lt;0.1] = np.nan
</code></pre>
"
"Should a pandas dataframe column be converted in some way before passing it to a scikit learn regressor?","<p>I have a pandas dataframe and passing <code>df[list_of_columns]</code> as X and <code>df[[single_column]]</code> as <code>Y</code> to a Random Forest regressor.</p>

<p>What does the following warnning mean and what should be done to resolve it?</p>

<pre><code>DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().   probas = cfr.fit(trainset_X, trainset_Y).predict(testset_X)
</code></pre>
"
"Accuracy score in pyTorch LSTM","<p>I have been running <a href=""http://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"" rel=""noreferrer"">this LSTM tutorial</a> on the <a href=""http://downloads.schwa.org/wikiner/wikigold.conll.txt"" rel=""noreferrer"">wikigold.conll NER data set</a></p>

<p><code>training_data</code> contains a list of tuples of sequences and tags, for example:</p>

<pre><code>training_data = [
    (""They also have a song called \"" wake up \"""".split(), [""O"", ""O"", ""O"", ""O"", ""O"", ""O"", ""I-MISC"", ""I-MISC"", ""I-MISC"", ""I-MISC""]),
    (""Major General John C. Scheidt Jr."".split(), [""O"", ""O"", ""I-PER"", ""I-PER"", ""I-PER""])
]
</code></pre>

<p>And I wrote down this function</p>

<pre><code>def predict(indices):
    """"""Gets a list of indices of training_data, and returns a list of predicted lists of tags""""""
    for index in indicies:
        inputs = prepare_sequence(training_data[index][0], word_to_ix)
        tag_scores = model(inputs)
        values, target = torch.max(tag_scores, 1)
        yield target
</code></pre>

<p>This way I can get the predicted labels for specific indices in the training data.</p>

<p>However, how do I evaluate the accuracy score across all training data.</p>

<p>Accuracy being, the amount of words correctly classified across all sentences divided by the word count.</p>

<h2>This is what I came up with, which is extremely slow and ugly:</h2>

<pre><code>y_pred = list(predict([s for s, t in training_data]))
y_true = [t for s, t in training_data]
c=0
s=0
for i in range(len(training_data)):
    n = len(y_true[i])
    #super ugly and ineffiicient
    s+=(sum(sum(list(y_true[i].view(-1, n) == y_pred[i].view(-1, n).data))))
    c+=n

print ('Training accuracy:{a}'.format(a=float(s)/c))
</code></pre>

<h2>How can this be done efficiently in pytorch ?</h2>

<p>P.S:
I've been trying to use <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html"" rel=""noreferrer"">sklearn's accuracy_score</a> unsuccessfully</p>
"
"GridSearch for an estimator inside a OneVsRestClassifier","<p>I want to perform GridSearchCV in a SVC model, but that uses the one-vs-all strategy. For the latter part, I can just do this:</p>

<pre><code>model_to_set = OneVsRestClassifier(SVC(kernel=""poly""))
</code></pre>

<p>My problem is with the parameters. Let's say I want to try the following values:</p>

<pre><code>parameters = {""C"":[1,2,4,8], ""kernel"":[""poly"",""rbf""],""degree"":[1,2,3,4]}
</code></pre>

<p>In order to perform GridSearchCV, I should do something like:</p>

<pre><code> cv_generator = StratifiedKFold(y, k=10)
 model_tunning = GridSearchCV(model_to_set, param_grid=parameters, score_func=f1_score, n_jobs=1, cv=cv_generator)
</code></pre>

<p>However, then I execute it I get:</p>

<pre><code>Traceback (most recent call last):
  File ""/.../main.py"", line 66, in &lt;module&gt;
    argclass_sys.set_model_parameters(model_name=""SVC"", verbose=3, file_path=PATH_ROOT_MODELS)
  File ""/.../base.py"", line 187, in set_model_parameters
    model_tunning.fit(self.feature_encoder.transform(self.train_feats), self.label_encoder.transform(self.train_labels))
  File ""/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py"", line 354, in fit
    return self._fit(X, y)
  File ""/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py"", line 392, in _fit
    for clf_params in grid for train, test in cv)
  File ""/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py"", line 473, in __call__
    self.dispatch(function, args, kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py"", line 296, in dispatch
    job = ImmediateApply(func, args, kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py"", line 124, in __init__
    self.results = func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py"", line 85, in fit_grid_point
    clf.set_params(**clf_params)
  File ""/usr/local/lib/python2.7/dist-packages/sklearn/base.py"", line 241, in set_params
    % (key, self.__class__.__name__))
ValueError: Invalid parameter kernel for estimator OneVsRestClassifier
</code></pre>

<p>Basically, since the SVC is inside a OneVsRestClassifier and that's the estimator I send to the GridSearchCV, the SVC's parameters can't be accessed. </p>

<p>In order to accomplish what I want, I see two solutions:</p>

<ol>
<li>When creating the SVC, somehow tell it not to use the one-vs-one strategy but the one-vs-all.</li>
<li>Somehow indicate the GridSearchCV that the parameters correspond to the estimator inside the OneVsRestClassifier. </li>
</ol>

<p>I'm yet to find a way to do any of the mentioned alternatives. Do you know if there's a way to do any of them? Or maybe you could suggest another way to get to the same result?</p>

<p>Thanks!</p>
"
"How to tune parameters in Random Forest, using Scikit Learn?","<pre><code>class sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)
</code></pre>

<p>I'm using a random forest model with 9 samples and about 7000 attributes.  Of these samples, there are 3 categories that my classifier recognizes. </p>

<p>I know this is far from ideal conditions but I'm trying to figure out which attributes are the most important in feature predictions.  Which parameters would be the best to tweak for optimizing feature importance? </p>

<p>I tried different <code>n_estimators</code> and noticed that the amount of ""significant features"" (i.e. nonzero values in the <code>feature_importances_</code> array) increased dramatically. </p>

<p>I've read through the documentation but if anyone has any experience in this, I would like to know which parameters are the best to tune and a brief explanation why. </p>
"
"scikit .predict() default threshold","<p>I'm working on a classification problem with unbalanced classes (5% 1's). I want to predict the class, not the probability.</p>

<p>In a binary classification problem, is scikit's <code>classifier.predict()</code> using <code>0.5</code> by default?
If it doesn't, what's the default method? If it does, how do I change it?</p>

<p>In scikit some classifiers have the <code>class_weight='auto'</code> option, but not all do. With <code>class_weight='auto'</code>, would <code>.predict()</code> use the actual population proportion as a threshold?</p>

<p>What would be the way to do this in a classifier like <code>MultinomialNB</code> that doesn't support <code>class_weight</code>? Other than using <code>predict_proba()</code> and then calculation the classes myself.</p>
"
"Run an OLS regression with Pandas Data Frame","<p>I have a <code>pandas</code> data frame and I would like to able to predict the values of column A from the values in columns B and C. Here is a toy example:</p>

<pre><code>import pandas as pd
df = pd.DataFrame({""A"": [10,20,30,40,50], 
                   ""B"": [20, 30, 10, 40, 50], 
                   ""C"": [32, 234, 23, 23, 42523]})
</code></pre>

<p>Ideally, I would have something like <code>ols(A ~ B + C, data = df)</code> but when I look at the <a href=""http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html"" rel=""noreferrer"">examples</a> from algorithm libraries like <code>scikit-learn</code> it appears to feed the data to the model with a list of rows instead of columns. This would require me to reformat the data into lists inside lists, which seems to defeat the purpose of using pandas in the first place. What is the most pythonic way to run an OLS regression (or any machine learning algorithm more generally) on data in a pandas data frame? </p>
"
"Vectorizing a Pandas dataframe for Scikit-Learn","<p>Say I have a dataframe in Pandas like the following:</p>

<pre><code>&gt; my_dataframe

col1   col2
A      foo
B      bar
C      something
A      foo
A      bar
B      foo
</code></pre>

<p>where rows represent instances, and columns input features (not showing the target label, but this would be for a classification task), i.e. I trying to build <strong>X</strong> out of <code>my_dataframe</code>.</p>

<p>How can I vectorize this efficiently using e.g. <a href=""http://scikit-learn.org/stable/modules/feature_extraction.html#loading-features-from-dicts""><code>DictVectorizer</code></a> ?</p>

<p>Do I need to convert each and every entry in my DataFrame to a dictionary first? (that's the way it is done in the example in the link above). Is there a more efficient way to do this?</p>
"
"How to predict time series in scikit-learn?","<p>Scikit-learn utilizes a very convenient approach based on <code>fit</code> and <code>predict</code> methods. I have time-series data in the format suited for <code>fit</code> and <code>predict</code>.</p>

<p>For example I have the following <code>Xs</code>:</p>

<pre><code>[[1.0, 2.3, 4.5], [6.7, 2.7, 1.2], ..., [3.2, 4.7, 1.1]]
</code></pre>

<p>and the corresponding <code>ys</code>:</p>

<pre><code>[[1.0], [2.3], ..., [7.7]]
</code></pre>

<p>These data have the following meaning. The values stored in <code>ys</code> form a time series. The values in <code>Xs</code> are corresponding time dependent ""factors"" that are known to have some influence on the values in <code>ys</code> (for example: temperature, humidity and atmospheric pressure).</p>

<p>Now, of course, I can use <code>fit(Xs,ys)</code>. But then I get a model in which future values in <code>ys</code> depend only on factors and do not dependend on the previous <code>Y</code> values (at least directly) and this is a limitation of the model. I would like to have a model in which <code>Y_n</code> depends also on <code>Y_{n-1}</code> and <code>Y_{n-2}</code> and so on. For example I might want to use an exponential moving average as a model. What is the most elegant way to do it in scikit-learn</p>

<p><strong>ADDED</strong></p>

<p>As it has been mentioned in the comments, I can extend <code>Xs</code> by adding <code>ys</code>. But this way has some limitations. For example, if I add the last 5 values of <code>y</code> as 5 new columns to <code>X</code>, the information about time ordering of <code>ys</code> is lost. For example, there is no indication in <code>X</code> that values in the 5th column follows value in the 4th column and so on. As a model, I might want to have a linear fit of the last five <code>ys</code> and use the found linear function to make a prediction. But if I have 5 values in 5 columns it is not so trivial.</p>

<p><strong>ADDED 2</strong></p>

<p>To make my problem even more clear, I would like to give one concrete example. I would like to have a ""linear"" model in which <code>y_n = c + k1*x1 + k2*x2 + k3*x3 + k4*EMOV_n</code>, where EMOV_n is just an exponential moving average. How, can I implement this simple model in scikit-learn?</p>
"
"Unbalanced classification using RandomForestClassifier in sklearn","<p>I have a dataset where the classes are unbalanced.  The classes are either '1' or '0' where the ratio of class '1':'0' is 5:1.  How do you calculate the prediction error for each class and the rebalance weights accordingly in sklearn with Random Forest, kind of like in the following link:  <a href=""http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#balance"">http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#balance</a></p>
"
"Deprecation warning in scikit-learn svmlight format loader","<p>I'm getting a new deprecation warning in an IPython notebook I wrote that I've not seen before. What I'm seeing is the following:</p>

<pre><code>X,y = load_svmlight_file('./GasSensorArray/batch2.dat')
/Users/cpd/.virtualenvs/py27-ipython+pandas/lib/python2.7/site-packages/sklearn/datasets/svmlight_format.py:137: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
return _load_svmlight_file(f, dtype, multilabel, zero_based, query_id)
/Users/cpd/.virtualenvs/py27-ipython+pandas/lib/python2.7/site-packages/sklearn/datasets/svmlight_format.py:137: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
return _load_svmlight_file(f, dtype, multilabel, zero_based, query_id)
...
</code></pre>

<p>Any thoughts on what might be the issue here? I took another look at my data file and at first glance, I don't see any obvious issue. I'm not sure what I changed in my system setup that would have caused this. I've got v. 0.14.1 of scikit-learn installed. </p>
"
"Find p-value (significance) in scikit-learn LinearRegression","<p>How can I find the p-value (significance) of each coefficient?</p>

<pre><code>lm = sklearn.linear_model.LinearRegression()
lm.fit(x,y)
</code></pre>
"
"Cannot import scikits-learn even though it seems to be installed","<p>Per the scikit-learn user guide, I installed scikit-learn using <code>pip install -U scikit-learn</code>.</p>

<p>So using <code>pip search scikit-learn</code>, I get this search result:</p>

<pre><code>scikit-learn - A set of python modules for machine learning and data mining
INSTALLED: 0.12.1 (latest)
</code></pre>

<p>But when I go into Python and try to <code>import sklearn</code>, I get an <code>ImportError: No module named sklearn</code>. This really should have just worked.</p>

<p>I am using Enthought's free distribution of Python (2.7.3) on a Mac OS 10.6.8 with NumPy 1.6.1 and SciPy 0.10.1. Yes, I'm aware that EPD Free comes with scikit-learn but pip should have upgraded my version so that I can actually use scikit-learn.</p>
"
"Will pandas dataframe object work with sklearn kmeans clustering?","<p>dataset is pandas dataframe. This is sklearn.cluster.KMeans</p>

<pre><code> km = KMeans(n_clusters = n_Clusters)

 km.fit(dataset)

 prediction = km.predict(dataset)
</code></pre>

<p>This is how I decide which entity belongs to which cluster:</p>

<pre><code> for i in range(len(prediction)):
     cluster_fit_dict[dataset.index[i]] = prediction[i]
</code></pre>

<p>This is how dataset looks:</p>

<pre><code> A 1 2 3 4 5 6
 B 2 3 4 5 6 7
 C 1 4 2 7 8 1
 ...
</code></pre>

<p>where A,B,C are indices</p>

<p>Is this the correct way of using k-means?</p>
"
"Random state (Pseudo-random number)in Scikit learn","<p>I want to implement a machine learning algorithm in scikit learn, but I don't understand what this parameter <code>random_state</code> does? Why should I use it? </p>

<p>I also could not understand what is a Pseudo-random number. </p>
"
"How does sklearn.svm.svc's function predict_proba() work internally?","<p>I am using <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"" rel=""noreferrer"">sklearn.svm.svc</a> from <a href=""http://scikit-learn.org/stable/"" rel=""noreferrer"">scikit-learn</a> to do binary classification.  I am using its predict_proba() function to get probability estimates.  Can anyone tell me how predict_proba() internally calculates the probability?</p>
"
"What are the different use cases of joblib versus pickle?","<p>Background: I'm just getting started with scikit-learn, and read at the bottom of the page about <a href=""http://scikit-learn.org/stable/tutorial/basic/tutorial.html"" rel=""noreferrer"">joblib, versus pickle</a>. </p>

<blockquote>
  <p>it may be more interesting to use joblib’s replacement of pickle (joblib.dump &amp; joblib.load), which is more efficient on big data, but can only pickle to the disk and not to a string</p>
</blockquote>

<p>I read this Q&amp;A on Pickle, 
<a href=""https://stackoverflow.com/questions/3438675/common-use-of-pickle-in-python"">Common use-cases for pickle in Python</a> and wonder if the community here can share the differences between joblib and pickle?  When should one use one over another? </p>
"
"how to tune parameters of custom kernel function with pipeline in scikit-learn","<p>currently I have successfully defined a custom kernel function(pre-computing the kernel matrix) using def function, and now I am using the GridSearchCV function to get the best parameters. </p>

<p>so, in the custom kernel function, there is a total of 2 parameters which will be tuned (Namely gamm and sea_gamma in the example below), and also, for SVR model, the <em>cost c</em> parameter has to be tuned as well. But until now, I can just tune the <em>cost c</em> parameter using GridSearchCV -> please refer to the Part I: example below. </p>

<p>I have searched for some similar solutions such as:</p>

<p><a href=""https://stackoverflow.com/questions/24595153/is-it-possible-to-tune-parameters-with-grid-search-for-custom-kernels-in-scikit"">Is it possible to tune parameters with grid search for custom kernels in scikit-learn?</a></p>

<p>it says that ""<em>One way to do this is using Pipeline, SVC(kernel='precomputed') and wrapping your custom kernel function as a sklearn estimator (a subclass of BaseEstimator and TransformerMixin))</em>.""But which is still different from my case and question, however, I tried to solve the problem based on this solution, but it didn't print any outputs so far, even any errors. -> please refer to the Part II: solutions with pipeline. </p>

<p>Part I: Example-> my original custom kernel and scoring method in grid search is:</p>

<pre><code>    import numpy as np
    import pandas as pd
    import sklearn.svm as svm
    from sklearn import preprocessing,svm, datasets
    from sklearn.preprocessing import StandardScaler,  MaxAbsScaler
    from sklearn.metrics.pairwise import rbf_kernel
    from sklearn.grid_search import GridSearchCV
    from sklearn.svm import SVR
    from sklearn.pipeline import Pipeline
    from sklearn.metrics.scorer import make_scorer

    # weighting the vectors
    def distance_scale(X,Y):
        K = np.zeros((X.shape[0],Y.shape[0]))
        gamma_sea =192

        for i in range(X.shape[0]):
            for j in range(Y.shape[0]):
                dis = min(np.abs(X[i]-Y[j]),1-np.abs(X[i]-Y[j]))
                K[i,j] = np.exp(-gamma_sea*dis**2)
        return K

    # custom RBF kernel : kernel matrix calculation 
    def sea_rbf(X,Y):
        gam=1
        t1 = X[:, 5:6]
        t2 = Y[:, 5:6]
        X = X[:, 0:5]
        Y = Y[:, 0:5]
        d = distance_scale(t1,t2)
        return rbf_kernel(X,Y,gamma=gam)*d

    def my_custom_loss_func(y_true, y_pred):
        error=np.abs((y_true - y_pred)/y_true)
        return np.mean(error)*100

    my_scorer = make_scorer(my_custom_loss_func,greater_is_better=False)


    # Generate sample data 
    X_train=np.random.random((100,6))
    y_train=np.random.random((100,1))
    X_test=np.random.random((40,6))
    y_test=np.random.random((40,1))
    y_train=np.ravel(y_train)
    y_test=np.ravel(y_test)

    # scale the input and output in training data set, also scale the input                                         
    #in testing data set
    max_scale = preprocessing.MaxAbsScaler().fit(X_train)
    X_train_max = max_scale.transform(X_train)
    X_test_max = max_scale.transform(X_test)
    max_scale_y = preprocessing.MaxAbsScaler().fit(y_train)
    y_train_max = max_scale_y.transform(y_train)

    #precompute the kernel matrix
    gam=sea_rbf(X_train_max,X_train_max)

    #grid search for the model with the custom scoring method, but can only tune the *cost c* parameter in this case.
    clf= GridSearchCV(SVR(kernel='precomputed'),
                       scoring=my_scorer,
                       cv=5,
                       param_grid={""C"": [0.1,1,2,3,4,5]
                                   })

    clf.fit(gam, y_train_max)
    print(clf.best_params_)
    print(clf.best_score_)
    print(clf.grid_scores_)
</code></pre>

<p>Part II:Solution with Pipeline</p>

<pre><code>from __future__ import print_function
from __future__ import division

import sys

import sklearn
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline

# Wrapper class for the custom kernel RBF_kernel
class RBF2Kernel(BaseEstimator,TransformerMixin):

    def __init__(self, gamma=1,sea_gamma=20):
        super(RBF2Kernel,self).__init__()
        self.gamma = gamma
        self.sea_gamma = sea_gamma

        def fit(self, X, y=None, **fit_params):
        return self
   #calculate the kernel matrix
    def transform(self, X):
        self.a_train_ = X[:, 0:5]
        self.b_train_ = X[:, 0:5]
        self.t1_train_ = X[:, 5:6]
        self.t2_train_ = X[:, 5:6]
        sea=16
        K = np.zeros((t1.shape[0],t2.shape[0]))

        for i in range(self.t1_train_.shape[0]):
             for j in range(self.t2_train_.shape[0]):
                    dis = min(np.abs(self.t1_train_[i]*sea-        self.t2_train_[j]*sea),sea-np.abs(self.t1_train_[i]*sea-self.t2_train_[j]*sea))
                    K[i,j] = np.exp(-self.gamma_sea *dis**2)
        return K

        return rbf_kernel(self.a_train_ , self.b_train_, gamma=self.gamma)*K

def main():

    print('python: {}'.format(sys.version))
    print('numpy: {}'.format(np.__version__))
    print('sklearn: {}'.format(sklearn.__version__))

    # Generate sample data
    X_train=np.random.random((100,6))
    y_train=np.random.random((100,1))
    X_test=np.random.random((40,6))
    y_test=np.random.random((40,1))
    y_train=np.ravel(y_train)
    y_test=np.ravel(y_test)


    # Create a pipeline where our custom predefined kernel RBF2Kernel
    # is run before SVR.

    pipe = Pipeline([
        ('sc', MaxAbsScaler()),    
        ('rbf2', RBF2Kernel()),
        ('svm', SVR()),
    ])

    # Set the parameter 'gamma' of our custom kernel by
    # using the 'estimator__param' syntax.
    cv_params = dict([
        ('rbf2__gamma', 10.0**np.arange(-2,2)),
        ('rbf2__sea_gamma', 10.0**np.arange(-2,2)),
        ('svm__kernel', ['precomputed']),
        ('svm__C', 10.0**np.arange(-2,2)),
    ])

    # Do grid search to get the best parameter value of 'gamma'.
    # here i am also trying to tune the parameters of the custom kernel
    model = GridSearchCV(pipe, cv_params, verbose=1, n_jobs=-1,scoring=my_scorer)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc_test = mean_absolute_error(y_test, y_pred)
    mape_100 =  my_custom_loss_func (y_test, y_pred)

    print(""Test accuracy: {}"".format(acc_test))
    print(""mape_100: {}"".format(mape_100))
    print(""Best params:"")
    print(model.best_params_)
    print(model.grid_scores_)

if __name__ == '__main__':
    main()
</code></pre>

<p>so, in summary:</p>

<ol>
<li>the example works well, but it can just tune the default parameter(cost parater in this case)</li>
<li>I want to tune the extra parameters from the custom kernel which i have defined it as a function in Part I.</li>
<li>scikit-learn or python is still really new for me, if the explanation is unclear, please let me know if you have any questions for the details. </li>
</ol>

<p>Thanks a lot for your reading, hope the long description would make you a bit more clear, all suggestions are welcomed :)</p>
"
"What's the difference between predict_proba and decision function in Sklearn (Python)?","<p>I'm studying a <a href=""http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"" rel=""noreferrer"">scikit-learn example</a> (Classifier comparison) and got confused with <code>predict_proba</code> and <code>decision_function</code>.</p>

<p>They plot the classification results by drawing the contours using either  <code>Z = clf.decision_function()</code>, or <code>Z = clf.predict_proba()</code>. </p>

<p>What's the differences between these two? Is it so that each classification method has either of the two as score? </p>

<p>Which one is more proper to interpret the classification result and how should I choose from the two?</p>
"
"What is a good heuristic to detect if a column in a pandas.DataFrame is categorical?","<p>I've been developing a tool that automatically preprocesses data in pandas.DataFrame format. During this preprocessing step, I want to treat continuous and categorical data differently. In particular, I want to be able to apply, e.g., a OneHotEncoder to <em>only</em> the categorical data.</p>

<p>Now, let's assume that we're provided a pandas.DataFrame and have no other information about the data in the DataFrame. What is a good heuristic to use to determine whether a column in the pandas.DataFrame is categorical?</p>

<p>My initial thoughts are:</p>

<p>1) If there are strings in the column (e.g., the column data type is <code>object</code>), then the column very likely contains categorical data</p>

<p>2) If some percentage of the values in the column is unique (e.g., >=20%), then the column very likely contains continuous data</p>

<p>I've found <code>1)</code> to work fine, but <code>2)</code> hasn't panned out very well. I need better heuristics. How would you solve this problem?</p>

<p><strong>Edit:</strong> Someone requested that I explain why <code>2)</code> didn't work well. There were some tests cases where we still had continuous values in a column but there weren't many unique values in the column. The heuristic in <code>2)</code> obviously failed in that case. There were also issues where we had a categorical column that had many, many unique values, e.g., passenger names in the Titanic data set. Same column type misclassification problem there.</p>
"
"Combining feature extraction classes in scikit-learn","<p>I'm using <code>sklearn.pipeline.Pipeline</code> to chain feature extractors and a classifier. Is there a way to combine multiple feature selection classes (for example the ones from <code>sklearn.feature_selection.text</code>) in parallel and join their output?</p>

<p>My code right now looks as follows:</p>

<pre><code>pipeline = Pipeline([
    ('vect', CountVectorizer()),
    ('tfidf', TfidfTransformer()),
    ('clf', SGDClassifier())])
</code></pre>

<p>It results in the following:</p>

<pre><code>vect -&gt; tfidf -&gt; clf
</code></pre>

<p>I want to be able to specify a pipeline that looks as follows:</p>

<pre><code>vect1 -&gt; tfidf1 \
                 -&gt; clf
vect2 -&gt; tfidf2 /
</code></pre>
"
"How to normalize an array in NumPy?","<p>I would like to have the norm of one NumPy array. More specifically, I am looking for an equivalent version of this function</p>

<pre><code>def normalize(v):
    norm = np.linalg.norm(v)
    if norm == 0: 
       return v
    return v / norm
</code></pre>

<p>Is there something like that in <code>skearn</code> or <code>numpy</code>?</p>

<p>This function works in a situation where <code>v</code> is the 0 vector.</p>
"
"Efficiently count word frequencies in python","<p>I'd like to count frequencies of all words in a text file.</p>

<pre><code>&gt;&gt;&gt; countInFile('test.txt')
</code></pre>

<p>should return <code>{'aaa':1, 'bbb': 2, 'ccc':1}</code> if the target text file is like:</p>

<pre><code># test.txt
aaa bbb ccc
bbb
</code></pre>

<p>I've implemented it with pure python following <a href=""https://stackoverflow.com/questions/12117576/how-to-count-word-frequencies-within-a-file-in-python"">some posts</a>. However, I've found out pure-python ways are insufficient due to huge file size (> 1GB).</p>

<p>I think borrowing sklearn's power is a candidate.</p>

<p>If you let CountVectorizer count frequencies for each line, I guess you will get word frequencies by summing up each column. But, it sounds a bit indirect way.</p>

<p>What is the most efficient and straightforward way to count words in a file with python?</p>

<h3>Update</h3>

<p>My (very slow) code is here:</p>

<pre><code>from collections import Counter

def get_term_frequency_in_file(source_file_path):
    wordcount = {}
    with open(source_file_path) as f:
        for line in f:
            line = line.lower().translate(None, string.punctuation)
            this_wordcount = Counter(line.split())
            wordcount = add_merge_two_dict(wordcount, this_wordcount)
    return wordcount

def add_merge_two_dict(x, y):
    return { k: x.get(k, 0) + y.get(k, 0) for k in set(x) | set(y) }
</code></pre>
"
"predict_proba for a cross-validated model","<p>I would like to predict the probability from Logistic Regression model with cross-validation. I know you can get the cross-validation scores, but is it possible to return the values from predict_proba instead of the scores?</p>

<pre><code># imports
from sklearn.linear_model import LogisticRegression
from sklearn.cross_validation import (StratifiedKFold, cross_val_score,
                                      train_test_split)
from sklearn import datasets

# setup data
iris = datasets.load_iris()
X = iris.data
y = iris.target

# setup model
cv = StratifiedKFold(y, 10)
logreg = LogisticRegression()

# cross-validation scores
scores = cross_val_score(logreg, X, y, cv=cv)

# predict probabilities
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)
logreg.fit(Xtrain, ytrain)
proba = logreg.predict_proba(Xtest)
</code></pre>
"
"Evaluate multiple scores on sklearn cross_val_score","<p>I'm trying to evaluate multiple machine learning algorithms with sklearn for a couple of metrics (accuracy, recall, precision and maybe more).</p>

<p>For what I understood from the documentation <a href=""http://scikit-learn.org/stable/modules/model_evaluation.html#"" rel=""noreferrer"">here</a> and from the source code(I'm using sklearn 0.17), the <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score"" rel=""noreferrer"">cross_val_score</a> function only receives one scorer for each execution. So for calculating multiple scores, I have to :</p>

<ol>
<li>Execute multiple times</li>
<li><p>Implement my (time consuming and error prone) scorer</p>

<p>I've executed multiple times with this code :</p>

<pre><code>from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.cross_validation import  cross_val_score
import time
from sklearn.datasets import  load_iris

iris = load_iris()

models = [GaussianNB(), DecisionTreeClassifier(), SVC()]
names = [""Naive Bayes"", ""Decision Tree"", ""SVM""]
for model, name in zip(models, names):
    print name
    start = time.time()
    for score in [""accuracy"", ""precision"", ""recall""]:
        print score,
        print "" : "",
        print cross_val_score(model, iris.data, iris.target,scoring=score, cv=10).mean()
    print time.time() - start
</code></pre></li>
</ol>

<p>And I get this output: </p>

<pre><code>Naive Bayes
accuracy  :  0.953333333333
precision  :  0.962698412698
recall  :  0.953333333333
0.0383198261261
Decision Tree
accuracy  :  0.953333333333
precision  :  0.958888888889
recall  :  0.953333333333
0.0494720935822
SVM
accuracy  :  0.98
precision  :  0.983333333333
recall  :  0.98
0.063080072403
</code></pre>

<p>Which is ok, but it's slow for my own data. How can I measure all scores ?</p>
"
"Supervised Dimensionality Reduction for Text Data in scikit-learn","<p>I'm trying to use scikit-learn to do some machine learning on natural language data. I've got my corpus transformed into bag-of-words vectors (which take the form of a sparse CSR matrix) and I'm wondering if there's a supervised dimensionality reduction algorithm in sklearn capable of taking high-dimensional, supervised data and projecting it into a lower dimensional space which preserves the variance between these classes. </p>

<p>The high-level problem description is that I have a collection of documents, each of which can have multiple labels on it, and I want to predict which of those labels will get slapped on a new document based on the content of the document.</p>

<p>At it's core, this is a supervised, multi-label, multi-class problem using a sparse representation of BoW vectors. Is there a dimensionality reduction technique in sklearn that can handle that sort of data? Are there other sorts of techniques people have used in working with supervised, BoW data in scikit-learn?</p>

<p>Thanks! </p>
"
"sklearn GridSearchCV with Pipeline","<p>I'm new to <code>sklearn</code>'s <code>Pipeline</code> and <code>GridSearchCV</code> features.  I am trying to build a pipeline which first does RandomizedPCA on my training data and then fits a ridge regression model.  Here is my code:</p>

<pre><code>pca = RandomizedPCA(1000, whiten=True)
rgn = Ridge()

pca_ridge = Pipeline([('pca', pca),
                      ('ridge', rgn)])

parameters = {'ridge__alpha': 10 ** np.linspace(-5, -2, 3)}

grid_search = GridSearchCV(pca_ridge, parameters, cv=2, n_jobs=1, scoring='mean_squared_error')
grid_search.fit(train_x, train_y[:, 1:])
</code></pre>

<p>I know about the <code>RidgeCV</code> function but I want to try out Pipeline and GridSearch CV.</p>

<p>I want the grid search CV to report RMSE error, but this doesn't seem supported in sklearn so I'm making do with MSE.  However, the scores it resports are negative:</p>

<pre><code>In [41]: grid_search.grid_scores_
Out[41]: 
[mean: -0.02665, std: 0.00007, params: {'ridge__alpha': 1.0000000000000001e-05},
 mean: -0.02658, std: 0.00009, params: {'ridge__alpha': 0.031622776601683791},
 mean: -0.02626, std: 0.00008, params: {'ridge__alpha': 100.0}]
</code></pre>

<p>Obviously this isn't possible for mean squared error - what am I doing wrong here?</p>
"
"How can I call scikit-learn classifiers from Java?","<p>I have a classifier that I trained using Python's scikit-learn. How can I use the classifier from a Java program? Can I use Jython? Is there some way to save the classifier in Python and load it in Java? Is there some other way to use it?</p>
"
"sklearn.LabelEncoder with never seen before values","<p>If a <code>sklearn.LabelEncoder</code> has been fitted on a training set, it might break if it encounters new values when used on a test set.</p>

<p>The only solution I could come up with for this is to map everything new in the test set (i.e. not belonging to any existing class) to <code>""&lt;unknown&gt;""</code>, and then explicitly add a corresponding class to the <code>LabelEncoder</code> afterward:</p>

<pre><code># train and test are pandas.DataFrame's and c is whatever column
le = LabelEncoder()
train[c] = le.fit_transform(train[c])
test[c] = test[c].map(lambda s: '&lt;unknown&gt;' if s not in le.classes_ else s)
le.classes_ = np.append(le.classes_, '&lt;unknown&gt;')
test[c] = le.transform(test[c])
</code></pre>

<p>This works, but is there a better solution?</p>

<p><strong>Update</strong></p>

<p>As @sapo_cosmico points out in a comment, it seems that the above doesn't work anymore, given what I assume is an implementation change in <code>LabelEncoder.transform</code>, which now seems to use <code>np.searchsorted</code> (I don't know if it was the case before). So instead of appending the <code>&lt;unknown&gt;</code> class to the <code>LabelEncoder</code>'s list of already extracted classes, it needs to be inserted in sorted order:</p>

<pre><code>import bisect
le_classes = le.classes_.tolist()
bisect.insort_left(le_classes, '&lt;unknown&gt;')
le.classes_ = le_classes
</code></pre>

<p>However, as this feels pretty clunky all in all, I'm certain there is a better approach for this.</p>
"
"Regression trees or Random Forest regressor with categorical inputs","<p>I have been trying to use a categorical inpust in a regression tree (or Random Forest Regressor) but sklearn keeps returning errors and asking for numerical inputs.</p>

<pre><code>import sklearn as sk
MODEL = sk.ensemble.RandomForestRegressor(n_estimators=100)
MODEL.fit([('a',1,2),('b',2,3),('a',3,2),('b',1,3)], [1,2.5,3,4]) # does not work
MODEL.fit([(1,1,2),(2,2,3),(1,3,2),(2,1,3)], [1,2.5,3,4]) #works

MODEL = sk.tree.DecisionTreeRegressor()
MODEL.fit([('a',1,2),('b',2,3),('a',3,2),('b',1,3)], [1,2.5,3,4]) # does not work
MODEL.fit([(1,1,2),(2,2,3),(1,3,2),(2,1,3)], [1,2.5,3,4]) #works
</code></pre>

<p>To my understanding, categorical inputs should be possible in these methods without any conversion (e.g. WOE substitution).</p>

<p>Has anyone else had this difficulty?</p>

<p>thanks!</p>
"
"Why are LASSO in sklearn (python) and matlab statistical package different?","<p>I am using <code>LaasoCV</code> from <code>sklearn</code> to select the best model is selected by cross-validation. I found that the cross validation gives different result if I use sklearn or matlab statistical toolbox.</p>

<p>I used <code>matlab</code> and replicate the example given in 
<a href=""http://www.mathworks.se/help/stats/lasso-and-elastic-net.html"" rel=""noreferrer"">http://www.mathworks.se/help/stats/lasso-and-elastic-net.html</a>
to get a figure like this</p>

<p><img src=""https://i.stack.imgur.com/Xu3vk.png"" alt=""enter image description here""></p>

<p>Then I saved the <code>matlab</code> data, and tried to replicate the figure with <code>laaso_path</code> from <code>sklearn</code>, I got </p>

<p><img src=""https://i.stack.imgur.com/rME6q.png"" alt=""enter image description here""></p>

<p>Although there are some similarity between these two figures, there are also certain differences. As far as I understand parameter <code>lambda</code> in <code>matlab</code> and <code>alpha</code> in <code>sklearn</code> are same, however in this figure it seems that there are some differences. Can somebody point out which is the correct one or am I missing something? Further the coefficient obtained are also different (which is my main concern).</p>

<p><strong>Matlab Code:</strong></p>

<pre><code>rng(3,'twister') % for reproducibility
X = zeros(200,5);
for ii = 1:5
      X(:,ii) = exprnd(ii,200,1);
end
r = [0;2;0;-3;0];
Y = X*r + randn(200,1)*.1;

save randomData.mat % To be used in python code

[b fitinfo] = lasso(X,Y,'cv',10);
lassoPlot(b,fitinfo,'plottype','lambda','xscale','log');

disp('Lambda with min MSE')
fitinfo.LambdaMinMSE
disp('Lambda with 1SE')
fitinfo.Lambda1SE
disp('Quality of Fit')
lambdaindex = fitinfo.Index1SE;
fitinfo.MSE(lambdaindex)
disp('Number of non zero predictos')
fitinfo.DF(lambdaindex)
disp('Coefficient of fit at that lambda')
b(:,lambdaindex)
</code></pre>

<p><strong>Python Code:</strong></p>

<pre><code>import scipy.io
import numpy as np
import pylab as pl
from sklearn.linear_model import lasso_path, LassoCV

data=scipy.io.loadmat('randomData.mat')
X=data['X']
Y=data['Y'].flatten()

model = LassoCV(cv=10,max_iter=1000).fit(X, Y)
print 'alpha', model.alpha_
print 'coef', model.coef_

eps = 1e-2 # the smaller it is the longer is the path
models = lasso_path(X, Y, eps=eps)
alphas_lasso = np.array([model.alpha for model in models])
coefs_lasso = np.array([model.coef_ for model in models])

pl.figure(1)
ax = pl.gca()
ax.set_color_cycle(2 * ['b', 'r', 'g', 'c', 'k'])
l1 = pl.semilogx(alphas_lasso,coefs_lasso)
pl.gca().invert_xaxis()
pl.xlabel('alpha')
pl.show()
</code></pre>
"
"How do I solve overfitting in random forest of Python sklearn?","<p>I am using RandomForestClassifier implemented in python sklearn package to build a binary classification model. The below is the results of cross validations:</p>

<pre><code>Fold 1 : Train: 164  Test: 40
Train Accuracy: 0.914634146341
Test Accuracy: 0.55

Fold 2 : Train: 163  Test: 41
Train Accuracy: 0.871165644172
Test Accuracy: 0.707317073171

Fold 3 : Train: 163  Test: 41
Train Accuracy: 0.889570552147
Test Accuracy: 0.585365853659

Fold 4 : Train: 163  Test: 41
Train Accuracy: 0.871165644172
Test Accuracy: 0.756097560976

Fold 5 : Train: 163  Test: 41
Train Accuracy: 0.883435582822
Test Accuracy: 0.512195121951
</code></pre>

<p>I am using ""Price"" feature to predict ""quality"" which is a ordinal value. In each cross validation, there are 163 training examples and 41 test examples. </p>

<p>Apparently, overfitting occurs here. So is there any parameters provided by sklearn can be used to overcome this problem? I found some parameters <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"">here</a>, e.g. min_samples_split and min_sample_leaf, but I do not quite understand how to tune them.</p>

<p>Thanks in advance!</p>
"
"Scikit Learn SVC decision_function and predict","<p>I'm trying to understand the relationship between decision_function and predict, which are instance methods of SVC  (<a href=""http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"" rel=""noreferrer"">http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html</a>). So far I've gathered that decision function returns pairwise scores between classes. I was under the impression that predict chooses the class that maximizes its pairwise score, but I tested this out and got different results. Here's the code I was using to try and understand the relationship between the two. First I generated the pairwise score matrix, and then I printed out the class that has maximal pairwise score which was different than the class predicted by clf.predict.</p>

<pre><code>        result = clf.decision_function(vector)[0]
        counter = 0
        num_classes = len(clf.classes_)
        pairwise_scores = np.zeros((num_classes, num_classes))
        for r in xrange(num_classes):
            for j in xrange(r + 1, num_classes):
                pairwise_scores[r][j] = result[counter]
                pairwise_scores[j][r] = -result[counter]
                counter += 1

        index = np.argmax(pairwise_scores)
        class = index_star / num_classes
        print class
        print clf.predict(vector)[0]
</code></pre>

<p>Does anyone know the relationship between these predict and decision_function?</p>
"
"Prepare data for text classification using Scikit Learn SVM","<p>I'm trying to apply SVM from Scikit learn to classify the tweets I collected.
So, there will be two categories, name them A and B.
For now, I have all the tweets categorized in two text file, 'A.txt' and 'B.txt'.
However, I'm not sure what type of data inputs the Scikit Learn SVM is asking for.
I have a dictionary with labels (A and B) as its keys and a dictionary of features (unigrams) and their frequencies as values.
Sorry, I'm really new to machine learning and not sure what I should do to get the SVM work.
And I found that SVM is using numpy.ndarray as the type of its data input. Do I need to create one based on my own data?
Should it be something like this?</p>

<pre><code>Labels    features    frequency
  A        'book'        54
  B       'movies'       32
</code></pre>

<p>Any help is appreciated.</p>
"
"Getting model attributes from scikit-learn pipeline","<p>I typically get <code>PCA</code> loadings like this:</p>

<pre><code>pca = PCA(n_components=2)
X_t = pca.fit(X).transform(X)
loadings = pca.components_
</code></pre>

<p>If I run <code>PCA</code> using a <code>scikit-learn</code> pipline ...</p>

<pre><code>from sklearn.pipeline import Pipeline
pipeline = Pipeline(steps=[    
('scaling',StandardScaler()),
('pca',PCA(n_components=2))
])
X_t=pipeline.fit_transform(X)
</code></pre>

<p>... is it possible to get the loadings?</p>

<p>Simply trying <code>loadings = pipeline.components_</code> fails:</p>

<pre><code>AttributeError: 'Pipeline' object has no attribute 'components_'
</code></pre>

<p>Thanks!</p>

<p>(Also interested in extracting attributes like <code>coef_</code> from learning pipelines.)</p>
"
"How do I get the components for LDA in scikit-learn?","<p>When using PCA in sklearn, it's easy to get out the components:</p>

<pre><code>from sklearn import decomposition
pca = decomposition.PCA(n_components=n_components)
pca_data = pca.fit(input_data)
pca_components = pca.components_
</code></pre>

<p>But I can't for the life of me figure out how to get the components out of LDA, as there is no components_ attribute. Is there a similar attribute in sklearn lda?</p>
"
"How to plot scikit learn classification report?","<p>Is it possible to plot with matplotlib scikit-learn classification report?. Let's assume I print the classification report like this:</p>

<pre><code>print '\n*Classification Report:\n', classification_report(y_test, predictions)
    confusion_matrix_graph = confusion_matrix(y_test, predictions)
</code></pre>

<p>and I get:</p>

<pre><code>Clasification Report:
             precision    recall  f1-score   support

          1       0.62      1.00      0.76        66
          2       0.93      0.93      0.93        40
          3       0.59      0.97      0.73        67
          4       0.47      0.92      0.62       272
          5       1.00      0.16      0.28       413

avg / total       0.77      0.57      0.49       858
</code></pre>

<p>How can I ""plot"" the avobe chart?.</p>
"
"How do I find which attributes my tree splits on, when using scikit-learn?","<p>I have been exploring scikit-learn, making decision trees with both entropy and gini splitting criteria, and exploring the differences.</p>

<p>My question, is how can I ""open the hood"" and find out exactly which attributes the trees are splitting on at each level, along with their associated information values, so I can see where the two criterion make different choices?</p>

<p>So far, I have explored the 9 methods outlined in the documentation.  They don't appear to allow access to this information.  But surely this information is accessible?  I'm envisioning a list or dict that has entries for node and gain.</p>

<p>Thanks for your help and my apologies if I've missed something completely obvious.</p>
"
"show feature names after feature selection","<p>I need to build a classifier for text, and now I'm using TfidfVectorizer and SelectKBest to selection the features, as following:</p>

<pre><code>vectorizer = TfidfVectorizer(sublinear_tf = True, max_df = 0.5, stop_words = 'english',charset_error='strict')

X_train_features = vectorizer.fit_transform(data_train.data)
y_train_labels = data_train.target;

ch2 = SelectKBest(chi2, k = 1000)
X_train_features = ch2.fit_transform(X_train_features, y_train_labels)
</code></pre>

<p>I want to print out selected features name(text) after select k best features, is there any way to do that? I just need to print out selected feature names, maybe I should use CountVectorizer instead?</p>
"
"Non-Integer Class Labels Scikit-Learn","<p>Quick SVM question for scikit-learn. When you train an SVM, it's something like</p>

<pre><code>from sklearn import svm
s = svm.SVC()
s.fit(training_data, labels)
</code></pre>

<p>Is there any way for <code>labels</code> to be a list of a non-numeric type? For instance, if I want to classify vectors as 'cat' or 'dog,' without having to have some kind of external lookup table that encodes 'cat' and 'dog' into 1's and 2's. When I try to just pass a list of strings, I get ...</p>

<p><code>ValueError: invalid literal for float(): cat</code></p>

<p>So, it doesn't look like just shoving strings in <code>labels</code> will work. Any ideas?</p>
"
"Panda's get_dummies vs. Sklearn's OneHotEncoder() :: What is more efficient?","<p>I'm learning different methods to convert categorical variables to numeric for machine-learning classifiers.  I came across the <code>pd.get_dummies</code> method and <code>sklearn.preprocessing.OneHotEncoder()</code> and I wanted to see how they differed in terms of performance and usage. </p>

<p>I found a tutorial on how to use <code>OneHotEnocder()</code> on <a href=""https://xgdgsc.wordpress.com/2015/03/20/note-on-using-onehotencoder-in-scikit-learn-to-work-on-categorical-features/"">https://xgdgsc.wordpress.com/2015/03/20/note-on-using-onehotencoder-in-scikit-learn-to-work-on-categorical-features/</a> since the <code>sklearn</code> documentation wasn't too helpful on this feature. I have a feeling I'm not doing it correctly...but</p>

<p><strong>Can some explain the pros and cons of using <code>pd.dummies</code> over <code>sklearn.preprocessing.OneHotEncoder()</code> and vice versa?</strong> I know that <code>OneHotEncoder()</code> gives you a sparse matrix but other than that I'm not sure how it is used and what the benefits are over the <code>pandas</code> method.  Am I using it inefficiently? </p>

<pre><code>import pandas as pd
import numpy as np
from sklearn.datasets import load_iris
sns.set()

%matplotlib inline

#Iris Plot
iris = load_iris()
n_samples, m_features = iris.data.shape

#Load Data
X, y = iris.data, iris.target
D_target_dummy = dict(zip(np.arange(iris.target_names.shape[0]), iris.target_names))

DF_data = pd.DataFrame(X,columns=iris.feature_names)
DF_data[""target""] = pd.Series(y).map(D_target_dummy)
#sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \
#0                  5.1               3.5                1.4               0.2   
#1                  4.9               3.0                1.4               0.2   
#2                  4.7               3.2                1.3               0.2   
#3                  4.6               3.1                1.5               0.2   
#4                  5.0               3.6                1.4               0.2   
#5                  5.4               3.9                1.7               0.4   

DF_dummies = pd.get_dummies(DF_data[""target""])
#setosa  versicolor  virginica
#0         1           0          0
#1         1           0          0
#2         1           0          0
#3         1           0          0
#4         1           0          0
#5         1           0          0

from sklearn.preprocessing import OneHotEncoder, LabelEncoder
def f1(DF_data):
    Enc_ohe, Enc_label = OneHotEncoder(), LabelEncoder()
    DF_data[""Dummies""] = Enc_label.fit_transform(DF_data[""target""])
    DF_dummies2 = pd.DataFrame(Enc_ohe.fit_transform(DF_data[[""Dummies""]]).todense(), columns = Enc_label.classes_)
    return(DF_dummies2)

%timeit pd.get_dummies(DF_data[""target""])
#1000 loops, best of 3: 777 µs per loop

%timeit f1(DF_data)
#100 loops, best of 3: 2.91 ms per loop
</code></pre>
"
"predict_proba or decision_function as estimator ""confidence""","<p>I'm using LogisticRegression as a model to train an estimator in scikit-learn. The features I use are (mostly) categorical; and so are the labels. Therefore, I use a DictVectorizer and a LabelEncoder, respectively, to encode the values properly. </p>

<p>The training part is fairly straightforward, but I'm having problems with the test part. The simple thing to do is to use the ""predict"" method of the trained model and get the predicted label. However, for the processing I need to do afterwards, I need the probability for each possible label (class) for each particular instance. I decided to use the ""predict_proba"" method. However, I get different results for the same test instance, whether I use this method when the instance is by itself or accompanied by others. </p>

<p>Next, is a code that reproduces the problem.</p>

<pre><code>from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction import DictVectorizer
from sklearn.preprocessing import LabelEncoder


X_real = [{'head': u'n\xe3o', 'dep_rel': u'ADVL'}, 
          {'head': u'v\xe3o', 'dep_rel': u'ACC'}, 
          {'head': u'empresa', 'dep_rel': u'SUBJ'}, 
          {'head': u'era', 'dep_rel': u'ACC'}, 
          {'head': u't\xeam', 'dep_rel': u'ACC'}, 
          {'head': u'import\xe2ncia', 'dep_rel': u'PIV'}, 
          {'head': u'balan\xe7o', 'dep_rel': u'SUBJ'}, 
          {'head': u'ocupam', 'dep_rel': u'ACC'}, 
          {'head': u'acesso', 'dep_rel': u'PRED'}, 
          {'head': u'elas', 'dep_rel': u'SUBJ'}, 
          {'head': u'assinaram', 'dep_rel': u'ACC'}, 
          {'head': u'agredido', 'dep_rel': u'SUBJ'}, 
          {'head': u'pol\xedcia', 'dep_rel': u'ADVL'}, 
          {'head': u'se', 'dep_rel': u'ACC'}] 
y_real = [u'AM-NEG', u'A1', u'A0', u'A1', u'A1', u'A1', u'A0', u'A1', u'AM-ADV', u'A0', u'A1', u'A0', u'A2', u'A1']

feat_encoder =  DictVectorizer()
feat_encoder.fit(X_real)

label_encoder = LabelEncoder()
label_encoder.fit(y_real)

model = LogisticRegression()
model.fit(feat_encoder.transform(X_real), label_encoder.transform(y_real))

print ""Test 1...""
X_test1 = [{'head': u'governo', 'dep_rel': u'SUBJ'}]
X_test1_encoded = feat_encoder.transform(X_test1)
print ""Features Encoded""
print X_test1_encoded
print ""Shape""
print X_test1_encoded.shape
print ""decision_function:""
print model.decision_function(X_test1_encoded)
print ""predict_proba:""
print model.predict_proba(X_test1_encoded)

print ""Test 2...""
X_test2 = [{'head': u'governo', 'dep_rel': u'SUBJ'}, 
           {'head': u'atrav\xe9s', 'dep_rel': u'ADVL'}, 
           {'head': u'configuram', 'dep_rel': u'ACC'}]

X_test2_encoded = feat_encoder.transform(X_test2)
print ""Features Encoded""
print X_test2_encoded
print ""Shape""
print X_test2_encoded.shape
print ""decision_function:""
print model.decision_function(X_test2_encoded)
print ""predict_proba:""
print model.predict_proba(X_test2_encoded)


print ""Test 3...""
X_test3 = [{'head': u'governo', 'dep_rel': u'SUBJ'}, 
           {'head': u'atrav\xe9s', 'dep_rel': u'ADVL'}, 
           {'head': u'configuram', 'dep_rel': u'ACC'},
           {'head': u'configuram', 'dep_rel': u'ACC'},]

X_test3_encoded = feat_encoder.transform(X_test3)
print ""Features Encoded""
print X_test3_encoded
print ""Shape""
print X_test3_encoded.shape
print ""decision_function:""
print model.decision_function(X_test3_encoded)
print ""predict_proba:""
print model.predict_proba(X_test3_encoded)
</code></pre>

<p>Following is the output obtained:</p>

<pre><code>Test 1...
Features Encoded
  (0, 4)    1.0
Shape
(1, 19)
decision_function:
[[ 0.55372615 -1.02949707 -1.75474347 -1.73324726 -1.75474347]]
predict_proba:
[[ 1.  1.  1.  1.  1.]]
Test 2...
Features Encoded
  (0, 4)    1.0
  (1, 1)    1.0
  (2, 0)    1.0
Shape
(3, 19)
decision_function:
[[ 0.55372615 -1.02949707 -1.75474347 -1.73324726 -1.75474347]
 [-1.07370197 -0.69103629 -0.89306092 -1.51402163 -0.89306092]
 [-1.55921001  1.11775556 -1.92080112 -1.90133404 -1.92080112]]
predict_proba:
[[ 0.59710757  0.19486904  0.26065002  0.32612646  0.26065002]
 [ 0.23950111  0.24715931  0.51348452  0.3916478   0.51348452]
 [ 0.16339132  0.55797165  0.22586546  0.28222574  0.22586546]]
Test 3...
Features Encoded
  (0, 4)    1.0
  (1, 1)    1.0
  (2, 0)    1.0
  (3, 0)    1.0
Shape
(4, 19)
decision_function:
[[ 0.55372615 -1.02949707 -1.75474347 -1.73324726 -1.75474347]
 [-1.07370197 -0.69103629 -0.89306092 -1.51402163 -0.89306092]
 [-1.55921001  1.11775556 -1.92080112 -1.90133404 -1.92080112]
 [-1.55921001  1.11775556 -1.92080112 -1.90133404 -1.92080112]]
predict_proba:
[[ 0.5132474   0.12507868  0.21262531  0.25434403  0.21262531]
 [ 0.20586462  0.15864173  0.4188751   0.30544372  0.4188751 ]
 [ 0.14044399  0.3581398   0.1842498   0.22010613  0.1842498 ]
 [ 0.14044399  0.3581398   0.1842498   0.22010613  0.1842498 ]]
</code></pre>

<p>As can be seen, the values obtained with ""predict_proba"" for the instance in ""X_test1"" change when that same instance is with others in X_test2. Also, ""X_test3"" just reproduces the ""X_test2"" and adds one more instance (that is equal to the last in ""X_test2""), but the probability values for all of them change. Why does this happen?
Also, I find it really strange that ALL the probabilities for ""X_test1"" are 1, shouldn't the sum of all be 1?</p>

<p>Now, if instead of using ""predict_proba"" I use ""decision_function"", I get the consistency in the values obtained that I need. The problem is that I get negative coefficients, and even some of the positives ones are greater than 1. </p>

<p>So, what should I use? Why do the values of ""predict_proba"" change that way? Am I not understanding correctly what those values mean?</p>

<p>Thanks in advance for any help you could give me.</p>

<p><strong>UPDATE</strong></p>

<p>As suggested, I changed the code so as to also print the encoded ""X_test1"", ""X_test2"" and ""X_test3"", as well as their shapes. This doesn't appear to be the problem, as the encoding is consistant for the same instances between the test sets. </p>
"
"Save python random forest model to file","<p>In R, after running ""random forest"" model, I can use <code>save.image(""***.RData"")</code> to store the model. Afterwards, I can just load the model to do predictions directly.</p>

<p>Can you do a similar thing in python? I separate the Model and Prediction into two files. And in Model file:</p>

<pre><code>rf= RandomForestRegressor(n_estimators=250, max_features=9,compute_importances=True)
fit= rf.fit(Predx, Predy)
</code></pre>

<p>I tried to return <code>rf</code> or <code>fit</code>, but still can't load the model in the prediction file.</p>

<p>Can you separate the model and prediction using the sklearn random forest package?</p>
"
"Mixing categorial and continuous data in Naive Bayes classifier using scikit-learn","<p>I'm using scikit-learn in Python to develop a classification algorithm to predict the gender of certain customers. Amongst others, I want to use the Naive Bayes classifier but my problem is that I have a mix of categorical data (ex: ""Registered online"", ""Accepts email notifications"" etc) and continuous data (ex: ""Age"", ""Length of membership"" etc). I haven't used scikit much before but I suppose that that Gaussian Naive Bayes is suitable for continuous data and that Bernoulli Naive Bayes can be used for categorical data. However, since I want to have <strong>both</strong> categorical and continuous data in my model, I don't really know how to handle this. Any ideas would be much appreciated!</p>
"
"Using scikit-learn NMF with a precomputed set of basis vectors (Python)","<p>I want to use scikit-learn NMF (from <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html"" rel=""noreferrer"">here</a>) (or any other NMF if it does the job, actually).</p>

<p>Specifically, I have an input matrix (which is an audio magnitude spectrogram), and I want to decompose it.</p>

<p>I already have the W matrix pre-computed. How do I use a <strong>fixed W</strong> in <code>sklearn.decompose.NMF</code>? I haven't found any other question asking this.</p>

<p>I see that <a href=""https://librosa.github.io/librosa/generated/librosa.decompose.decompose.html"" rel=""noreferrer"">this</a> method also mentions something similar in the <em>fit</em> parameter: ""If False, components are assumed to be pre-computed and stored in transformer, and are not changed."". However, I am not sure how to make that transformer object.</p>
"
"What is python's equivalent of R's NA?","<p>What is python's equivalent of R's NA?</p>

<p>To be more specific:
R has NaN, NA, NULL, Inf and -Inf. NA is generally used when there is missing data. What is python's equivalent?</p>

<p>How libraries such as numpy and pandas handle missing values?</p>

<p>How does scikit-learn handle missing values?</p>

<p>Is it different for python 2.7 and python 3?</p>
"
"Factor Loadings using sklearn","<p>I want the correlations between individual variables and principal components in python.
I am using PCA in sklearn. I don't understand how can I achieve the loading matrix after I have decomposed my data? My code is here.</p>

<pre><code>iris = load_iris()
data, y = iris.data, iris.target
pca = PCA(n_components=2)
transformed_data = pca.fit(data).transform(data)
eigenValues = pca.explained_variance_ratio_
</code></pre>

<p><a href=""http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"">http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html</a> doesn't mention how this can be achieved.</p>
"
"Using DictVectorizer with sklearn DecisionTreeClassifier","<p>I try to start a decision tree with python and sklearn.
Working approach was like this:</p>

<pre><code>import pandas as pd
from sklearn import tree

for col in set(train.columns):
    if train[col].dtype == np.dtype('object'):
        s = np.unique(train[col].values)
        mapping = pd.Series([x[0] for x in enumerate(s)], index = s)
        train_fea = train_fea.join(train[col].map(mapping))
    else:
        train_fea = train_fea.join(train[col])

dt = tree.DecisionTreeClassifier(min_samples_split=3,
                             compute_importances=True,max_depth=5)
dt.fit(train_fea, labels)
</code></pre>

<p>Now I try to make the same thing with DictVectorizer, but my code doesn't work:</p>

<pre><code>from sklearn.feature_extraction import DictVectorizer

vec = DictVectorizer(sparse=False)
train_fea = vec.fit_transform([dict(enumerate(sample)) for sample in train])

dt = tree.DecisionTreeClassifier(min_samples_split=3,
                             compute_importances=True,max_depth=5)
dt.fit(train_fea, labels)
</code></pre>

<p>I've got a error in last line: ""ValueError: Number of labels=332448 does not match number of samples=55"". As I learnt from documentation DictVectorize was designed to transform nominal features into numerical ones. What do I do wrong?</p>

<p>corrected (thanks ogrisel for pushing me to make a full example):</p>

<pre><code>import pandas as pd
import numpy as np
from sklearn import tree

##################################
#  working example
train = pd.DataFrame({'a' : ['a', 'b', 'a'], 'd' : ['e', 'e', 'f'],
                  'b' : [0, 1, 1], 'c' : ['b', 'c', 'b']})
columns = set(train.columns)
columns.remove('b')
train_fea = train[['b']]

for col in columns:
    if train[col].dtype == np.dtype('object'):
        s = np.unique(train[col].values)
        mapping = pd.Series([x[0] for x in enumerate(s)], index = s)
        train_fea = train_fea.join(train[col].map(mapping))
    else:
        train_fea = train_fea.join(train[col])

dt = tree.DecisionTreeClassifier(min_samples_split=3,
                         compute_importances=True,max_depth=5)
dt.fit(train_fea, train['c'])

##########################################
# example with DictVectorizer and error

from sklearn.feature_extraction import DictVectorizer

vec = DictVectorizer(sparse=False)
train_fea = vec.fit_transform([dict(enumerate(sample)) for sample in train])

dt = tree.DecisionTreeClassifier(min_samples_split=3,
                         compute_importances=True,max_depth=5)
dt.fit(train_fea, train['c'])
</code></pre>

<p>Last code was fixed with a help of ogrisel:</p>

<pre><code>import pandas as pd
from sklearn import tree
from sklearn.feature_extraction import DictVectorizer
from sklearn import preprocessing

train = pd.DataFrame({'a' : ['a', 'b', 'a'], 'd' : ['e', 'x', 'f'],
                  'b' : [0, 1, 1], 'c' : ['b', 'c', 'b']})

# encode labels
labels = train[['c']]
le = preprocessing.LabelEncoder()
labels_fea = le.fit_transform(labels) 
# vectorize training data
del train['c']
train_as_dicts = [dict(r.iteritems()) for _, r in train.iterrows()]
train_fea = DictVectorizer(sparse=False).fit_transform(train_as_dicts)
# use decision tree
dt = tree.DecisionTreeClassifier()
dt.fit(train_fea, labels_fea)
# transform result
predictions = le.inverse_transform(dt.predict(train_fea).astype('I'))
predictions_as_dataframe = train.join(pd.DataFrame({""Prediction"": predictions}))
print predictions_as_dataframe
</code></pre>

<p>everything works</p>
"
"How to apply standardization to SVMs in scikit-learn?","<p>I'm using the current stable version 0.13 of scikit-learn. I'm applying a linear support vector classifier to some data using the class <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC"" rel=""noreferrer""><code>sklearn.svm.LinearSVC</code></a>.</p>

<p>In the <a href=""http://scikit-learn.org/stable/modules/preprocessing.html"" rel=""noreferrer"">chapter about preprocessing</a> in scikit-learn's documentation, I've read the following:</p>

<blockquote>
  <p>Many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger that others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.</p>
</blockquote>

<p><strong>Question 1:</strong> Is standardization useful for SVMs in general, also for those with a linear kernel function as in my case?</p>

<p><strong>Question 2:</strong> As far as I understand, I have to compute the mean and standard deviation on the training data and apply this same transformation on the test data using the class <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler"" rel=""noreferrer""><code>sklearn.preprocessing.StandardScaler</code></a>. However, what I don't understand is whether I have to transform the training data as well or just the test data prior to feeding it to the SVM classifier. </p>

<p>That is, do I have to do this:</p>

<pre><code>scaler = StandardScaler()
scaler.fit(X_train)                # only compute mean and std here
X_test = scaler.transform(X_test)  # perform standardization by centering and scaling

clf = LinearSVC()
clf.fit(X_train, y_train)
clf.predict(X_test)
</code></pre>

<p>Or do I have to do this:</p>

<pre><code>scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)  # compute mean, std and transform training data as well
X_test = scaler.transform(X_test)  # same as above

clf = LinearSVC()
clf.fit(X_train, y_train)
clf.predict(X_test)
</code></pre>

<p>In short, do I have to use <code>scaler.fit(X_train)</code> or <code>scaler.fit_transform(X_train)</code> on the training data in order to get reasonable results with <code>LinearSVC</code>?</p>
"
"sklearn logistic regression with unbalanced classes","<p>I'm solving a classification problem with sklearn's logistic regression in python.</p>

<p>My problem is a general/generic one.  I have a dataset with two classes/result (positive/negative or 1/0), but the set is highly unbalanced.  There are ~5% positives and ~95% negatives.</p>

<p>I know there are a number of ways to deal with an unbalanced problem like this, but have not found a good explanation of how to implement properly using the sklearn package.</p>

<p>What I've done thus far is to build a balanced training set by selecting entries with a positive outcome and an equal number of randomly selected negative entries.  I can then train the model to this set, but I'm stuck with how to modify the model to then work on the original unbalanced population/set.</p>

<p>What are the specific steps to do this?  I've poured over the sklearn documentation and examples and haven't found a good explanation.</p>
"
"sklearn selectKbest: which variables were chosen?","<p>I'm trying to get sklearn to select the best k variables (for example k=1) for a linear regression. This works and I can get the R-squared, but it doesn't tell me which variables were the best. How can I find that out?</p>

<p>I have code of the following form (real variable list is much longer):</p>

<pre><code>X=[]
for i in range(len(df)):
X.append([averageindegree[i],indeg3_sum[i],indeg5_sum[i],indeg10_sum[i])


training=[]
actual=[]
counter=0
for fold in range(500):
    X_train, X_test, y_train, y_test = crossval.train_test_split(X, y, test_size=0.3)
    clf = LinearRegression()
    #clf = RidgeCV()
    #clf = LogisticRegression()
    #clf=ElasticNetCV()

    b = fs.SelectKBest(fs.f_regression, k=1) #k is number of features.
    b.fit(X_train, y_train)
    #print b.get_params

    X_train = X_train[:, b.get_support()]
    X_test = X_test[:, b.get_support()]


    clf.fit(X_train,y_train)
    sc = clf.score(X_train, y_train)
    training.append(sc)
    #print ""The training R-Squared for fold "" + str(1) + "" is "" + str(round(sc*100,1))+""%""
    sc = clf.score(X_test, y_test)
    actual.append(sc)
    #print ""The actual R-Squared for fold "" + str(1) + "" is "" + str(round(sc*100,1))+""%""
</code></pre>
"
"Keep pandas structure with numpy/scikit functions","<p>I'm using the excellent <code>read_csv()</code>function from pandas, which gives:</p>

<pre><code>In [31]: data = pandas.read_csv(""lala.csv"", delimiter="","")

In [32]: data
Out[32]: 
&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 12083 entries, 0 to 12082
Columns: 569 entries, REGIONC to SCALEKER
dtypes: float64(51), int64(518)
</code></pre>

<p>but when i apply a function from scikit-learn i loose the informations about columns:</p>

<pre><code>from sklearn import preprocessing
preprocessing.scale(data)
</code></pre>

<p>gives numpy array.</p>

<p>Is there a way to apply scikit or numpy function to DataFrames without loosing the information?</p>
"
"Best way to combine probabilistic classifiers in scikit-learn","<p>I have a logistic regression and a random forest and I'd like to combine them (ensemble) for the final classification probability calculation by taking an average.</p>

<p>Is there a built-in way to do this in sci-kit learn?  Some way where I can use the ensemble of the two as a classifier itself?  Or would I need to roll my own classifier?</p>
"
"I have much more than 3 elements in every class but i get this error: class cannot be less than k=3 in scikit-learn","<p>This is my target (y): </p>

<pre><code>target = [7,1,2,2,3,5,4,
      1,3,1,4,4,6,6,
      7,5,7,8,8,8,5,
      3,3,6,2,7,7,1,
      10,3,7,10,4,10,
      2,2,2,7]
</code></pre>

<p>I do not know why while i'm executing :
    ...
    # Split the dataset in two equal parts
    X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.5, random_state=0)</p>

<pre><code># Set the parameters by cross-validation
tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],
                 'C': [1, 10, 100, 1000]},
                {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]

scores = ['precision', 'recall']

for score in scores:
    print(""# Tuning hyper-parameters for %s"" % score)
    print()

    clf = GridSearchCV(SVC(C=1), tuned_parameters)#scoring non esiste
    #I get error in the line below
    clf.fit(X_train, y_train, cv=5) 
...
</code></pre>

<p>i get this error:</p>

<pre><code>Traceback (most recent call last):
  File ""C:\Python27\SVMpredictCROSSeGRID.py"", line 232, in &lt;module&gt;
clf.fit(X_train, y_train, cv=5)  #The minimum number of labels for any class cannot be less than k=3.
File ""C:\Python27\lib\site-packages\sklearn\grid_search.py"", line 354, in fit
return self._fit(X, y)
File ""C:\Python27\lib\site-packages\sklearn\grid_search.py"", line 372, in _fit
cv = check_cv(cv, X, y, classifier=is_classifier(estimator))
File ""C:\Python27\lib\site-packages\sklearn\cross_validation.py"", line 1148, in check_cv
cv = StratifiedKFold(y, cv, indices=is_sparse)
File ""C:\Python27\lib\site-packages\sklearn\cross_validation.py"", line 358, in __init__
"" be less than k=%d."" % (min_labels, k))
ValueError: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than k=3.
</code></pre>
"
"scikit-learn cross validation, negative values with mean squared error","<p>When I use the following code with Data matrix <code>X</code> of size (952,144) and output vector <code>y</code> of size (952), <code>mean_squared_error</code> metric returns negative values, which is unexpected. Do you have any idea?</p>

<pre><code>from sklearn.svm import SVR
from sklearn import cross_validation as CV

reg = SVR(C=1., epsilon=0.1, kernel='rbf')
scores = CV.cross_val_score(reg, X, y, cv=10, scoring='mean_squared_error')
</code></pre>

<p>all values in <code>scores</code> are then negative.</p>
"
"How is the TFIDFVectorizer in scikit-learn supposed to work?","<p>I'm trying to get words that are distinctive of certain documents using the TfIDFVectorizer class in scikit-learn. It creates a tfidf matrix with all the words and their scores in all the documents, but then it seems to count common words, as well. This is some of the code I'm running: </p>

<pre><code>vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(contents)
feature_names = vectorizer.get_feature_names()
dense = tfidf_matrix.todense()
denselist = dense.tolist()
df = pd.DataFrame(denselist, columns=feature_names, index=characters)
s = pd.Series(df.loc['Adam'])
s[s &gt; 0].sort_values(ascending=False)[:10]
</code></pre>

<p>I expected this to return a list of distinctive words for the document 'Adam', but what it does it return a list of common words: </p>

<pre><code>and     0.497077
to      0.387147
the     0.316648
of      0.298724
in      0.186404
with    0.144583
his     0.140998
</code></pre>

<p>I might not understand it perfectly, but as I understand it, tf-idf is supposed to find words that are distinctive of one document in a corpus, finding words that appear frequently in one document, but not in other documents. Here, <code>and</code> appears frequently in other documents, so I don't know why it's returning a high value here. </p>

<p>The complete code I'm using to generate this is <a href=""https://github.com/JonathanReeve/milton-analysis/blob/v0.1/tfidf-scikit.ipynb"" rel=""noreferrer"">in this Jupyter notebook</a>. </p>

<p>When I compute tf/idfs semi-manually, using the NLTK and computing scores for each word, I get the appropriate results. For the 'Adam' document: </p>

<pre><code>fresh        0.000813
prime        0.000813
bone         0.000677
relate       0.000677
blame        0.000677
enough       0.000677
</code></pre>

<p>That looks about right, since these are words that appear in the 'Adam' document, but not as much in other documents in the corpus. The complete code used to generate this is in <a href=""https://github.com/JonathanReeve/milton-analysis/blob/v0.1/tfidf-nltk.ipynb"" rel=""noreferrer"">this Jupyter notebook</a>. </p>

<p>Am I doing something wrong with the scikit code? Is there another way to initialize this class where it returns the right results? Of course, I can ignore stopwords by passing <code>stop_words = 'english'</code>, but that doesn't really solve the problem, since common words of any sort shouldn't have high scores here. </p>
"
"Does GridSearchCV use predict or predict_proba, when using auc_score as score function?","<p>Does GridSearchCV use predict or predict_proba, when using auc_score as score function?</p>

<p>The predict function generates predicted class labels, which will always result in a triangular ROC-curve. A more curved ROC-curve is obtained using the predicted class probabilities. The latter one is, as far as I know, more accurate. If so, the area under the 'curved' ROC-curve is probably best to measure classification performance within the grid search. </p>

<p>Therefore I am curious if either the class labels or class probabilities are used for the grid search, when using the area under the ROC-curve as performance measure. I tried to find the answer in the code, but could not figure it out. Does anyone here know the answer?</p>

<p>Thanks</p>
"
"Keras and Sklearn logreg returning different results","<p>I'm comparing the results of a logistic regressor written in Keras to the default Sklearn Logreg. My input is one-dimensional. My output has two classes and I'm interested in the probability that the output belongs to the class 1.</p>

<p>I'm expecting the results to be almost identical, but they are not even close.</p>

<p>Here is how I generate my random data. Note that X_train, X_test are still vectors, I'm just using capital letters because I'm used to it. Also there is no need for scaling in this case.</p>

<pre><code>X = np.linspace(0, 1, 10000)
y = np.random.sample(X.shape)
y = np.where(y&lt;X, 1, 0)
</code></pre>

<p>Here's cumsum of y plotted over X. Doing a regression here is not rocket science.</p>

<p><a href=""https://i.stack.imgur.com/1Ba18.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1Ba18.png"" alt=""here&#39;s y plotted over x""></a></p>

<p>I do a standard train-test-split:</p>

<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y)
X_train = X_train.reshape(-1,1)
X_test = X_test.reshape(-1,1)
</code></pre>

<p>Next, I train a default logistic regressor:</p>

<pre><code>from sklearn.linear_model import LogisticRegression
sk_lr = LogisticRegression()
sk_lr.fit(X_train, y_train)
sklearn_logreg_result = sk_lr.predict_proba(X_test)[:,1]
</code></pre>

<p>And a logistic regressor that I write in Keras:</p>

<pre><code>from keras.models import Sequential
from keras.layers import Dense
keras_lr = Sequential()
keras_lr.add(Dense(1, activation='sigmoid', input_dim=1))
keras_lr.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])
_ = keras_lr.fit(X_train, y_train, verbose=0)
keras_lr_result = keras_lr.predict(X_test)[:,0]
</code></pre>

<p>And a hand-made solution:</p>

<pre><code>pearson_corr = np.corrcoef(X_train.reshape(X_train.shape[0],), y_train)[0,1]
b = pearson_corr * np.std(y_train) / np.std(X_train)
a = np.mean(y_train) - b * np.mean(X_train)
handmade_result = (a + b * X_test)[:,0]
</code></pre>

<p>I expect all three to deliver similar results, but here is what happens. This is a reliability diagram using 100 bins.</p>

<p><a href=""https://i.stack.imgur.com/1Zg0z.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1Zg0z.png"" alt=""enter image description here""></a></p>

<p>I have played around with loss functions and other parameters, but the Keras logreg stays roughly like this. What might be causing the problem here?</p>

<p>edit: Using binary crossentropy is not the solution here, as shown by this plot (note that the input data has changed between the two plots).</p>

<p><a href=""https://i.stack.imgur.com/gZEjF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gZEjF.png"" alt=""enter image description here""></a></p>
"
"Appropriate Deep Learning Structure for multi-class classification","<p>I have the following data</p>

<pre><code>         feat_1    feat_2 ... feat_n   label
gene_1   100.33     10.2  ... 90.23    great
gene_2   13.32      87.9  ... 77.18    soso
....
gene_m   213.32     63.2  ... 12.23    quitegood
</code></pre>

<p>The size of <code>M</code> is large ~30K rows, and <code>N</code> is much smaller ~10 columns.
My question is what is the appropriate Deep Learning structure to learn
and test the data like above.</p>

<p>At the end of the day, the user will give a vector of genes with expression.</p>

<pre><code>gene_1   989.00
gene_2   77.10
...
gene_N   100.10
</code></pre>

<p>And the system will label which label does each gene apply e.g. great or soso, etc...</p>

<p>By structure I mean one of these:</p>

<ul>
<li>Convolutional Neural Network (CNN)</li>
<li>Autoencoder</li>
<li>Deep Belief Network (DBN)</li>
<li>Restricted Boltzman Machine</li>
</ul>
"
"ImportError in importing from sklearn: cannot import name check_build","<p>I am getting the following error while trying to import from sklearn:</p>

<pre><code>&gt;&gt;&gt; from sklearn import svm

Traceback (most recent call last):
  File ""&lt;pyshell#17&gt;"", line 1, in &lt;module&gt;
   from sklearn import svm
  File ""C:\Python27\lib\site-packages\sklearn\__init__.py"", line 16, in &lt;module&gt;
   from . import check_build
ImportError: cannot import name check_build
</code></pre>

<p>I am using python 2.7, scipy-0.12.0b1 superpack, numpy-1.6.0 superpack, scikit-learn-0.11
I have a windows 7 machine</p>

<p>I have checked several answers for this issue but none of them gives a way out of this error.</p>
"
"Stratified Train/Test-split in scikit-learn","<p>I need to split my data into a training set (75%) and test set (25%). I currently do that with the code below:</p>

<pre><code>X, Xt, userInfo, userInfo_train = sklearn.cross_validation.train_test_split(X, userInfo)   
</code></pre>

<p>However, I'd like to stratify my training dataset. How do I do that? I've been looking into the <code>StratifiedKFold</code> method, but doesn't let me specifiy the 75%/25% split and only stratify the training dataset.</p>
"
"How can i know probability of class predicted by predict() function in Support Vector Machine?","<p>How can i know sample's probability that it belongs to a class predicted by predict() function of Scikit-Learn in Support Vector Machine?</p>

<pre><code>&gt;&gt;&gt;print clf.predict([fv])
[5]
</code></pre>

<p>There is any function?</p>
"
"What is the inverse of regularization strength in Logistic Regression? How should it affect my code?","<p>I am using <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"" rel=""noreferrer""><code>sklearn.linear_model.LogisticRegression</code></a> in <code>scikit learn</code> to run a Logistic Regression.</p>

<pre><code>C : float, optional (default=1.0) Inverse of regularization strength;
    must be a positive float. Like in support vector machines, smaller
    values specify stronger regularization.
</code></pre>

<p>What does <code>C</code> mean here in simple terms please? What is regularization strength?</p>
"
"Finding the dimension with highest variance using scikit-learn PCA","<p>I need to use pca to identify the dimensions with the highest variance of a certain set of data. I'm using scikit-learn's pca to do it, but I can't identify from the output of the pca method what are the components of my data with the highest variance. Keep in mind that I don't want to eliminate those dimensions, only identify them.</p>

<p>My data is organized as a matrix with 150 rows of data, each one with 4 dimensions. I'm doing as follow:</p>

<pre class=""lang-py prettyprint-override""><code>pca = sklearn.decomposition.PCA()
pca.fit(data_matrix)
</code></pre>

<p>When I print <strong>pca.explained_variance_ratio_</strong>, it outputs an array of variance ratios ordered from highest to lowest, but it doesn't tell me which dimension from the data they correspond to (I've tried changing the order of columns on my matrix, and the resulting variance ratio array was the same). </p>

<p>Printing <strong>pca.components_</strong> gives me a 4x4 matrix (I left the original number of components as argument to pca) with some values I can't understand the meaning of...according to scikit's documentation, they should be the components with the maximum variance (the eigenvectors perhaps?), but no sign of which dimension those values refer to.</p>

<p>Transforming the data doesn't help either, because the dimensions are changed in a way I can't really know which one they were originally.</p>

<p>Is there any way I can get this information with scikit's pca? Thanks</p>
"
"RandomForestClassfier.fit(): ValueError: could not convert string to float","<p>Given is a simple CSV file:</p>

<pre><code>A,B,C
Hello,Hi,0
Hola,Bueno,1
</code></pre>

<p>Obviously the real dataset is far more complex than this, but this one reproduces the error. I'm attempting to build a random forest classifier for it, like so:</p>

<pre><code>cols = ['A','B','C']
col_types = {'A': str, 'B': str, 'C': int}
test = pd.read_csv('test.csv', dtype=col_types)

train_y = test['C'] == 1
train_x = test[cols]

clf_rf = RandomForestClassifier(n_estimators=50)
clf_rf.fit(train_x, train_y)
</code></pre>

<p>But I just get this traceback when invoking fit():</p>

<pre><code>ValueError: could not convert string to float: 'Bueno'
</code></pre>

<p>scikit-learn version is 0.16.1.</p>
"
"Text[Multi-Level] Classification with many outputs","<p><strong>Problem Statement:</strong></p>

<p>To classify a text document to which  category it belongs and also to classify up to two levels of the category.</p>

<p><strong>Sample Training Set:</strong></p>

<pre><code>Description Category    Level1  Level2
The gun shooting that happened in Vegas killed two  Crime | High    Crime   High
Donald Trump elected as President of America    Politics | High Politics    High
Rian won in football qualifier  Sports | Low    Sports  Low
Brazil won in football final    Sports | High   Sports  High
</code></pre>

<p><strong>Initial Attempt:</strong></p>

<p>I tried to create a classifier model which would try to classify the Category using Random forest method and it gave me 90% overall.</p>

<p><strong>Code1:</strong></p>

<pre><code>import pandas as pd
#import numpy as np

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import BernoulliNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
#from stemming.porter2 import stem

from nltk.corpus import stopwords

from sklearn.model_selection import cross_val_score

stop = stopwords.words('english')
data_file = ""Training_dataset_70k""

#Reading the input/ dataset
data = pd.read_csv( data_file, header = 0, delimiter= ""\t"", quoting = 3, encoding = ""utf8"")
data = data.dropna()

#Removing stopwords, punctuation and stemming
data['Description'] = data['Description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
data['Description'] = data['Description'].str.replace('[^\w\s]',' ').replace('\s+',' ')
#data['Description'] = data['Description'].apply(lambda x: ' '.join([stem(word) for word in x.split()]))

train_data, test_data, train_label,  test_label = train_test_split(data.Description, data.Category, test_size=0.3, random_state=100)

RF = RandomForestClassifier(n_estimators=10)
vectorizer = TfidfVectorizer( max_features = 40000, ngram_range = ( 1,3 ), sublinear_tf = True )
data_features = vectorizer.fit_transform( train_data )
RF.fit(data_features, train_label)
test_data_feature = vectorizer.transform(test_data)
Output_predict = RF.predict(test_data_feature)
print ""Overall_Accuracy: "" + str(np.mean(Output_predict == test_label))
with codecs.open(""out_Category.txt"", ""w"", ""utf8"") as out:
    for inp, pred, act in zip(test_data, Output_predict, test_label):
        try:
            out.write(""{}\t{}\t{}\n"".format(inp, pred, act))
        except:
            continue
</code></pre>

<p><strong>Problem:</strong></p>

<p>I want to add two more level to the model they are Level1 and Level2 the reasons for adding them is when I ran classification for Level1 alone I got 96% accuracy. I am stuck at splitting training and test dataset and to train a model which has three classifications.</p>

<p>Is it possible to create a model with three classification or should I create three models? How to split train and test data?</p>

<p><strong>Edit1:</strong>
    import string
    import codecs
    import pandas as pd
    import numpy as np</p>

<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import BernoulliNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from stemming.porter2 import stem

from nltk.stem import PorterStemmer
from nltk.corpus import stopwords

from sklearn.model_selection import cross_val_score


stop = stopwords.words('english')

data_file = ""Training_dataset_70k""
#Reading the input/ dataset
data = pd.read_csv( data_file, header = 0, delimiter= ""\t"", quoting = 3, encoding = ""utf8"")
data = data.dropna()
#Removing stopwords, punctuation and stemming
data['Description'] = data['Description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
data['Description'] = data['Description'].str.replace('[^\w\s]',' ').replace('\s+',' ')

train_data, test_data, train_label,  test_label = train_test_split(data.Description, data[[""Category"", ""Level1"", ""Level2""]], test_size=0.3, random_state=100)
RF = RandomForestClassifier(n_estimators=2)
vectorizer = TfidfVectorizer( max_features = 40000, ngram_range = ( 1,3 ), sublinear_tf = True )
data_features = vectorizer.fit_transform( train_data )
print len(train_data), len(train_label)
print train_label
RF.fit(data_features, train_label)
test_data_feature = vectorizer.transform(test_data)
#print test_data_feature
Output_predict = RF.predict(test_data_feature)
print ""BreadCrumb_Accuracy: "" + str(np.mean(Output_predict == test_label))
with codecs.open(""out_bread_crumb.txt"", ""w"", ""utf8"") as out:
    for inp, pred, act in zip(test_data, Output_predict, test_label):
        try:
            out.write(""{}\t{}\t{}\n"".format(inp, pred, act))
        except:
            continue
</code></pre>
"
"How to output RandomForest Classifier from python?","<p>I have trained a RandomForestClassifier from Python Sckit Learn Module with very big dataset, but question is how can I possibly save this model and let other people apply it on their end.
Thank you!</p>
"
"sklearn - Cross validation with multiple scores","<p>I would like to compute the <strong>recall</strong>, <strong>precision</strong> and <strong>f-measure</strong> of a cross validation test for different classifiers.
<em>scikit-learn</em> comes with <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html"">cross_val_score</a> but unfortunately such method does not return multiple values.</p>

<p>I could compute such measures by calling <strong>three times</strong> <em>cross_val_score</em> but that is not efficient. Is there any better solution?</p>

<p>By now I wrote this function:</p>

<pre><code>from sklearn import metrics

def mean_scores(X, y, clf, skf):

    cm = np.zeros(len(np.unique(y)) ** 2)
    for i, (train, test) in enumerate(skf):
        clf.fit(X[train], y[train])
        y_pred = clf.predict(X[test])
        cm += metrics.confusion_matrix(y[test], y_pred).flatten()

    return compute_measures(*cm / skf.n_folds)

def compute_measures(tp, fp, fn, tn):
     """"""Computes effectiveness measures given a confusion matrix.""""""
     specificity = tn / (tn + fp)
     sensitivity = tp / (tp + fn)
     fmeasure = 2 * (specificity * sensitivity) / (specificity + sensitivity)
     return sensitivity, specificity, fmeasure
</code></pre>

<p>It basically sums up the confusion matrix values and once you have <em>false positive</em>, <em>false negative</em> etc you can easily compute the recall, precision etc... But still I don't like this solution :)</p>
"
"RandomForestClassifier vs ExtraTreesClassifier in scikit learn","<p>Can anyone explain the difference between the RandomForestClassifier and ExtraTreesClassifier in scikit learn.  I've spent a good bit of time reading the paper:</p>

<p>P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006 </p>

<p>It seems these are the difference for ET:</p>

<p>1) When choosing variables at a split, samples are drawn from the entire training set instead of a bootstrap sample of the training set.</p>

<p>2) Splits are chosen completely at random from the range of values in the sample at each split.  </p>

<p>The result from these two things are many more ""leaves"".</p>
"
"Predicting how long an scikit-learn classification will take to run","<p>Is there a way to predict how long it will take to run a classifier from sci-kit learn based on the parameters and dataset?  I know, pretty meta, right?</p>

<p>Some classifiers/parameter combinations are quite fast, and some take so long that I eventually just kill the process.  I'd like a way to estimate in advance how long it will take.</p>

<p>Alternatively, I'd accept some pointers on how to set common parameters to reduce the run time.</p>
"
"Problems obtaining most informative features with scikit learn?","<p>Im triying to obtain the most informative features from a <a href=""http://pastebin.com/3qYc9mfZ"" rel=""noreferrer"">textual corpus</a>. From this well answered <a href=""https://stackoverflow.com/questions/26976362/how-to-get-most-informative-features-for-scikit-learn-classifier-for-different-c"">question</a> I know that this task could be done as follows:</p>

<pre><code>def most_informative_feature_for_class(vectorizer, classifier, classlabel, n=10):
    labelid = list(classifier.classes_).index(classlabel)
    feature_names = vectorizer.get_feature_names()
    topn = sorted(zip(classifier.coef_[labelid], feature_names))[-n:]

    for coef, feat in topn:
        print classlabel, feat, coef
</code></pre>

<p>Then:</p>

<pre><code>most_informative_feature_for_class(tfidf_vect, clf, 5)
</code></pre>

<p>For this classfier:</p>

<pre><code>X = tfidf_vect.fit_transform(df['content'].values)
y = df['label'].values


from sklearn import cross_validation
X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,
                                                    y, test_size=0.33)
clf = SVC(kernel='linear', C=1)
clf.fit(X, y)
prediction = clf.predict(X_test)
</code></pre>

<p>The problem is the output of <code>most_informative_feature_for_class</code>:</p>

<pre><code>5 a_base_de_bien bastante   (0, 2451)   -0.210683496368
  (0, 3533) -0.173621065386
  (0, 8034) -0.135543062425
  (0, 10346)    -0.173621065386
  (0, 15231)    -0.154148294738
  (0, 18261)    -0.158890483047
  (0, 21083)    -0.297476572586
  (0, 434)  -0.0596263855375
  (0, 446)  -0.0753492277856
  (0, 769)  -0.0753492277856
  (0, 1118) -0.0753492277856
  (0, 1439) -0.0753492277856
  (0, 1605) -0.0753492277856
  (0, 1755) -0.0637950312345
  (0, 3504) -0.0753492277856
  (0, 3511) -0.115802483001
  (0, 4382) -0.0668983049212
  (0, 5247) -0.315713152154
  (0, 5396) -0.0753492277856
  (0, 5753) -0.0716096348446
  (0, 6507) -0.130661516772
  (0, 7978) -0.0753492277856
  (0, 8296) -0.144739048504
  (0, 8740) -0.0753492277856
  (0, 8906) -0.0753492277856
  : :
  (0, 23282)    0.418623443832
  (0, 4100) 0.385906085143
  (0, 15735)    0.207958503155
  (0, 16620)    0.385906085143
  (0, 19974)    0.0936828782325
  (0, 20304)    0.385906085143
  (0, 21721)    0.385906085143
  (0, 22308)    0.301270427482
  (0, 14903)    0.314164150621
  (0, 16904)    0.0653764031957
  (0, 20805)    0.0597723455204
  (0, 21878)    0.403750815828
  (0, 22582)    0.0226150073272
  (0, 6532) 0.525138162099
  (0, 6670) 0.525138162099
  (0, 10341)    0.525138162099
  (0, 13627)    0.278332617058
  (0, 1600) 0.326774799211
  (0, 2074) 0.310556919237
  (0, 5262) 0.176400451433
  (0, 6373) 0.290124806858
  (0, 8593) 0.290124806858
  (0, 12002)    0.282832270298
  (0, 15008)    0.290124806858
  (0, 19207)    0.326774799211
</code></pre>

<p>It is not returning the label nor the words. Why this is happening and how can I print the words and the labels?. Do you guys this is happening since I am using pandas to read the data?. Another thing I tried is the following, form this <a href=""https://stackoverflow.com/questions/11116697/how-to-get-most-informative-features-for-scikit-learn-classifiers"">question</a>:</p>

<pre><code>def print_top10(vectorizer, clf, class_labels):
    """"""Prints features with the highest coefficient values, per class""""""
    feature_names = vectorizer.get_feature_names()
    for i, class_label in enumerate(class_labels):
        top10 = np.argsort(clf.coef_[i])[-10:]
        print(""%s: %s"" % (class_label,
              "" "".join(feature_names[j] for j in top10)))


print_top10(tfidf_vect,clf,y)
</code></pre>

<p>But I get this traceback:</p>

<p>Traceback (most recent call last):</p>

<pre><code>  File ""/Users/user/PycharmProjects/TESIS_FINAL/Classification/Supervised_learning/Final/experimentos/RBF/SVM_con_rbf.py"", line 237, in &lt;module&gt;
    print_top10(tfidf_vect,clf,5)
  File ""/Users/user/PycharmProjects/TESIS_FINAL/Classification/Supervised_learning/Final/experimentos/RBF/SVM_con_rbf.py"", line 231, in print_top10
    for i, class_label in enumerate(class_labels):
TypeError: 'int' object is not iterable
</code></pre>

<p>Any idea of how to solve this, in order to get the features with the highest coefficient values?.</p>
"
"sklearn.cross_validation.StratifiedShuffleSplit - error: ""indices are out-of-bounds""","<p>I was trying to split the sample dataset using Scikit-learn's Stratified Shuffle Split. I followed the example shown on the Scikit-learn documentation <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html"">here</a>  </p>

<pre><code>import pandas as pd
import numpy as np
# UCI's wine dataset
wine = pd.read_csv(""https://s3.amazonaws.com/demo-datasets/wine.csv"")

# separate target variable from dataset
target = wine['quality']
data = wine.drop('quality',axis = 1)

# Stratified Split of train and test data
from sklearn.cross_validation import StratifiedShuffleSplit
sss = StratifiedShuffleSplit(target, n_iter=3, test_size=0.2)

for train_index, test_index in sss:
    xtrain, xtest = data[train_index], data[test_index]
    ytrain, ytest = target[train_index], target[test_index]

# Check target series for distribution of classes
ytrain.value_counts()
ytest.value_counts()
</code></pre>

<p>However, upon running this script, I get the following error:</p>

<pre><code>IndexError: indices are out-of-bounds
</code></pre>

<p>Could someone please point out what I am doing wrong here? Thanks!</p>
"
"Can I use CountVectorizer in scikit-learn to count frequency of documents that were not used to extract the tokens?","<p>I have been working with the <code>CountVectorizer</code> class in scikit-learn.</p>

<p>I understand that if used in the manner shown below, the final output will consist of an array containing counts of features, or tokens.</p>

<p>These tokens are extracted from a set of keywords, i.e.</p>

<pre><code>tags = [
  ""python, tools"",
  ""linux, tools, ubuntu"",
  ""distributed systems, linux, networking, tools"",
]
</code></pre>

<p>The next step is:</p>

<pre><code>from sklearn.feature_extraction.text import CountVectorizer
vec = CountVectorizer(tokenizer=tokenize)
data = vec.fit_transform(tags).toarray()
print data
</code></pre>

<p>Where we get</p>

<pre><code>[[0 0 0 1 1 0]
 [0 1 0 0 1 1]
 [1 1 1 0 1 0]]
</code></pre>

<p>This is fine, but my situation is just a little bit different.  </p>

<p>I want to extract the features the same way as above, but I don't want the rows in <code>data</code> to be the same documents that the features were extracted from.</p>

<p>In other words, how can I get counts of another set of documents, say, </p>

<pre><code>list_of_new_documents = [
  [""python, chicken""],
  [""linux, cow, ubuntu""],
  [""machine learning, bird, fish, pig""]
]
</code></pre>

<p>And get:</p>

<pre><code>[[0 0 0 1 0 0]
 [0 1 0 0 0 1]
 [0 0 0 0 0 0]]
</code></pre>

<p>I have read the documentation for the <code>CountVectorizer</code> class, and came across the <code>vocabulary</code> argument, which is a mapping of terms to feature indices.  I can't seem to get this argument to help me, however.</p>

<p>Any advice is appreciated.<br>
PS:  all credit due to <a href=""http://blog.mafr.de/2012/04/15/scikit-learn-feature-extractio/"" rel=""noreferrer"">Matthias Friedrich's Blog</a> for the example I used above.</p>
"
"What's wrong with my implementation of Neural Networks?","<p><a href=""https://i.stack.imgur.com/L9SsG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/L9SsG.png"" alt=""enter image description here""></a>I want to plot the learning error curve of a neural net with respect to the number of training examples. Here is the code :</p>

<pre><code>import sklearn
import numpy as np
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt
from sklearn import neural_network
from sklearn import cross_validation

myList=[]
myList2=[]
w=[]

dataset=np.loadtxt(""data"", delimiter="","")
X=dataset[:, 0:6]
Y=dataset[:,6]
clf=sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(2,3),activation='tanh')

# split the data between training and testing
X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, test_size=0.25, random_state=33)

# begin with few training datas
X_eff=X_train[0:int(len(X_train)/150), : ]
Y_eff=Y_train[0:int(len(Y_train)/150)]

k=int(len(X_train)/150)-1


for m in range (140) :


    print (m)

    w.append(k)

    # train the model and store the training error
    A=clf.fit(X_eff,Y_eff)
    myList.append(1-A.score(X_eff,Y_eff))

      # compute the testing error
    myList2.append(1-A.score(X_test,Y_test))

    # add some more training datas
    X_eff=np.vstack((X_eff,X_train[k+1:k+101,:]))
    Y_eff=np.hstack((Y_eff,Y_train[k+1:k+101]))
    k=k+100

plt.figure(figsize=(8, 8))
plt.subplots_adjust()
plt.title(""Erreur d'entrainement et de test"")
plt.plot(w,myList,label=""training error"")
plt.plot(w,myList2,label=""test error"")
plt.legend()
plt.show()
</code></pre>

<p>However, I get a very strange result, with curves fluctuating, the training error very close to the testing error which does not appear to be normal.
Where is the mistake? I can't understand why there are so many ups and downs and why the training error does not increase, as it would be expected to.Any help would be appreciated !</p>

<p>EDIT : the dataset I am using is <a href=""https://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King%29"" rel=""nofollow noreferrer"">https://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King%29</a> where I got rid of the classes having less than 1000 instances. I manually re-encoded the litteral data.</p>
"
"Recovering features names of explained_variance_ratio_ in PCA with sklearn","<p>I'm trying to recover from a PCA done with scikit-learn, <strong>which</strong> features are selected as <em>relevant</em>.</p>

<p>A classic example with IRIS dataset.</p>

<pre><code>import pandas as pd
import pylab as pl
from sklearn import datasets
from sklearn.decomposition import PCA

# load dataset
iris = datasets.load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)

# normalize data
df_norm = (df - df.mean()) / df.std()

# PCA
pca = PCA(n_components=2)
pca.fit_transform(df_norm.values)
print pca.explained_variance_ratio_
</code></pre>

<p>This returns</p>

<pre><code>In [42]: pca.explained_variance_ratio_
Out[42]: array([ 0.72770452,  0.23030523])
</code></pre>

<p><strong>How can I recover which two features allow these two explained variance among the dataset ?</strong>
Said diferently, how can i get the index of this features in iris.feature_names ?</p>

<pre><code>In [47]: print iris.feature_names
['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
</code></pre>

<p>Thanks in advance for your help.</p>
"
"find important features for classification","<p>I'm trying to classify some EEG data using a logistic regression model (this seems to give the best classification of my data). The data I have is from a multichannel EEG setup so in essence I have a matrix of 63 x 116 x 50 (that is channels x time points x number of trials (there are two trial types of 50), I have reshaped this to a long vector, one for each trial.</p>

<p>What I would like to do is after the classification to see which features were the most useful in classifying the trials. How can I do that and is it possible to test the significance of these features? e.g. to say that the classification was drive mainly by N-features and these are feature x to z. So I could for instance say that channel 10 at time point 90-95 was significant or important for the classification.</p>

<p>So is this possible or am I asking the wrong question?</p>

<p>any comments or paper references are much appreciated. </p>
"
"Machine Learning (tensorflow / sklearn) in Django?","<p>I have a django form, which is collecting user response. I also have a tensorflow sentences classification model. What is the best/standard way to  put these two together.
Details: </p>

<ol>
<li>tensorflow model was trained on the Movie Review data from Rotten Tomatoes.</li>
<li>Everytime a new row is made in my response model , i want the tensorflow code to classify it( + or - ).</li>
<li>Basically I have a django project directory and two .py files for classification. Before going ahead myself , i wanted to know what is the standard way to implement machine learning algorithms to a web app.</li>
</ol>

<p>It'd be awesome if you could suggest a tutorial or a repo.
Thank you !</p>
"
"How are feature_importances in RandomForestClassifier determined?","<p>I have a classification task with a time-series as the data input, where each attribute (n=23) represents a specific point in time. Besides the absolute classification result I would like to find out, which attributes/dates contribute to the result to what extent. Therefore I am just using the <code>feature_importances_</code>, which works well for me.</p>

<p>However, I would like to know how they are getting calculated and which measure/algorithm is used. Unfortunately I could not find any documentation on this topic.</p>
"
"Why does CalibratedClassifierCV underperform a direct classifer?","<p>I noticed that sklearn's new <code>CalibratedClassifierCV</code> seems to underperform the direct <code>base_estimator</code> when the <code>base_estimator</code> is <code>GradientBoostingClassifer</code>, (I haven't tested other classifiers).  Interestingly, if <code>make_classification</code>'s parameters are:</p>

<pre><code>n_features = 10
n_informative = 3
n_classes = 2
</code></pre>

<p>then the <code>CalibratedClassifierCV</code> seems to be the slight outperformer (log loss evaluation).</p>

<p>However, under the following classification data set the <code>CalibratedClassifierCV</code> seems to generally be the underperformer:</p>

<pre><code>from sklearn.datasets import make_classification
from sklearn import ensemble
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import log_loss
from sklearn import cross_validation
# Build a classification task using 3 informative features

X, y = make_classification(n_samples=1000,
                           n_features=100,
                           n_informative=30,
                           n_redundant=0,
                           n_repeated=0,
                           n_classes=9,
                           random_state=0,
                           shuffle=False)

skf = cross_validation.StratifiedShuffleSplit(y, 5)

for train, test in skf:

    X_train, X_test = X[train], X[test]
    y_train, y_test = y[train], y[test]

    clf = ensemble.GradientBoostingClassifier(n_estimators=100)
    clf_cv = CalibratedClassifierCV(clf, cv=3, method='isotonic')
    clf_cv.fit(X_train, y_train)
    probas_cv = clf_cv.predict_proba(X_test)
    cv_score = log_loss(y_test, probas_cv)

    clf = ensemble.GradientBoostingClassifier(n_estimators=100)
    clf.fit(X_train, y_train)
    probas = clf.predict_proba(X_test)
    clf_score = log_loss(y_test, probas) 

    print 'calibrated score:', cv_score
    print 'direct clf score:', clf_score
    print
</code></pre>

<p>One run yielded:</p>

<p><img src=""https://i.stack.imgur.com/HarT8.png"" alt=""enter image description here""></p>

<p>Maybe I'm missing something about how <code>CalibratedClassifierCV</code> works, or am not using it correctly, but I was under the impression that if anything, passing a classifier to <code>CalibratedClassifierCV</code> would result in improved performance relative to the <code>base_estimator</code> alone.</p>

<p>Can anyone explain this observed underperformance? </p>
"
"Python Non negative Matrix Factorization that handles both zeros and missing data?","<p>I look for a NMF implementation that has a python interface, and handles both missing data and zeros.</p>

<p>I don't want to impute my missing values before starting the factorization, I want them to be ignored in the minimized function.</p>

<p>It seems that neither scikit-learn, nor nimfa, nor graphlab, nor mahout propose such an option.</p>

<p>Thanks!</p>
"
"Getting deprecation warning in Sklearn over 1d array, despite not having a 1D array","<p>I am trying to use SKLearn to run an SVM model. I am just trying it out now with some sample data. Here is the data and the code:</p>

<pre><code>import numpy as np
from sklearn import svm
import random as random

A = np.array([[random.randint(0, 20) for i in range(2)] for i in range(10)])
lab = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]

clf = svm.SVC(kernel='linear', C=1.0)
clf.fit(A, lab)
</code></pre>

<p>FYI, when I run </p>

<pre><code>import sklearn
sklearn.__version__
</code></pre>

<p>It outputs 0.17.</p>

<p>Now, when I run <code>print(clf.predict([1, 1]))</code>, I get the following warning:</p>

<pre><code>C:\Users\me\AppData\Local\Continuum\Anaconda2\lib\site-packages\sklearn\ut
ils\validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecat
ed in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.re
shape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contain
s a single sample.
  DeprecationWarning)
</code></pre>

<p>It does give me a prediction, which is great. However, I find this weird for a few reasons.</p>

<p>I don't have a 1d array. If you print A, you get</p>

<pre><code>array([[ 9, 12],
       [ 2, 16],
       [14, 14],
       [ 4,  2],
       [ 8,  4],
       [12,  3],
       [ 0,  0],
       [ 3, 13],
       [15, 17],
       [15, 16]]) 
</code></pre>

<p>Which appears to me to be 2 dimensional. But okay, let's just say that what I have is in fact a 1D array. Let's try to change it using <code>reshape</code>, as suggested by the error.</p>

<p>Same code as above, but now we have</p>

<pre><code>A = np.array([[random.randint(0, 20) for i in range(2)] for i in range(10)]).reshape(-1,1)
</code></pre>

<p>But then this outputs an array of length 20, which makes no sense and is not what I want. I also tried it with <code>reshape(1, -1)</code> but then this gives me a single observation / list with 20 items in it. </p>

<p>How can I reshape my data in numpy arrays so that I don't get this warning?</p>

<hr>

<p>I looked at two answers on SO, and neither worked for me. <a href=""https://stackoverflow.com/questions/35082140/preprocessing-in-scikit-learn-single-sample-depreciation-warning"">Question 1</a> and <a href=""https://stackoverflow.com/questions/35166146/sci-kit-learn-reshape-your-data-either-using-x-reshape-1-1"">Question 2</a>. It seems that Q1 was actually 1D data and was solved using <code>reshape</code>, which I tried and failed at. Q2 has an answer about how to track warnings and errors, which isn't what I want. The other answer is again an instance of a 1D array.</p>
"
"classifiers in scikit-learn that handle nan/null","<p>I was wondering if there are classifiers that handle nan/null values in scikit-learn.  I thought random forest regressor handles this but I got an error when I call <code>predict</code>.</p>

<pre><code>X_train = np.array([[1, np.nan, 3],[np.nan, 5, 6]])
y_train = np.array([1, 2])
clf = RandomForestRegressor(X_train, y_train)
X_test = np.array([7, 8, np.nan])
y_pred = clf.predict(X_test) # Fails!
</code></pre>

<p>Can I not call predict with any scikit-learn algorithm with missing values?</p>

<p><strong>Edit.</strong>
Now that I think about this, it makes sense.  It's not an issue during training but when you predict how do you branch when the variable is null?  maybe you could just split both ways and average the result?  It seems like k-NN should work fine as long as the distance function ignores nulls though.</p>

<p><strong>Edit 2 (older and wiser me)</strong>
Some gbm libraries (such as xgboost) use a ternary tree instead of a binary tree precisely for this purpose: 2 children for the yes/no decision and 1 child for the missing decision. sklearn is <a href=""https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/tree/_tree.pyx#L70-L74"" rel=""nofollow noreferrer"">using a binary tree</a></p>
"
"Concatenate custom features with CountVectorizer","<p>I have a bunch of files with articles. For each article there should be some features, like: <strong>text length</strong>, <strong>text_spam</strong> (all are ints or floats, and in most cases they should be loaded from csv). And what I want to do is - to combine these features with CountVectorizer and then classify those texts.</p>

<p>I have watched some tutorials, but still I have no idea how to implement this stuff. Found something <a href=""http://scikit-learn.org/stable/auto_examples/feature_stacker.html"">here</a>, but can't actually implement this for my needs.</p>

<p>Any ideas how that could be done with scikit?</p>

<p>Thank you.</p>

<p>What I came across right now is:</p>

<pre><code>from sklearn.feature_extraction import DictVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.pipeline import FeatureUnion

measurements = [
    {'text_length': 1000, 'text_spam': 4.3},
    {'text_length': 2000, 'text_spam': 4.1},
]

corpus = [
    'some text',
    'some text 2 hooray',
]

vectorizer = DictVectorizer()
count_vectorizer = CountVectorizer(min_df=1)

first_x = vectorizer.fit_transform(measurements)
second_x = count_vectorizer.fit_transform(corpus)

combined_features = FeatureUnion([('first', first_x), ('second', second_x)])
</code></pre>

<p>For this bunch of code I do not understand how to load ""real""-data, since training sets are already loaded. And the second one - how to load categories (y parameter for fit function)?</p>
"
"Error importing scikit-learn modules","<p>I'm trying to call a function from the cluster module, like so:</p>

<pre><code>import sklearn
db = sklearn.cluster.DBSCAN()
</code></pre>

<p>and I get the following error:</p>

<pre><code>AttributeError: 'module' object has no attribute 'cluster'
</code></pre>

<p>Tab-completing in IPython, I seem to have access to the base, clone, externals, re, setup_module, sys, and warning modules.  Nothing else, though others (including cluster) are in the sklearn directory.</p>

<p>Following pbu's advice below and using</p>

<pre><code>from sklearn import cluster
</code></pre>

<p>I get:</p>

<pre><code>Traceback (most recent call last):
  File ""test.py"", line 2, in &lt;module&gt;
    from sklearn import cluster
  File ""C:\Python34\lib\site-packages\sklearn\cluster\__init__.py"", line 6, in &lt;module&gt;
    from .spectral import spectral_clustering, SpectralClustering
  File ""C:\Python34\lib\site-packages\sklearn\cluster\spectral.py"", line 13, in &lt;module&gt;
    from ..utils import check_random_state, as_float_array
  File ""C:\Python34\lib\site-packages\sklearn\utils\__init__.py"", line 16, in &lt;module&gt;
    from .class_weight import compute_class_weight, compute_sample_weight
  File ""C:\Python34\lib\site-packages\sklearn\utils\class_weight.py"", line 7, in &lt;module&gt;
    from ..utils.fixes import in1d
  File ""C:\Python34\lib\site-packages\sklearn\utils\fixes.py"", line 318, in &lt;module&gt;
    from scipy.sparse.linalg import lsqr as sparse_lsqr
  File ""C:\Python34\lib\site-packages\scipy\sparse\linalg\__init__.py"", line 109, in &lt;module&gt;
    from .isolve import *
  File ""C:\Python34\lib\site-packages\scipy\sparse\linalg\isolve\__init__.py"", line 6, in &lt;module&gt;
    from .iterative import *
  File ""C:\Python34\lib\site-packages\scipy\sparse\linalg\isolve\iterative.py"", line 7, in &lt;module&gt;
    from . import _iterative
ImportError: DLL load failed: The specified module could not be found.
</code></pre>

<p>I'm using Python 3.4 on Windows, scikit-learn 0.16.1.</p>
"
"How to use scikit-learn PCA for features reduction and know which features are discarded","<p>I am trying to run a PCA on a matrix of dimensions m x n where m is the number of features and n the number of samples.</p>

<p>Suppose I want to preserve the <code>nf</code> features with the maximum variance. With <code>scikit-learn</code> I am able to do it in this way:</p>

<pre><code>from sklearn.decomposition import PCA

nf = 100
pca = PCA(n_components=nf)
# X is the matrix transposed (n samples on the rows, m features on the columns)
pca.fit(X)

X_new = pca.transform(X)
</code></pre>

<p>Now, I get a new matrix <code>X_new</code> that has a shape of n x nf. Is it possible to know which features have been discarded or the retained ones?</p>

<p>Thanks</p>
"
"fit_transform() takes 2 positional arguments but 3 were given with LabelBinarizer","<p>I am totally new to Machine Learning and I have been working with unsupervised learning technique.</p>

<p>Image shows my sample Data(After all Cleaning) Screenshot :
<a href=""https://i.stack.imgur.com/sxXbT.png"" rel=""noreferrer"">Sample Data</a></p>

<p>I have this two Pipline built to Clean the Data:</p>

<pre><code>num_attribs = list(housing_num)
cat_attribs = [""ocean_proximity""]

print(type(num_attribs))

num_pipeline = Pipeline([
    ('selector', DataFrameSelector(num_attribs)),
    ('imputer', Imputer(strategy=""median"")),
    ('attribs_adder', CombinedAttributesAdder()),
    ('std_scaler', StandardScaler()),
])

cat_pipeline = Pipeline([
    ('selector', DataFrameSelector(cat_attribs)),
    ('label_binarizer', LabelBinarizer())
])
</code></pre>

<p>Then I did the union of this two pipelines and the code for the same is shown below :</p>

<pre><code>from sklearn.pipeline import FeatureUnion

full_pipeline = FeatureUnion(transformer_list=[
        (""num_pipeline"", num_pipeline),
        (""cat_pipeline"", cat_pipeline),
    ])
</code></pre>

<p>Now I am trying to do fit_transform on the <a href=""https://i.stack.imgur.com/HJ30l.png"" rel=""noreferrer"">Data</a> But Its showing Me the Error.</p>

<p>Code for Transformation:</p>

<pre><code>housing_prepared = full_pipeline.fit_transform(housing)
housing_prepared
</code></pre>

<p>Error message:
fit_transform() takes 2 positional arguments but 3 were given</p>
"
"How to split data into 3 sets (train, validation and test)?","<p>I have a pandas dataframe and I wish to divide it to 3 separate sets. I know that using <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html"" rel=""noreferrer"">train_test_split</a> from <code>sklearn.cross_validation</code>, one can divide the data in two sets (train and test). However, I couldn't find any solution about splitting the data into three sets. Preferably, I'd like to have the indices of the original data. </p>

<p>I know that a workaround would be to use <code>train_test_split</code> two times and somehow adjust the indices. But is there a more standard / built-in way to split the data into 3 sets instead of 2?</p>
"
"scikit-learn: Random forest class_weight and sample_weight parameters","<p>I have a class imbalance problem and been experimenting with a weighted Random Forest using the implementation in scikit-learn (>= 0.16). </p>

<p>I have noticed that the implementation takes a <em>class_weight</em> parameter in the tree constructor and <em>sample_weight</em> parameter in the fit method to help solve class imbalance. Those two seem to be multiplied though to decide a final weight.</p>

<p>I have trouble understanding the following:</p>

<ul>
<li>In what stages of the tree construction/training/prediction are those weights used? I have seen some papers for weighted trees, but I am not sure what scikit implements.</li>
<li>What exactly is the difference between class_weight and sample_weight?</li>
</ul>
"
"sklearn: Found arrays with inconsistent numbers of samples when calling LinearRegression.fit()","<p>Just trying to do a simple linear regression but I'm baffled by this error for:</p>

<pre><code>regr = LinearRegression()
regr.fit(df2.iloc[1:1000, 5].values, df2.iloc[1:1000, 2].values)
</code></pre>

<p>which produces:</p>

<pre><code>ValueError: Found arrays with inconsistent numbers of samples: [  1 999]
</code></pre>

<p>These selections must have the same dimensions, and they should be numpy arrays, so what am I missing? </p>
"
"Using the predict_proba() function of RandomForestClassifier in the safe and right way","<p>I'm using Scikit-learn to apply machine learning algorithm on my datasets. Sometimes I need to have the probabilities of labels/classes instated of the labels/classes themselves. Instead of having Spam/Not Spam as labels of emails, I wish to have only for example: 0.78 probability a given email is Spam. </p>

<p>For such purpose, I'm using predict_proba() with RandomForestClassifier as following: </p>

<pre><code>clf = RandomForestClassifier(n_estimators=10, max_depth=None,
    min_samples_split=1, random_state=0)
scores = cross_val_score(clf, X, y)
print(scores.mean())

classifier = clf.fit(X,y)
predictions = classifier.predict_proba(Xtest)
print(predictions)
</code></pre>

<p>And I got those results:</p>

<pre><code> [ 0.4  0.6]
 [ 0.1  0.9]
 [ 0.2  0.8]
 [ 0.7  0.3]
 [ 0.3  0.7]
 [ 0.3  0.7]
 [ 0.7  0.3]
 [ 0.4  0.6]
</code></pre>

<p>Where the second column is for class: Spam. However, I have two main issues with the results about which I am not confident. The first issue is that the results represent the probabilities of the labels without being affected by the size of my data? The second issue is that the results only show only one digit which is not very specific in some cases where the 0.701 probability is very different from 0.708. Is there any way to get the next 5 digit for example? </p>

<p>Many thanks in advance for your time in reading these two issues and their questions.  </p>
"
"How to one-hot-encode from a pandas column containing a list?","<p>I would like to break down a pandas column consisting of a list of elements into as many columns as there are unique elements i.e. <code>one-hot-encode</code> them (with value <code>1</code> representing a given element existing in a row and <code>0</code> in the case of absence). </p>

<p>For example, taking dataframe <strong>df</strong></p>

<pre><code>Col1   Col2         Col3
 C      33     [Apple, Orange, Banana]
 A      2.5    [Apple, Grape]
 B      42     [Banana] 
</code></pre>

<p>I would like to convert this to:</p>

<p><strong>df</strong> </p>

<pre><code>Col1   Col2   Apple   Orange   Banana   Grape
 C      33     1        1        1       0
 A      2.5    1        0        0       1
 B      42     0        0        1       0
</code></pre>

<p>How can I use pandas/sklearn to achieve this?</p>
"
"Numpy hstack - ""ValueError: all the input arrays must have same number of dimensions"" - but they do","<p>I am trying to join two numpy arrays. In one I have a set of columns/features after running TF-IDF on a single column of text. In the other I have one column/feature which is an integer. So I read in a column of train and test data, run TF-IDF on this, and then I want to add another integer column because I think this will help my classifier learn more accurately how it should behave. </p>

<p>Unfortunately, I am getting the error in the title when I try and run <code>hstack</code> to add this single column to my other numpy array.</p>

<p>Here is my code : </p>

<pre><code>  #reading in test/train data for TF-IDF
  traindata = list(np.array(p.read_csv('FinalCSVFin.csv', delimiter="";""))[:,2])
  testdata = list(np.array(p.read_csv('FinalTestCSVFin.csv', delimiter="";""))[:,2])

  #reading in labels for training
  y = np.array(p.read_csv('FinalCSVFin.csv', delimiter="";""))[:,-2]

  #reading in single integer column to join
  AlexaTrainData = p.read_csv('FinalCSVFin.csv', delimiter="";"")[[""alexarank""]]
  AlexaTestData = p.read_csv('FinalTestCSVFin.csv', delimiter="";"")[[""alexarank""]]
  AllAlexaAndGoogleInfo = AlexaTestData.append(AlexaTrainData)

  tfv = TfidfVectorizer(min_df=3,  max_features=None, strip_accents='unicode',  
        analyzer='word',token_pattern=r'\w{1,}',ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1) #tf-idf object
  rd = lm.LogisticRegression(penalty='l2', dual=True, tol=0.0001, 
                             C=1, fit_intercept=True, intercept_scaling=1.0, 
                             class_weight=None, random_state=None) #Classifier
  X_all = traindata + testdata #adding test and train data to put into tf-idf
  lentrain = len(traindata) #find length of train data
  tfv.fit(X_all) #fit tf-idf on all our text
  X_all = tfv.transform(X_all) #transform it
  X = X_all[:lentrain] #reduce to size of training set
  AllAlexaAndGoogleInfo = AllAlexaAndGoogleInfo[:lentrain] #reduce to size of training set
  X_test = X_all[lentrain:] #reduce to size of training set

  #printing debug info, output below : 
  print ""X.shape =&gt; "" + str(X.shape)
  print ""AllAlexaAndGoogleInfo.shape =&gt; "" + str(AllAlexaAndGoogleInfo.shape)
  print ""X_all.shape =&gt; "" + str(X_all.shape)

  #line we get error on
  X = np.hstack((X, AllAlexaAndGoogleInfo))
</code></pre>

<p>Below is the output and error message :</p>

<pre><code>X.shape =&gt; (7395, 238377)
AllAlexaAndGoogleInfo.shape =&gt; (7395, 1)
X_all.shape =&gt; (10566, 238377)



---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-12-2b310887b5e4&gt; in &lt;module&gt;()
     31 print ""X_all.shape =&gt; "" + str(X_all.shape)
     32 #X = np.column_stack((X, AllAlexaAndGoogleInfo))
---&gt; 33 X = np.hstack((X, AllAlexaAndGoogleInfo))
     34 sc = preprocessing.StandardScaler().fit(X)
     35 X = sc.transform(X)

C:\Users\Simon\Anaconda\lib\site-packages\numpy\core\shape_base.pyc in hstack(tup)
    271     # As a special case, dimension 0 of 1-dimensional arrays is ""horizontal""
    272     if arrs[0].ndim == 1:
--&gt; 273         return _nx.concatenate(arrs, 0)
    274     else:
    275         return _nx.concatenate(arrs, 1)

ValueError: all the input arrays must have same number of dimensions
</code></pre>

<p>What is causing my problem here? How can I fix this? As far as I can see I should be able to join these columns? What have I misunderstood?</p>

<p>Thank you.</p>

<p>Edit : </p>

<p>Using the method in the answer below gets the following error : </p>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-16-640ef6dd335d&gt; in &lt;module&gt;()
---&gt; 36 X = np.column_stack((X, AllAlexaAndGoogleInfo))
     37 sc = preprocessing.StandardScaler().fit(X)
     38 X = sc.transform(X)

C:\Users\Simon\Anaconda\lib\site-packages\numpy\lib\shape_base.pyc in column_stack(tup)
    294             arr = array(arr,copy=False,subok=True,ndmin=2).T
    295         arrays.append(arr)
--&gt; 296     return _nx.concatenate(arrays,1)
    297 
    298 def dstack(tup):

ValueError: all the input array dimensions except for the concatenation axis must match exactly
</code></pre>

<p>Interestingly, I tried to print the <code>dtype</code> of X and this worked fine : </p>

<pre><code>X.dtype =&gt; float64
</code></pre>

<p>However, trying to print the dtype of <code>AllAlexaAndGoogleInfo</code> like so : </p>

<pre><code>print ""AllAlexaAndGoogleInfo.dtype =&gt; "" + str(AllAlexaAndGoogleInfo.dtype) 
</code></pre>

<p>produces :</p>

<pre><code>'DataFrame' object has no attribute 'dtype'
</code></pre>
"
"ImportError: cannot import name inplace_column_scale","<p>Using Python 2.7 with scikit-learn 0.14 package. It runs well on some examples from the user guild expect the Linear Models.</p>

<pre><code>Traceback (most recent call last):
File ""E:\P\plot_ols.py"", line 28, in &lt;module&gt;
from sklearn import datasets, linear_model
File ""C:\Python27\lib\site-packages\sklearn\linear_model\__init__.py"", line 12, in    &lt;module&gt;
from .base import LinearRegression
File ""C:\Python27\lib\site-packages\sklearn\linear_model\base.py"", line 29, in &lt;module&gt;
from ..utils.sparsefuncs import mean_variance_axis0, inplace_column_scale
ImportError: cannot import name inplace_column_scale
</code></pre>

<p>Thank you~</p>
"
"How to nest LabelKFold?","<p>I have a dataset with ~300 points and 32 distinct labels and I want to evaluate a LinearSVR model by plotting its learning curve using grid search and LabelKFold validation.</p>

<p>The code I have looks like this:</p>

<pre><code>import numpy as np
from sklearn import preprocessing
from sklearn.svm import LinearSVR
from sklearn.pipeline import Pipeline
from sklearn.cross_validation import LabelKFold
from sklearn.grid_search import GridSearchCV
from sklearn.learning_curve import learning_curve
    ...
#get data (x, y, labels)
    ...
C_space = np.logspace(-3, 3, 10)
epsilon_space = np.logspace(-3, 3, 10)  

svr_estimator = Pipeline([
    (""scale"", preprocessing.StandardScaler()),
    (""svr"", LinearSVR),
])

search_params = dict(
    svr__C = C_space,
    svr__epsilon = epsilon_space
)

kfold = LabelKFold(labels, 5)

svr_search = GridSearchCV(svr_estimator, param_grid = search_params, cv = ???)

train_space = np.linspace(.5, 1, 10)
train_sizes, train_scores, valid_scores = learning_curve(svr_search, x, y, train_sizes = train_space, cv = ???, n_jobs = 4)
    ...
#plot learning curve
</code></pre>

<p>My question is how to setup the cv attribute for the grid search and learning curve so that it will break my original set into training and test sets that don't share any labels for computing the learning curve. And then from those training sets, further separate them into training and test sets without sharing labels for the grid search?</p>

<p>Essentially, how do I run a nested LabelKFold?</p>

<hr>

<p>I, the user who created the bounty for this question, wrote the following reproducible example using data available from <code>sklearn</code>.</p>

<pre><code>import numpy as np
from sklearn.datasets import load_digits
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import make_scorer, roc_auc_score
from sklearn.grid_search import GridSearchCV
from sklearn.cross_validation import cross_val_score, LabelKFold

digits = load_digits()
X = digits['data']
Y = digits['target']
Z = np.zeros_like(Y) ## this is just to make a 2-class problem, purely for the sake of an example
Z[np.where(Y&gt;4)]=1

strata = [x % 13 for x in xrange(Y.size)] # define the strata for use in

## define stuff for nested cv...
mtry = [5, 10]
tuned_par = {'max_features': mtry}
toy_rf = RandomForestClassifier(n_estimators=10, max_depth=10, random_state=10,
                                class_weight=""balanced"")
roc_auc_scorer = make_scorer(roc_auc_score, needs_threshold=True)

## define outer k-fold label-aware cv
outer_cv = LabelKFold(labels=strata, n_folds=5)

#############################################################################
##  this works: using regular randomly-allocated 10-fold CV in the inner folds
#############################################################################
vanilla_clf = GridSearchCV(estimator=toy_rf, param_grid=tuned_par, scoring=roc_auc_scorer,
                        cv=5, n_jobs=1)
vanilla_results = cross_val_score(vanilla_clf, X=X, y=Z, cv=outer_cv, n_jobs=1)

##########################################################################
##  this does not work: attempting to use label-aware CV in the inner loop
##########################################################################
inner_cv = LabelKFold(labels=strata, n_folds=5)
nested_kfold_clf = GridSearchCV(estimator=toy_rf, param_grid=tuned_par, scoring=roc_auc_scorer,
                                cv=inner_cv, n_jobs=1)
nested_kfold_results = cross_val_score(nested_kfold_clf, X=X, y=Y, cv=outer_cv, n_jobs=1)
</code></pre>
"
"scikit grid search over multiple classifiers python","<p>I wanted to know if there is a better more inbuilt way to do grid search and test multiple models in a single pipeline. Of course the parameters of the models would be different, which made is complicated for me to figure this out. Here is what I did:</p>

<pre><code>from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.grid_search import GridSearchCV


def grid_search():
    pipeline1 = Pipeline((
    ('clf', RandomForestClassifier()),
    ('vec2', TfidfTransformer())
    ))

    pipeline2 = Pipeline((
    ('clf', KNeighborsClassifier()),
    ))

    pipeline3 = Pipeline((
    ('clf', SVC()),
    ))

    pipeline4 = Pipeline((
    ('clf', MultinomialNB()),
    ))

    parameters1 = {
    'clf__n_estimators': [10, 20, 30],
    'clf__criterion': ['gini', 'entropy'],
    'clf__max_features': [5, 10, 15],
    'clf__max_depth': ['auto', 'log2', 'sqrt', None]
    }

    parameters2 = {
    'clf__n_neighbors': [3, 7, 10],
    'clf__weights': ['uniform', 'distance']
    }

    parameters3 = {
    'clf__C': [0.01, 0.1, 1.0],
    'clf__kernel': ['rbf', 'poly'],
    'clf__gamma': [0.01, 0.1, 1.0],

    }
    parameters4 = {
    'clf__alpha': [0.01, 0.1, 1.0]
    }

    pars = [parameters1, parameters2, parameters3, parameters4]
    pips = [pipeline1, pipeline2, pipeline3, pipeline4]

    print ""starting Gridsearch""
    for i in range(len(pars)):
        gs = GridSearchCV(pips[i], pars[i], verbose=2, refit=False, n_jobs=-1)
        gs = gs.fit(X_train, y_train)
        print ""finished Gridsearch""
        print gs.best_score_
</code></pre>

<p>However, this approach is still giving the best model within each classifier, and not comparing between classifiers.</p>
"
"Does the SVM in sklearn support incremental (online) learning?","<p>I am currently in the process of designing a recommender system for text articles (a binary case of 'interesting' or 'not interesting'). One of my specifications is that it should continuously update to changing trends. </p>

<p>From what I can tell, the best way to do this is to make use of machine learning algorithm that supports incremental/<a href=""http://en.wikipedia.org/wiki/Online%5fmachine%5flearning"">online learning</a>. </p>

<p>Algorithms like the Perceptron and Winnow support online learning but I am not completely certain about Support Vector Machines. Does the scikit-learn python library support online learning and if so, is a support vector machine one of the algorithms that can make use of it?</p>

<p>I am obviously not completely tied down to using support vector machines, but they are usually the go to algorithm for binary classification due to their all round performance. I would be willing to change to whatever fits best in the end.</p>
"
"Right function for normalizing input of sklearn SVM","<p>I found several questions related to this, but no one solved my doubts.
In particular, the two answers to <a href=""https://stackoverflow.com/questions/20506682/normalizing-feature-values-for-svm"">this</a> question confused me even more.</p>

<p>I'm training a linear SVM on top of a set of features - Convolutional Neural Net features resulting from images. I have, for example, a 3500x4096 <code>X</code> matrix with examples on rows and features on columns, as usual.</p>

<p>I'm wondering how to properly standardize/normalize this matrix before feeding the SVM. I see two ways (using sklearn):</p>

<ol>
<li><p>Standardizing features. It results in features with 0 mean and unitary std.</p>

<pre><code>X = sklearn.preprocessing.scale(X)
</code></pre></li>
<li><p>Normalizing features. It results in features with unitary norm.</p>

<pre><code>X = sklearn.preprocessing.normalize(X, axis=0)
</code></pre></li>
</ol>

<p>My results are sensibly better with normalization (76% accuracy) than with standardiing (68% accuracy).</p>

<p>Is it a completely dataset-dependent choice? Or how can one choose between the two techniques?</p>
"
"Scikit-learn balanced subsampling","<p>I'm trying to create N balanced random subsamples of my large unbalanced dataset. Is there a way to do this simply with scikit-learn / pandas or do I have to implement it myself? Any pointers to code that does this?</p>

<p>These subsamples should be random and can be overlapping as I feed each to separate classifier in a very large ensemble of classifiers.</p>

<p>In Weka there is tool called spreadsubsample, is there equivalent in sklearn? 
<a href=""http://wiki.pentaho.com/display/DATAMINING/SpreadSubsample"">http://wiki.pentaho.com/display/DATAMINING/SpreadSubsample</a></p>

<p>(I know about weighting but that's not what I'm looking for.)</p>
"
"How does the class_weight parameter in scikit-learn work?","<p>I am having a lot of trouble understanding how the <code>class_weight</code> parameter in scikit-learn's Logistic Regression operates.</p>

<p><strong>The Situation</strong></p>

<p>I want to use logistic regression to do binary classification on a very unbalanced data set. The classes are labelled 0 (negative) and 1 (positive) and the observed data is in a ratio of about 19:1 with the majority of samples having negative outcome.</p>

<p><strong>First Attempt: Manually Preparing Training Data</strong></p>

<p>I split the data I had into disjoint sets for training and testing (about 80/20). Then I randomly sampled the training data by hand to get training data in different proportions than 19:1; from 2:1 -> 16:1.</p>

<p>I then trained logistic regression on these different training data subsets and plotted recall (= TP/(TP+FN)) as a function of the different training proportions. Of course, the recall was computed on the disjoint TEST samples which had the observed proportions of 19:1. Note, although I trained the different models on different training data, I computed recall for all of them on the same (disjoint) test data.</p>

<p>The results were as expected: the recall was about 60% at 2:1 training proportions and fell off rather fast by the time it got to 16:1. There were several proportions 2:1 -> 6:1 where the recall was decently above 5%.</p>

<p><strong>Second Attempt: Grid Search</strong></p>

<p>Next, I wanted to test different regularization parameters and so I used GridSearchCV and made a grid of several values of the <code>C</code> parameter as well as the <code>class_weight</code> parameter. To translate my n:m proportions of negative:positive training samples into the dictionary language of <code>class_weight</code> I thought that I just specify several dictionaries as follows:</p>

<pre><code>{ 0:0.67, 1:0.33 } #expected 2:1
{ 0:0.75, 1:0.25 } #expected 3:1
{ 0:0.8, 1:0.2 }   #expected 4:1
</code></pre>

<p>and I also included <code>None</code> and <code>auto</code>.</p>

<p>This time the results were totally wacked. All my recalls came out tiny (&lt; 0.05) for every value of <code>class_weight</code> except <code>auto</code>. So I can only assume that my understanding of how to set the <code>class_weight</code> dictionary is wrong. Interestingly, the <code>class_weight</code> value of 'auto' in the grid search was around 59% for all values of <code>C</code>, and I guessed it balances to 1:1?</p>

<p><strong>My Questions</strong></p>

<p>1) How do you properly use <code>class_weight</code> to achieve different balances in training data from what you actually give it? Specifically, what dictionary do I pass to <code>class_weight</code> to use n:m proportions of negative:positive training samples?</p>

<p>2) If you pass various <code>class_weight</code> dictionaries to GridSearchCV, during cross-validation will it rebalance the training fold data according to the dictionary but use the true given sample proportions for computing my scoring function on the test fold? This is critical since any metric is only useful to me if it comes from data in the observed proportions.</p>

<p>3) What does the <code>auto</code> value of <code>class_weight</code> do as far as proportions? I read the documentation and I assume ""balances the data inversely proportional to their frequency"" just means it makes it 1:1. Is this correct? If not, can someone clarify?</p>

<p>Thank you very much, any clarification would be greatly appreciated!</p>
"
"how to explain the decision tree from scikit-learn","<p>I have two problems with understanding the result of decision tree from scikit-learn. For example, this is one of my decision trees:</p>

<p><img src=""https://i.stack.imgur.com/hwGVa.png"" alt=""enter image description here"">
My question is that how I can use the tree? </p>

<p>The first question is that: if a sample satisfied the condition, then it goes to the <strong>LEFT</strong> branch (if exists), otherwise it goes <strong>RIGHT</strong>. In my case, if a sample with X[7] > 63521.3984. Then the sample will go to the green box. Correct?</p>

<p>The second question is that: when a sample reaches the leaf node, how can I know which category it belongs? In this example, I have three categories to classify. In the red box, there are 91, 212, and 113 samples are satisfied the condition, respectively. But how can I decide the category? 
I know there is a function  <strong>clf.predict(sample)</strong> to tell the category. Can I do that from the graph???
Many thanks.</p>
"
"Should I use `random.seed` or `numpy.random.seed` to control random number generation in `scikit-learn`?","<p>I'm using scikit-learn and numpy and I want to set the global seed so that my work is reproducible.</p>

<p>Should I use <code>numpy.random.seed</code> or <code>random.seed</code>?</p>

<p><strong>Edit:</strong>
From the link in the comments, I understand that they are different, and that the numpy version is not thread-safe. I want to know specifically which one to use to create IPython notebooks for data analysis. Some of the algorithms from scikit-learn involve generating random numbers, and I want to be sure that the notebook shows the same results on every run.</p>
"
"Efficiently create sparse pivot tables in pandas?","<p>I'm working turning a list of records with two columns (A and B) into a matrix representation. I have been using the pivot function within pandas, but the result ends up being fairly large. Does pandas support pivoting into a sparse format? I know I can pivot it and then turn it into some kind of sparse representation, but isn't as elegant as I would like. My end goal is to use it as the input for a predictive model.</p>

<p>Alternatively, is there some kind of sparse pivot capability outside of pandas?</p>

<p>edit: here is an example of a non-sparse pivot</p>

<pre><code>import pandas as pd
frame=pd.DataFrame()
frame['person']=['me','you','him','you','him','me']
frame['thing']=['a','a','b','c','d','d']
frame['count']=[1,1,1,1,1,1]

frame

  person thing  count
0     me     a      1
1    you     a      1
2    him     b      1
3    you     c      1
4    him     d      1
5     me     d      1

frame.pivot('person','thing')

        count            
thing       a   b   c   d
person                   
him       NaN   1 NaN   1
me          1 NaN NaN   1
you         1 NaN   1 NaN
</code></pre>

<p>This creates a matrix that could contain all possible combinations of persons and things, but it is not sparse.</p>

<p><a href=""http://docs.scipy.org/doc/scipy/reference/sparse.html"">http://docs.scipy.org/doc/scipy/reference/sparse.html</a></p>

<p>Sparse matrices take up less space because they can imply things like NaN or 0. If I have a very large data set, this pivoting function can generate a matrix that should be sparse due to the large number of NaNs or 0s. I was hoping that I could save a lot of space/memory by generating something that was sparse right off the bat rather than creating a dense matrix and then converting it to sparse.</p>
"
"Making SVM run faster in python","<p>Using the <strong>code</strong> below for svm in python:  </p>

<pre><code>from sklearn import datasets
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import SVC
iris = datasets.load_iris()
X, y = iris.data, iris.target
clf = OneVsRestClassifier(SVC(kernel='linear', probability=True, class_weight='auto'))
clf.fit(X, y)
proba = clf.predict_proba(X)
</code></pre>

<p>But it is taking a huge amount of time.</p>

<p><strong>Actual Data Dimensions</strong>:</p>

<pre><code>train-set (1422392,29)
test-set (233081,29)
</code></pre>

<p>How can I speed it up(parallel or some other way)? Please help.
I have already tried PCA and downsampling. </p>

<p>I have 6 classes.
Edit:
Found <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html"">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html</a>
but I wish for probability estimates and it seems not to so for svm.</p>

<p><strong>Edit:</strong></p>

<pre><code>from sklearn import datasets
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import SVC,LinearSVC
from sklearn.linear_model import SGDClassifier
import joblib
import numpy as np
from sklearn import grid_search
import multiprocessing
import numpy as np
import math

def new_func(a):                              #converts array(x) elements to (1/(1 + e(-x)))
    a=1/(1 + math.exp(-a))
    return a

if __name__ == '__main__':
    iris = datasets.load_iris()
    cores=multiprocessing.cpu_count()-2
    X, y = iris.data, iris.target                       #loading dataset

    C_range = 10.0 ** np.arange(-4, 4);                  #c value range 
    param_grid = dict(estimator__C=C_range.tolist())              

    svr = OneVsRestClassifier(LinearSVC(class_weight='auto'),n_jobs=cores) ################LinearSVC Code faster        
    #svr = OneVsRestClassifier(SVC(kernel='linear', probability=True,  ##################SVC code slow
    #   class_weight='auto'),n_jobs=cores)

    clf = grid_search.GridSearchCV(svr, param_grid,n_jobs=cores,verbose=2)  #grid search
    clf.fit(X, y)                                                   #training svm model                                     

    decisions=clf.decision_function(X)                             #outputs decision functions
    #prob=clf.predict_proba(X)                                     #only for SVC outputs probablilites
    print decisions[:5,:]
    vecfunc = np.vectorize(new_func)
    prob=vecfunc(decisions)                                        #converts deicision to (1/(1 + e(-x)))
    print prob[:5,:]
</code></pre>

<p><strong>Edit 2:</strong>
The answer by user3914041 yields very poor probability estimates.</p>
"
"Easy way to use parallel options of scikit-learn functions on HPC","<p>In many functions from scikit-learn implemented user-friendly parallelization. For example  in 
<code>sklearn.cross_validation.cross_val_score</code> you just pass desired number of computational jobs in <code>n_jobs</code> argument. And for PC with multi-core processor it will work very nice. But if I want use such option in high performance cluster (with installed OpenMPI package and using SLURM for resource management) ? As I know <code>sklearn</code> uses <code>joblib</code> for parallelization, which uses <code>multiprocessing</code>. And, as I know (from this, for example, <a href=""https://stackoverflow.com/questions/25772289/python-multiprocessing-within-mpi"">Python multiprocessing within mpi</a>) Python programs parallelized with <code>multiprocessing</code> easy to scale oh whole MPI architecture with <code>mpirun</code> utility. Can I spread computation of <code>sklearn</code> functions on several computational nodes just using <code>mpirun</code> and <code>n_jobs</code> argument?    </p>
"
"How can I plot the probability density function for a fitted Gaussian mixture model under scikit-learn?","<p>I'm struggling with a rather simple task.  I have a vector of floats to which I would like to fit a Gaussian mixture model with two Gaussian kernels:</p>

<pre><code>from sklearn.mixture import GMM

gmm = GMM(n_components=2)
gmm.fit(values)  # values is numpy vector of floats
</code></pre>

<p>I would now like to plot the probability density function for the mixture model I've created, but I can't seem to find any documentation on how to do this.  How should I best proceed?</p>

<p><strong>Edit:</strong></p>

<p><a href=""https://dl.dropboxusercontent.com/u/6160029/kde.pickle"" rel=""noreferrer"">Here</a> is the vector of data I'm fitting.  And below is a more detailed example of how I'm doing things:</p>

<pre><code>from sklearn.mixture import GMM
from matplotlib.pyplot import *
import numpy as np

try:
    import cPickle as pickle
except:
    import pickle

with open('/path/to/kde.pickle') as f:  # open the data file provided above
    kde = pickle.load(f)

gmm = GMM(n_components=2)
gmm.fit(kde)

x = np.linspace(np.min(kde), np.max(kde), len(kde))

# Plot the data to which the GMM is being fitted
figure()
plot(x, kde, color='blue')
</code></pre>

<p><img src=""https://i.stack.imgur.com/kMqGa.png"" alt=""enter image description here""></p>

<pre><code># My half-baked attempt at replicating the scipy example
fit = gmm.score_samples(x)[0]
plot(x, fit, color='red')
</code></pre>

<p><img src=""https://i.imgur.com/t9BnseY.png"" alt=""""></p>

<p>The fitted curve doesn't look anything like what I'd expect. It doesn't even seem Gaussian, which is a bit strange given it was produced by a Gaussian process.  Am I crazy?</p>
"