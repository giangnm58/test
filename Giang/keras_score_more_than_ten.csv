Title,Body
"Theano with Keras on Raspberry Pi","<p>I am trying to get Theano to run with Keras on a Raspberry Pi 3 (B) without success. I tried Ubuntu MATE and Raspbian as operating systems, without success. To install Theano and Keras, I have taken following steps:</p>

<ol>
<li>Install miniconda (armv7 distribution)</li>
<li>Install all Theano dependencies (as shown <a href=""http://deeplearning.net/software/theano/install_ubuntu.html"" rel=""noreferrer"">here</a>) through Conda (if possible), <code>pip</code> and <code>apt-get</code></li>
<li>Install Theano </li>
<li>Install Keras</li>
</ol>

<p>The aforementioned steps work without any issues. In the next step, I built a little test script (test.py) which loads an already built model via </p>

<pre><code>from keras.models import load_model
model = load_model('model.hdf5')
</code></pre>

<p>When the model is being loaded, I get the following error</p>

<pre><code>Segmentation fault (core dumped)
</code></pre>

<p>Then I tried to investigate the issue further, following this answer on SO (<a href=""https://stackoverflow.com/questions/10035541/what-causes-a-python-segmentation-fault"">What causes a Python segmentation fault?</a>):</p>

<pre><code>gdb python
&gt; run test.py
</code></pre>

<p>When I run this I get:</p>

<pre><code>Program received SIGSEV, Segmentation fault.
0x76fd9822 in ?? () from /lib/ld-linux-armhf.so.3
</code></pre>

<p>In the next step I ran in the gdb shell:</p>

<pre><code>&gt; backtrace
</code></pre>

<p>and got</p>

<pre><code>#0  0x76fd9822 in ?? () from /lib/ld-linux-armhf.so.3
#1  0x76fd983a in ?? () from /lib/ld-linux-armhf.so.3
</code></pre>

<p>this is the point where I don't know any further and I would like to ask, if anyone could point me into a direction on how to fix this issue and get keras + theano to run on a Raspberry Pi.</p>

<p>(I have also tried TensorFlow as an alternative, but getting the same issue)</p>

<p>Thanks a lot.</p>

<hr>

<p>EDIT</p>

<p>I have done some more investigations. If I <a href=""https://github.com/samjabrahams/tensorflow-on-raspberry-pi"" rel=""noreferrer"">run Keras with TensorFlow</a> the problem seems to change a little bit. I ran gdb again, but the error happens now in numpy, especially in libopenblas.so.0</p>

<pre><code>Program received signal SIGSEV, Segmentation fault.
0x75ead7cc in inner_thread()
from /home/&lt;path&gt;/numpy/core/../../../../libopenblas.so.0
</code></pre>

<p>Does this help?</p>

<hr>

<p>EDIT 2</p>

<p>I have installed everything without using Miniconda and Keras works now with TensorFlow (but not with Theano yet). </p>
"
"Getting gradient of model output w.r.t weights using Keras","<p>I am interesting in building reinforcement learning models with the simplicity of the Keras API. Unfortunately, I am unable to extract the gradient of the output (not error) with respect to the weights. I found the following code that performs a similar function (<a href=""https://stackoverflow.com/questions/36968128/saliency-maps-of-neural-networks-using-keras"">Saliency maps of neural networks (using Keras)</a>)</p>

<pre><code>get_output = theano.function([model.layers[0].input],model.layers[-1].output,allow_input_downcast=True)
fx = theano.function([model.layers[0].input] ,T.jacobian(model.layers[-1].output.flatten(),model.layers[0].input), allow_input_downcast=True)
grad = fx([trainingData])
</code></pre>

<p>Any ideas on how to calculate the gradient of the model output with respect to the weights for each layer would be appreciated.</p>
"
"Neural Network LSTM input shape from dataframe","<p>I am trying to implement an <a href=""https://keras.io/layers/recurrent/#lstm"" rel=""noreferrer"">LSTM with Keras</a>.</p>

<p>I know that LSTM's in Keras require a 3D tensor with shape <code>(nb_samples, timesteps, input_dim)</code> as an input. However, I am not entirely sure how the input should look like in my case, as I have just one sample of <code>T</code> observations for each input, not multiple samples, i.e. <code>(nb_samples=1, timesteps=T, input_dim=N)</code>. Is it better to split each of my inputs into samples of length <code>T/M</code>? <code>T</code> is around a few million observations for me, so how long should each sample in that case be, i.e., how would I choose <code>M</code>?</p>

<p>Also, am I right in that this tensor should look something like:</p>

<p><code>[[[a_11, a_12, ..., a_1M], [a_21, a_22, ..., a_2M], ..., [a_N1, a_N2, ..., a_NM]], [[b_11, b_12, ..., b_1M], [b_21, b_22, ..., b_2M], ..., [b_N1, b_N2, ..., b_NM]], ..., [[x_11, x_12, ..., a_1M], [x_21, x_22, ..., x_2M], ..., [x_N1, x_N2, ..., x_NM]]]</code>, where M and N defined as before and x corresponds to the last sample that I would have obtained from splitting as discussed above? </p>

<p>Finally, given a pandas dataframe with <code>T</code> observations in each column, and <code>N</code> columns, one for each input, how can I create such an input to feed to Keras?</p>
"
"Keras LSTM predicted timeseries squashed and shifted","<p>I'm trying to get some hands on experience with Keras during the holidays, and I thought I'd start out with the textbook example of timeseries prediction on stock data. So what I'm trying to do is given the last 48 hours worth of average price changes (percent since previous), predict what the average price chanege of the coming hour is.</p>

<p>However, when verifying against the test set (or even the training set) the amplitude of the predicted series is way off, and sometimes is shifted to be either always positive or always negative, i.e., shifted away from the 0% change, which I think would be correct for this kind of thing.</p>

<p>I came up with the following minimal example to show the issue:</p>

<pre><code>df = pandas.DataFrame.from_csv('test-data-01.csv', header=0)
df['pct'] = df.value.pct_change(periods=1)

seq_len=48
vals = df.pct.values[1:] # First pct change is NaN, skip it
sequences = []
for i in range(0, len(vals) - seq_len):
    sx = vals[i:i+seq_len].reshape(seq_len, 1)
    sy = vals[i+seq_len]
    sequences.append((sx, sy))

row = -24
trainSeqs = sequences[:row]
testSeqs = sequences[row:]

trainX = np.array([i[0] for i in trainSeqs])
trainy = np.array([i[1] for i in trainSeqs])

model = Sequential()
model.add(LSTM(25, batch_input_shape=(1, seq_len, 1)))
model.add(Dense(1))
model.compile(loss='mse', optimizer='adam')
model.fit(trainX, trainy, epochs=1, batch_size=1, verbose=1, shuffle=True)

pred = []
for s in trainSeqs:
    pred.append(model.predict(s[0].reshape(1, seq_len, 1)))
pred = np.array(pred).flatten()

plot(pred)
plot([i[1] for i in trainSeqs])
axis([2500, 2550,-0.03, 0.03])
</code></pre>

<p>As you can see, I create training and testing sequences, by selecting the last 48 hours, and the next step into a tuple, and then advancing 1 hour, repeating the procedure. The model is a very simple 1 LSTM and 1 dense layer.</p>

<p>I would have expected the plot of individual predicted points to overlap pretty nicely the plot of training sequences (after all this is the same set they were trained on), and sort of match for the test sequences. However I get the following result on <strong>training data</strong>:</p>

<ul>
<li>Orange: true data    </li>
<li>Blue: predicted data</li>
</ul>

<p><a href=""https://i.stack.imgur.com/bbPvr.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/bbPvr.png"" alt=""enter image description here""></a></p>

<p>Any idea what might be going on? Did I misunderstand something?</p>

<p><em>Update</em>: to better show what I mean by shifted and squashed I also plotted the predicted values by shifting it back to match the real data and multiplied to match the amplitude.</p>

<pre><code>plot(pred*12-0.03)
plot([i[1] for i in trainSeqs])
axis([2500, 2550,-0.03, 0.03])
</code></pre>

<p><a href=""https://i.stack.imgur.com/6k0F4.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/6k0F4.png"" alt=""enter image description here""></a></p>

<p>As you can see the prediction nicely fits the real data, it's just squashed and offset somehow, and I can't figure out why.</p>
"
"How to convert a dense layer to an equivalent convolutional layer in Keras?","<p>I would like to do something similar to the Fully Convolutional Networks paper (<a href=""https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf"" rel=""nofollow noreferrer"">https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf</a>) using Keras.  I have a network which ends up flattening the feature maps and runs them through several dense layers.  I would like to load the weights from a network like this into one where the dense layers are replaced with equivalent convolutions.</p>

<p>The VGG16 network which comes with Keras could be used as an example, where the 7x7x512 output of the last MaxPooling2D() is flattened and then goes into a Dense(4096) layer.  In this case the Dense(4096) would be replaced with a 7x7x4096 convolution.  </p>

<p>My real network is slightly different, there is a GlobalAveragePooling2D() layer instead of MaxPooling2D() and Flatten().  The output of GlobalAveragePooling2D() is a 2D tensor, and there is no need to additionally flatten it, so all the dense layers including the first would be replaced with 1x1 convolutions. </p>

<p>I've seen this question: <a href=""https://stackoverflow.com/questions/36966392/python-keras-how-to-transform-a-dense-layer-into-a-convolutional-layer"">Python keras how to transform a dense layer into a convolutional layer</a> which seems very similar if not identical.  The trouble is I can't get the suggested solution to work, because (a) I'm using TensorFlow as the backend, so the weights rearrangement/filter ""rotation"" isn't right, and (b) I can't figure out how to load the weights.  Loading the old weights file into the new network with <code>model.load_weights(by_name=True)</code> doesn't work, because the names don't match (and even if they did the dimensions differ).  </p>

<p>What should the rearrangement be when using TensorFlow?</p>

<p>How do I load the weights?  Do I create one of each model, call model.load_weights() on both to load the identical weights and then copy some of the extra weights that need rearrangement?</p>
"
"How to get reproducible results in keras","<p>I get different results (test accuracy) every time I run the <code>imdb_lstm.py</code> example from Keras framework (<a href=""https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py"">https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py</a>)
The code contains <code>np.random.seed(1337)</code> in the top, before any keras imports. It should prevent it from generating different numbers for every run. What am I missing?  </p>

<p>UPDATE: How to repro:  </p>

<ol>
<li>Install Keras (<a href=""http://keras.io/"">http://keras.io/</a>)   </li>
<li>Execute <a href=""https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py"">https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py</a>  a few times. It will train the model and output test accuracy.<br>
Expected result: Test accuracy is the same on every run.<br>
Actual result: Test accuracy is different on every run.</li>
</ol>

<p>UPDATE2: I'm running it on Windows 8.1 with MinGW/msys, module versions:<br>
theano 0.7.0<br>
numpy 1.8.1<br>
scipy 0.14.0c1</p>

<p>UPDATE3: I narrowed the problem down a bit. If I run the example with GPU (set theano flag device=gpu0) then I get different test accuracy every time, but if I run it on CPU then everything works as expected. My graphics card: NVIDIA GeForce GT 635)</p>
"
"Can Keras with Tensorflow backend be forced to use CPU or GPU at will?","<p>I have Keras installed with the Tensorflow backend and CUDA.  I'd like to sometimes on demand force Keras to use CPU.  Can this be done without say installing a separate CPU-only Tensorflow in a virtual environment?  If so how?  If the backend were Theano, the flags could be set, but I have not heard of Tensorflow flags accessible via Keras.  </p>
"
"How to save Scikit-Learn-Keras Model into a Persistence File (pickle/hd5/json/yaml)","<p>I have the following code, using <a href=""https://github.com/fchollet/keras/blob/master/keras/wrappers/scikit_learn.py"">Keras Scikit-Learn Wrapper</a>:</p>

<pre><code>from keras.models import Sequential
from sklearn import datasets
from keras.layers import Dense
from sklearn.model_selection import train_test_split
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn import preprocessing
import pickle
import numpy as np
import json

def classifier(X, y):
    """"""
    Description of classifier
    """"""
    NOF_ROW, NOF_COL =  X.shape

    def create_model():
        # create model
        model = Sequential()
        model.add(Dense(12, input_dim=NOF_COL, init='uniform', activation='relu'))
        model.add(Dense(6, init='uniform', activation='relu'))
        model.add(Dense(1, init='uniform', activation='sigmoid'))
        # Compile model
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        return model

    # evaluate using 10-fold cross validation
    seed = 7
    np.random.seed(seed)
    model = KerasClassifier(build_fn=create_model, nb_epoch=150, batch_size=10, verbose=0)
    return model


def main():
    """"""
    Description of main
    """"""

    iris = datasets.load_iris()
    X, y = iris.data, iris.target
    X = preprocessing.scale(X)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)
    model_tt = classifier(X_train, y_train)
    model_tt.fit(X_train,y_train)

    #--------------------------------------------------
    # This fail
    #-------------------------------------------------- 
    filename = 'finalized_model.sav'
    pickle.dump(model_tt, open(filename, 'wb'))
    # load the model from disk
    loaded_model = pickle.load(open(filename, 'rb'))
    result = loaded_model.score(X_test, Y_test)
    print(result)

    #--------------------------------------------------
    # This also fail
    #--------------------------------------------------
    # from keras.models import load_model       
    # model_tt.save('test_model.h5')


    #--------------------------------------------------
    # This works OK 
    #-------------------------------------------------- 
    # print model_tt.score(X_test, y_test)
    # print model_tt.predict_proba(X_test)
    # print model_tt.predict(X_test)


# Output of predict_proba
# 2nd column is the probability that the prediction is 1
# this value is used as final score, which can be used
# with other method as comparison
# [   [ 0.25311464  0.74688536]
#     [ 0.84401423  0.15598579]
#     [ 0.96047372  0.03952631]
#     ...,
#     [ 0.25518912  0.74481088]
#     [ 0.91467732  0.08532269]
#     [ 0.25473493  0.74526507]]

# Output of predict
# [[1]
# [0]
# [0]
# ...,
# [1]
# [0]
# [1]]


if __name__ == '__main__':
    main()
</code></pre>

<p>As stated in the code there it fails at this line:</p>

<pre><code>pickle.dump(model_tt, open(filename, 'wb'))
</code></pre>

<p>With this error:</p>

<pre><code>pickle.PicklingError: Can't pickle &lt;function create_model at 0x101c09320&gt;: it's not found as __main__.create_model
</code></pre>

<p>How can I get around it?</p>
"
"Tensorflow AttributeError: 'NoneType' object has no attribute 'TF_DeleteStatus'","<p>Tensorflow is giving me this unresolved error:</p>

<pre><code>Exception ignored in: &lt;bound method BaseSession.__del__ of &lt;tensorflow.python.client.session.Session object at 0x7f68d14b6668&gt;&gt;
Traceback (most recent call last):
  File ""/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 532, in __del__
AttributeError: 'NoneType' object has no attribute 'TF_DeleteStatus'
</code></pre>

<p>The error has been discussed <a href=""https://github.com/tensorflow/tensorflow/issues/3388"">here</a>. The problem is it is not showing up consistently. However, it is showing up in my terminal frequently. Has anybody managed to get around it.Thanks.</p>
"
"Is Keras thread safe?","<p>I'm using Python and Keras (currently using Theano backend, but I have no qualms with switching). I have a neural network that I load and process multiple sources of information with in parallel. Currently, I've been running each one in a separate process and it loads its own copy of the network from the file. This seems like a waste of RAM, so I was thinking it would be more efficient to have a single multi-threaded process with one instance of the network that is used by all threads. However, I'm wondering if Keras is thread safe with either backend. If I run <code>.predict(x)</code> on two different inputs at the same time in different threads, will I run into race conditions or other issues?</p>

<p>Thanks</p>
"
"Add Tensorflow pre-processing to existing Keras model (for use in Tensorflow Serving)","<p>I would like to include my custom pre-processing logic in my exported Keras model for use in Tensorflow Serving.</p>

<p><em>My pre-processing performs string tokenization and uses an external dictionary to convert each token to an index for input to the Embedding layer:</em></p>

<pre><code>from keras.preprocessing import sequence

token_to_idx_dict = ... #read from file

# Custom Pythonic pre-processing steps on input_data
tokens = [tokenize(s) for s in input_data]
token_idxs = [[token_to_idx_dict[t] for t in ts] for ts in tokens]
tokens_padded = sequence.pad_sequences(token_idxs, maxlen=maxlen)
</code></pre>

<p><em>Model architecture and training:</em></p>

<pre><code>model = Sequential()
model.add(Embedding(max_features, 128, input_length=maxlen))
model.add(LSTM(128, activation='sigmoid'))
model.add(Dense(n_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')

model.fit(x_train, y_train)
</code></pre>

<p>Since the model will be used in Tensorflow Serving, I want to incorporate all pre-processing logic into the model itself (encoded in the exported model file).</p>

<p><strong>Q: How can I do so using the Keras library only?</strong></p>

<p>I found <a href=""https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html"" rel=""noreferrer"">this guide</a> explains how to combine Keras and Tensorflow. But I'm still unsure how to export everything as one model.</p>

<p>I know Tensorflow has built-in string splitting, <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lookup/lookup_ops.py#L320"" rel=""noreferrer"">file I/O</a>, and <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lookup/lookup_ops.py#L195"" rel=""noreferrer"">dictionary lookup operations</a>.</p>

<p><em>Pre-processing logic using Tensorflow operations:</em></p>

<pre><code># Get input text
input_string_tensor = tf.placeholder(tf.string, shape={1})
# Split input text by whitespace
splitted_string = tf.string_split(input_string_tensor, "" "")
# Read index lookup dictionary
token_to_idx_dict = tf.contrib.lookup.HashTable(tf.contrib.lookup.TextFileInitializer(""vocab.txt"", tf.string, 0, tf.int64, 1, delimiter="",""), -1)
# Convert tokens to indexes
token_idxs = token_to_idx_dict.lookup(splitted_string)
# Pad zeros to fixed length
token_idxs_padded = tf.pad(token_idxs, ...)
</code></pre>

<p><strong>Q: How can I use these Tensorflow pre-defined pre-processing operations and my Keras layers together to both train and then export the model as a ""black box"" for use in Tensorflow Serving?</strong></p>
"
"How to properly manage memory and batch size with TensorFlow","<p>I am using TensorFlow to build a simple feed-forward neural network, and I am using variable size batches. I am not using the GPU, I have 8GB RAM, and running on Python 3.5.2.</p>

<p>My problem is that I have some batches that are too big and are generating the typical out of memory error. I understand that, it is not a problem. However, if I use Keras with TF backend I don't have that issue. I have built an example (with fixed size batches) bellow that illustrates this.</p>

<p>Is there a problem with my implementation? How should I handle batches that are too big?</p>

<h3>TensorFlow example (exhausts memory)</h3>



<pre class=""lang-py prettyprint-override""><code>
import numpy as np
import tensorflow as tf

n_observations = 100000
n_input = 6
batch_size = 20000
X = np.random.rand(n_observations, n_input)
Y = X[:,0] ** 3 + X[:,1] ** 2 + X[:,2] + X[:,3] + X[:,4] + X[:,5]+ np.random.rand(n_observations)

n_hidden = 16
n_output = 1

def generatebatch(n_observations, batch_size):
    for batch_i in range(n_observations // batch_size):
        start = batch_i*batch_size
        end = start + batch_size
        batch_xs = X[start:end, :]
        batch_ys = Y[start:end]
        yield batch_xs, batch_ys

with tf.Session() as sess:
    # placeholders for input and target
    net_input = tf.placeholder(tf.float32, [None, n_input])
    y_true = tf.placeholder(tf.float32)

    # Hidden Layer
    W1 = tf.Variable(tf.random_normal([n_input, n_hidden]))
    b1 = tf.Variable(tf.random_normal([n_hidden]))
    net_output1 = tf.nn.relu(tf.matmul(net_input, W1) + b1)

    # Yet another Hidden Layer
    yaW1 = tf.Variable(tf.random_normal([n_hidden, n_hidden]))
    yab1 = tf.Variable(tf.random_normal([n_hidden]))
    yanet_output1 = tf.nn.relu(tf.matmul(net_output1, yaW1) + yab1)

    # Output Layer
    W2 = tf.Variable(tf.random_normal([n_hidden, n_output]))
    b2 = tf.Variable(tf.random_normal([n_output]))
    net_output2 = tf.nn.relu(tf.matmul(yanet_output1, W2) + b2)

    # The loss function
    cost = tf.reduce_mean(tf.pow(y_true - net_output2, 2))

    # Configure the optimizer
    optimizer = tf.train.AdamOptimizer().minimize(cost)

    # Initialize variables
    sess.run(tf.global_variables_initializer())

    n_epochs = 100
    for epoch_i in range(n_epochs):
        batchloss = []
        for batch_xs, batch_ys in generatebatch(n_observations, batch_size):
            _, loss = sess.run(
                [optimizer, cost],
                feed_dict={
                    net_input: batch_xs,
                    y_true: batch_ys
            })
            batchloss.append(loss)
        print(np.mean(batchloss))
</code></pre>

<h3>Keras Example (handles the batch size somehow)</h3>

<pre class=""lang-py prettyprint-override""><code>
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
import logging

#just to hide the deprecation warnings
logging.basicConfig(level=logging.CRITICAL)

n_input = 6
n_observations = 100000
n_hidden = 16
n_epochs = 10
batch_size = 35000

# input data
X = np.random.rand(n_observations, n_input)
Y = X[:,0] ** 3 + X[:,1] ** 2 + X[:,2] + X[:,3] + X[:,4] + X[:,5]+ np.random.rand(n_observations)

# create and fit Multilayer Perceptron model
model = Sequential()
model.add(Dense(n_hidden, input_dim=n_input, activation='relu'))
model.add(Dense(n_hidden, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='mse', optimizer='adam')
model.fit(X, Y, nb_epoch=n_epochs, batch_size=batch_size, verbose=1)
</code></pre>
"
"How to change Keras backend (where's the json file)?","<p>I have installed Keras, and wanted to switch the backend to Theano. I checked out <a href=""https://stackoverflow.com/questions/40036748/keras-backend-importerror-cannot-import-name-ctc-ops"">this post</a>, but still have no idea where to put the created json file. Also, below is the error I got when running <code>import keras</code> in Python Shell:</p>

<blockquote>
  <p>Using TensorFlow backend.</p>
  
  <p>Traceback (most recent call last):   File """", line 1, in
  
      import keras   File ""C:\Python27\lib\site-packages\keras__init__.py"", line 2, in 
      from . import backend   File ""C:\Python27\lib\site-packages\keras\backend__init__.py"", line 64, in
  
      from .tensorflow_backend import *   File ""C:\Python27\lib\site-packages\keras\backend\tensorflow_backend.py"",
  line 1, in 
      import tensorflow as tf ImportError: No module named tensorflow</p>
</blockquote>

<p>When running <code>python -c ""import keras; print(keras.__version__)""</code> from Windows command line, I got:</p>

<blockquote>
  <p>Using TensorFlow backend. Traceback (most recent call last):   File
  """", line 1, in    File
  ""C:\Python27\lib\site-packages\keras__init__.py"", line 2, in 
      from . import backend   File ""C:\Python27\lib\site-packages\keras\backend__init__.py"", line 64, in
  
      from .tensorflow_backend import *   File ""C:\Python27\lib\site-packages\keras\backend\tensorflow_backend.py"",
  line 1, in 
      import tensorflow as tf ImportError: No module named tensorflow</p>
</blockquote>

<p>Can someone please help? Thanks!</p>
"
"How to stack multiple lstm in keras?","<p>I am using deep learning library keras and trying to stack multiple LSTM with no luck.
Below is my code</p>

<pre><code>model = Sequential()
model.add(LSTM(100,input_shape =(time_steps,vector_size)))
model.add(LSTM(100))
</code></pre>

<p>The above code returns error in the third line <code>Exception: Input 0 is incompatible with layer lstm_28: expected ndim=3, found ndim=2
</code></p>

<p>The input X is a tensor of shape (100,250,50). I am running keras on tensorflow backend</p>
"
"How to construct input data to LSTM for time series multi-step horizon with external features?","<p>I'm trying to use LSTM to do store sales forecast. Here is how my raw data look like:</p>

<pre><code>|     Date   | StoreID | Sales | Temperature |  Open   | StoreType |
|------------|---------|-------|-------------|---------|-----------|
| 01/01/2016 |   1     |   0   |      36     |    0    |     1     |
| 01/02/2016 |   1     | 10100 |      42     |    1    |     1     |
| ...
| 12/31/2016 |   1     | 14300 |      39     |    1    |     1     |
| 01/01/2016 |   2     | 25000 |      46     |    1    |     3     |
| 01/02/2016 |   2     | 23700 |      43     |    1    |     3     |
| ...
| 12/31/2016 |   2     | 20600 |      37     |    1    |     3     |
| ...
| 12/31/2016 |   10    | 19800 |      52     |    1    |     2     |
</code></pre>

<p>I need to forecast for the next 10 days' sales. In this example, I will need to forecast the store sales from 01-01-2017 to 01-10-2017. I know how to use other time series model or regression model to solve this problem, but I want to know if RNN-LSTM is a good candidate for it. </p>

<p>I started by taking <strong><em>only storeID=1 data</em></strong> to test the LSTM. If my data <strong><em>only have Date and Sales</em></strong>. I will construct my trainX and trainY in this way (please correct me if I'm wrong):</p>

<pre><code>Window = 20
Horizon = 10

|         trainX                  |          trainY              |
| [Yt-10, Yt-11, Yt-12,...,Yt-29] | [Yt, Yt-1, Yt-2,...,Yt-9]    |
| [Yt-11, Yt-12, Yt-13,...,Yt-30] | [Yt-2, Yt-3, Yt-4,...,Yt-10] |
| [Yt-12, Yt-13, Yt-14,...,Yt-31] | [Yt-3, Yt-4, Yt-5,...,Yt-11] |
...
</code></pre>

<p>After reshaping the two</p>

<pre><code>trainX.shape
(300, 1, 20)
trainY.shape
(300, 10)
</code></pre>

<p><strong>Question1:</strong> In this case, [samples, time steps, features] = [300, 1, 20]. Is this right? Or should I construct the sample as [300, 20, 1] ?</p>

<p><strong>Question2:</strong> I do want to use other information in the raw data like Temperature, StoreType, etc. How should I construct my input data for LSTM? </p>

<p><strong>Question3:</strong> So far we only discussed 1 store forecast, if I want to forecast for all the stores, how should I construct my input data then?</p>

<p>Currently I'm flowing examples from <a href=""http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"" rel=""noreferrer"">here</a>, but it seems not sufficient to cover the scenario that I have. I really appreciate for your help!</p>
"
"""g++ not detected"" while data set goes larger, is there any limit to matrix size in GPU?","<p>I got this message in using Keras to train an RNN for language model with a big 3D tensor (generated from a text, one hot encoded, and results a shape of (165717, 25, 7631)):</p>

<pre><code>WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to 
execute optimized C-implementations (for both CPU and GPU) and will default to 
Python implementations. Performance will be severely degraded. To remove this 
warning, set Theano flags cxx to an empty string.
ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc 
installation and try again.
</code></pre>

<p>But everything goes well while I limit the size of data set into small. Thus I wonder that does Theano or CUDA limit the size of matrix? </p>

<p>Besides, do I have a better way to do one hot representation? I mean, in the large 3D tensor, most elements are 0 due to the one-hot representation. However, I didn't found a layer which accepts index representation of words.</p>
"
"keras: what is the difference between model.predict and model.predict_proba","<p>I found model.predict and model.predict_proba both give an identical 2D matrix representing probabilities at each categories for each row. </p>

<p>What is the difference of the two functions?</p>
"
"Understanding Keras LSTMs","<p>I am trying to reconcile my understand of LSTMs and pointed out here: <a href=""http://colah.github.io/posts/2015-08-Understanding-LSTMs/"" rel=""noreferrer"">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a> with the LSTM implemented in Keras. I am following the blog written <a href=""http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"" rel=""noreferrer"">http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/</a> for the Keras tutorial. What I am mainly confused about is, </p>

<ol>
<li>The reshaping of the data series into <code>[samples, time steps, features]</code> and,</li>
<li>The stateful LSTMs </li>
</ol>

<p>Lets concentrate on the above two questions with reference to the code pasted below:</p>

<pre><code># reshape into X=t and Y=t+1
look_back = 3
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)

# reshape input to be [samples, time steps, features]
trainX = numpy.reshape(trainX, (trainX.shape[0], look_back, 1))
testX = numpy.reshape(testX, (testX.shape[0], look_back, 1))
########################
# The IMPORTANT BIT
##########################
# create and fit the LSTM network
batch_size = 1
model = Sequential()
model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
for i in range(100):
    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=2, shuffle=False)
    model.reset_states()
</code></pre>

<p>Note: create_dataset takes a sequence of length N and returns a <code>N-look_back</code> array of which each element is a <code>look_back</code> length sequence.    </p>

<h1>What is Time Steps and Features?</h1>

<p>As can be seen TrainX is a 3-D array with Time_steps and Feature being the last two dimensions respectively (3 and 1 in this particular code). With respect to the image below, does this mean that we are considering the <code>many to one</code> case, where the number of pink boxes are 3? Or does it literally mean the chain length is 3 (i.e. only 3 green boxes considered). <a href=""https://i.stack.imgur.com/kwhAP.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/kwhAP.jpg"" alt=""enter image description here""></a></p>

<p>Does the features argument become relevant when we consider multivariate series? e.g. modelling two financial stocks simultaneously? </p>

<h1>Stateful LSTMs</h1>

<p>Does stateful LSTMs mean that we save the cell memory values between runs of batches? If this is the case, <code>batch_size</code> is one, and the memory is reset between the training runs so what was the point of saying that it was stateful. I'm guessing this is related to the fact that training data is not shuffled, but I'm not sure how.</p>

<p>Any thoughts?
Image reference: <a href=""http://karpathy.github.io/2015/05/21/rnn-effectiveness/"" rel=""noreferrer"">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a></p>

<h2>Edit 1:</h2>

<p>A bit confused about @van's comment about the red and green boxes being equal. So just to confirm, does the following API calls correspond to the unrolled diagrams? Especially noting the second diagram (<code>batch_size</code> was arbitrarily chosen.):
<a href=""https://i.stack.imgur.com/sW207.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/sW207.jpg"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/15V2C.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/15V2C.jpg"" alt=""enter image description here""></a></p>

<h2>Edit 2:</h2>

<p>For people who have done Udacity's deep learning course and still confused about the time_step argument, look at the following discussion: <a href=""https://discussions.udacity.com/t/rnn-lstm-use-implementation/163169"" rel=""noreferrer"">https://discussions.udacity.com/t/rnn-lstm-use-implementation/163169</a></p>

<h2>Update:</h2>

<p>It turns out <code>model.add(TimeDistributed(Dense(vocab_len)))</code> was what I was looking for. Here is an example: <a href=""https://github.com/sachinruk/ShakespeareBot"" rel=""noreferrer"">https://github.com/sachinruk/ShakespeareBot</a></p>

<h2>Update2:</h2>

<p>I have summarised most of my understanding of LSTMs here: <a href=""https://www.youtube.com/watch?v=ywinX5wgdEU"" rel=""noreferrer"">https://www.youtube.com/watch?v=ywinX5wgdEU</a></p>
"
"How to prepare a dataset for Keras?","<h2>Motivation</h2>

<p>To run a set of labeled vectors through <a href=""http://keras.io/"">Keras</a> neural network.</p>

<h2>Example</h2>

<p>Looking at Keras dataset example mnist:</p>

<pre><code>keras.datasets import mnist
(x_tr, y_tr), (x_te, y_te) = mnist.load_data()
print x_tr.shape
</code></pre>

<p>It seem to be a 3 dimensional numpy array:</p>

<pre><code>(60000, 28, 28)
</code></pre>

<ul>
<li>1st dimension is for the samples</li>
<li>2nd and 3rd for each sample features</li>
</ul>

<h2>Attempt</h2>

<p>Building the labeled vectors:</p>

<pre><code>X_train = numpy.array([[1] * 128] * (10 ** 4) + [[0] * 128] * (10 ** 4))
X_test = numpy.array([[1] * 128] * (10 ** 2) + [[0] * 128] * (10 ** 2))

Y_train = numpy.array([True] * (10 ** 4) + [False] * (10 ** 4))
Y_test = numpy.array([True] * (10 ** 2) + [False] * (10 ** 2))

X_train = X_train.astype(""float32"")
X_test = X_test.astype(""float32"")

Y_train = Y_train.astype(""bool"")
Y_test = Y_test.astype(""bool"")
</code></pre>

<h2>The training code</h2>

<pre><code>model = Sequential()
model.add(Dense(128, 50))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(50, 50))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(50, 1))
model.add(Activation('softmax'))

rms = RMSprop()
model.compile(loss='binary_crossentropy', optimizer=rms)

model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
          show_accuracy=True, verbose=2, validation_data=(X_test, Y_test))

score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)
print('Test score:', score[0])
print('Test accuracy:', score[1])
</code></pre>

<h2>Result</h2>

<pre><code>Test score: 13.9705320154
Test accuracy: 1.0
</code></pre>

<p>Why do I get such a bad result for such a simple dataset?
Is my dataset malformed?</p>

<p>Thanks!</p>
"
"Why can't my DQN agent find the optimal policy in a non-deterministic environment?","<p>edit: The following seems also to be the case for <a href=""https://gym.openai.com/envs/FrozenLake-v0/"" rel=""noreferrer""><code>FrozenLake-v0</code></a>. Please note that I'm not interested in simple Q-learning as I want to see solutions that work with continuous observation spaces.</p>

<p>I recently created the <a href=""https://github.com/MartinThoma/banana-gym"" rel=""noreferrer""><code>banana_gym</code></a> OpenAI environment. The scenario is the following:</p>

<p>You have a banana. It has to get sold within 2 days, because it will be bad on the 3rd day. You may choose the price x, but the banana will only be sold with a probability of</p>

<p><a href=""https://i.stack.imgur.com/K8RaP.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/K8RaP.png"" alt=""enter image description here""></a></p>

<p>The reward is x - 1. If the banana is not sold on the third day, the reward is -1. (Intuition: You paid 1 Euro for the banana). Hence the environment is non-deterministic (stochastic).</p>

<p><strong>Actions</strong>: You may set the price to anything in {0.00, 0.10, 0.20, ..., 2.00}</p>

<p><strong>Observations</strong>: The remaining time (<a href=""https://github.com/MartinThoma/banana-gym/blob/master/gym_banana/envs/banana_env.py#L142"" rel=""noreferrer"">source</a>)</p>

<p>I calculated the optimal policy:</p>

<pre><code>Opt at step  1: price 1.50 has value -0.26 (chance: 0.28)
Opt at step  2: price 1.10 has value -0.55 (chance: 0.41)
</code></pre>

<p>which also matches my intuition: First try to sell the banana at a higher price because you know you have another try if you don't sell it. Then reduce the price to something above 0.00.</p>

<h2>Optimal policy calculation</h2>

<p>I'm pretty sure this one is correct, but for the sake of completeness</p>

<pre><code>#!/usr/bin/env python

""""""Calculate the optimal banana pricing policy.""""""

import math
import numpy as np


def main(total_time_steps, price_not_sold, chance_to_sell):
    """"""
    Compare the optimal policy to a given policy.

    Parameters
    ----------
    total_time_steps : int
        How often the agent may offer the banana
    price_not_sold : float
        How much do we have to pay if we don't sell until
        total_time_steps is over?
    chance_to_sell : function
        A function that takes the price as an input and outputs the
        probabilty that a banana will be sold.
    """"""
    r = get_optimal_policy(total_time_steps,
                           price_not_sold,
                           chance_to_sell)
    enum_obj = enumerate(zip(r['optimal_prices'], r['values']), start=1)
    for i, (price, value) in enum_obj:
        print(""Opt at step {:&gt;2}: price {:&gt;4.2f} has value {:&gt;4.2f} ""
              ""(chance: {:&gt;4.2f})""
              .format(i, price, value, chance_to_sell(price)))


def get_optimal_policy(total_time_steps,
                       price_not_sold,
                       chance_to_sell=None):
    """"""
    Get the optimal policy for the Banana environment.

    This means for each time step, calculate what is the smartest price
    to set.

    Parameters
    ----------
    total_time_steps : int
    price_not_sold : float
    chance_to_sell : function, optional

    Returns
    -------
    results : dict
        'optimal_prices' : List of best prices to set at a given time
        'values' : values of the value function at a given step with the
                   optimal policy
    """"""
    if chance_to_sell is None:
        chance_to_sell = get_chance
    values = [None for i in range(total_time_steps + 1)]
    optimal_prices = [None for i in range(total_time_steps)]

    # punishment if a banana is not sold
    values[total_time_steps] = (price_not_sold - 1)

    for i in range(total_time_steps - 1, -1, -1):
        opt_price = None
        opt_price_value = None
        for price in np.arange(0.0, 2.01, 0.10):
            p_t = chance_to_sell(price)
            reward_sold = (price - 1)
            value = p_t * reward_sold + (1 - p_t) * values[i + 1]
            if (opt_price_value is None) or (opt_price_value &lt; value):
                opt_price_value = value
                opt_price = price
        values[i] = opt_price_value
        optimal_prices[i] = opt_price
    return {'optimal_prices': optimal_prices,
            'values': values}


def get_chance(x):
    """"""
    Get probability that a banana will be sold at a given price x.

    Parameters
    ----------
    x : float

    Returns
    -------
    chance_to_sell : float
    """"""
    return (1 + math.exp(1)) / (1. + math.exp(x + 1))


if __name__ == '__main__':
    total_time_steps = 2
    main(total_time_steps=total_time_steps,
         price_not_sold=0.0,
         chance_to_sell=get_chance)
</code></pre>

<h2>DQN + Policy Extraction</h2>

<p>The following DQN agent (implemented with <a href=""https://github.com/matthiasplappert/keras-rl"" rel=""noreferrer"">Keras-RL</a>) works for the <code>CartPole-v0</code> environment, but learns the policy</p>

<pre><code>1: Take action 19 (price= 1.90)
0: Take action 14 (price= 1.40)
</code></pre>

<p>for the Banana environment. It goes in the right direction, but it consistently learns that strategy and <strong>not the optimal strategy</strong>:</p>

<p><strong>Why does the DQN agent not learn the optimal strategy?</strong></p>

<p>Execute with:</p>

<pre><code>$ python dqn.py --env Banana-v0 --steps 50000
</code></pre>

<p>Code for <code>dqn.py</code>:</p>

<pre><code>#!/usr/bin/env python

import numpy as np
import gym
import gym_banana

from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten
from keras.optimizers import Adam

from rl.agents.dqn import DQNAgent
from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy
from rl.memory import EpisodeParameterMemory


def main(env_name, nb_steps):
    # Get the environment and extract the number of actions.
    env = gym.make(env_name)
    np.random.seed(123)
    env.seed(123)

    nb_actions = env.action_space.n
    input_shape = (1,) + env.observation_space.shape
    model = create_nn_model(input_shape, nb_actions)

    # Finally, we configure and compile our agent.
    memory = EpisodeParameterMemory(limit=2000, window_length=1)

    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1.,
                                  value_min=.1, value_test=.05,
                                  nb_steps=1000000)
    agent = DQNAgent(model=model, nb_actions=nb_actions, policy=policy,
                     memory=memory, nb_steps_warmup=50000,
                     gamma=.99, target_model_update=10000,
                     train_interval=4, delta_clip=1.)
    agent.compile(Adam(lr=.00025), metrics=['mae'])
    agent.fit(env, nb_steps=nb_steps, visualize=False, verbose=1)

    # Get the learned policy and print it
    policy = get_policy(agent, env)
    for remaining_time, action in sorted(policy.items(), reverse=True):
        print(""{:&gt;2}: Take action {:&gt;2} (price={:&gt;5.2f})""
              .format(remaining_time, action, 2 / 20. * action))


def create_nn_model(input_shape, nb_actions):
    """"""
    Create a neural network model which maps the input to actions.

    Parameters
    ----------
    input_shape : tuple of int
    nb_actoins : int

    Returns
    -------
    model : keras Model object
    """"""
    model = Sequential()
    model.add(Flatten(input_shape=input_shape))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(512, activation='relu'))
    model.add(Dense(nb_actions, activation='linear'))  # important to be linear
    print(model.summary())
    return model


def get_policy(agent, env):
    policy = {}
    for x_in in range(env.TOTAL_TIME_STEPS):
        action = agent.forward(np.array([x_in]))
        policy[x_in] = action
    return policy


def get_parser():
    """"""Get parser object for script xy.py.""""""
    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter
    parser = ArgumentParser(description=__doc__,
                            formatter_class=ArgumentDefaultsHelpFormatter)
    parser.add_argument(""--env"",
                        dest=""environment"",
                        help=""OpenAI Gym environment"",
                        metavar=""ENVIRONMENT"",
                        default=""CartPole-v0"")
    parser.add_argument(""--steps"",
                        dest=""steps"",
                        default=10000,
                        type=int,
                        help=""how steps are trained?"")
    return parser


if __name__ == ""__main__"":
    args = get_parser().parse_args()
    main(args.environment, args.steps)
</code></pre>
"
"Keras import error Nadam","<p>I am getting an import error when trying to import the Keras module Nadam:</p>

<pre><code>&gt;&gt;&gt; from keras.optimizers import Nadam
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
ImportError: cannot import name Nadam
</code></pre>

<p>I can import and use SGD, Adam, etc, just not this optimizer. Any help appreciated.</p>

<p>I installed Keras using:</p>

<pre><code>git clone https://github.com/fchollet/keras.git
sudo python2.7 setup.py install
</code></pre>

<p>I have just found that, if I try to import it using the shell immediately after installation, the Nadam import works. But Nadam won't import in my script. So it's a path issue? </p>
"
"Show progress bar for each epoch during batchwise training in Keras","<p>When I load the whole dataset in memory and train the network in Keras using following code:</p>

<pre><code>model.fit(X, y, nb_epoch=40, batch_size=32, validation_split=0.2, verbose=1)
</code></pre>

<p>This generates a progress bar per epoch with metrics like ETA, accuracy, loss, etc</p>

<p>When I train the network in batches, I'm using the following code</p>

<pre><code>for e in range(40):
        for X, y in data.next_batch():
            model.fit(X, y, nb_epoch=1, batch_size=data.batch_size, verbose=1)
</code></pre>

<p>This will generate a progress bar for each batch instead of each epoch. Is it possible to generate a progress bar for each epoch during batchwise training? </p>
"
"Keras - How are batches and epochs used in fit_generator()?","<p>I have a video of 8000 frames, and I'd like to train a Keras model on batches of 200 frames each. I have a frame generator that loops through the video frame-by-frame and accumulates the (3 x 480 x 640) frames into a numpy matrix <code>X</code> of shape <code>(200, 3, 480, 640)</code> -- (batch size, rgb, frame height, frame width) -- and yields <code>X</code> and <code>Y</code> every 200th frame:</p>

<pre><code>import cv2
...
def _frameGenerator(videoPath, dataPath, batchSize):
    """"""
    Yield X and Y data when the batch is filled.
    """"""
    camera = cv2.VideoCapture(videoPath)
    width = camera.get(3)
    height = camera.get(4)
    frameCount = int(camera.get(7))  # Number of frames in the video file.

    truthData = _prepData(dataPath, frameCount)

    X = np.zeros((batchSize, 3, height, width))
    Y = np.zeros((batchSize, 1))

    batch = 0
    for frameIdx, truth in enumerate(truthData):
        ret, frame = camera.read()
        if ret is False: continue

        batchIndex = frameIdx%batchSize

        X[batchIndex] = frame
        Y[batchIndex] = truth

        if batchIndex == 0 and frameIdx != 0:
            batch += 1
            print ""now yielding batch"", batch
            yield X, Y
</code></pre>

<p>Here's how run <a href=""https://keras.io/models/model/"" rel=""noreferrer""><code>fit_generator()</code></a>:</p>

<pre><code>        batchSize = 200
        print ""Starting training...""
        model.fit_generator(
            _frameGenerator(videoPath, dataPath, batchSize),
            samples_per_epoch=8000,
            nb_epoch=10,
            verbose=args.verbosity
        )
</code></pre>

<p>My understanding is an epoch finishes when <code>samples_per_epoch</code> samples have been seen by the model, and <code>samples_per_epoch</code> = batch size * number of batches = 200 * 40. So after training for an epoch on frames 0-7999, the next epoch will start training again from frame 0. Is this correct?</p>

<p>With this setup <strong>I expect 40 batches (of 200 frames each) to be passed from the generator to <code>fit_generator</code>, per epoch; this would be 8000 total frames per epoch</strong> -- i.e., <code>samples_per_epoch=8000</code>. Then for subsequent epochs, <code>fit_generator</code> would reinitialize the generator such that we begin training again from the start of the video. Yet this is not the case. <strong>After the first epoch is complete (after the model logs batches 0-24), the generator picks up where it left off. Shouldn't the new epoch start again from the beginning of the training dataset?</strong></p>

<p>If there is something incorrect in my understanding of <code>fit_generator</code> please explain. I've gone through the documentation, this <a href=""https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py"" rel=""noreferrer"">example</a>, and these <a href=""https://github.com/fchollet/keras/issues/1627"" rel=""noreferrer"">related</a> <a href=""https://github.com/fchollet/keras/issues/107"" rel=""noreferrer"">issues</a>. I'm using Keras v1.0.7 with the TensorFlow backend. This issue is also posted in the <a href=""https://github.com/fchollet/keras/issues/3461"" rel=""noreferrer"">Keras repo</a>.</p>
"
"Get class labels from Keras functional model","<p>I have a functional model in Keras (Resnet50 from repo examples). I trained it with <code>ImageDataGenerator</code> and <code>flow_from_directory</code> data and saved model to <code>.h5</code> file. When I call <code>model.predict</code> I get an array of class probabilities. But I want to associate them with class labels (in my case - folder names). How can I get them? I found that I could use <code>model.predict_classes</code> and <code>model.predict_proba</code>, but I don't have these functions in Functional model, only in Sequential.</p>
"
"Keras + tensorflow gives the error ""no attribute 'control_flow_ops'""","<p>I am trying to run keras for the first time.  I installed the modules with:</p>

<pre><code>pip install keras --user
pip install tensorflow --user
</code></pre>

<p>and then tried to run <a href=""https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py"">https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py</a>.</p>

<p>However it gives me:</p>

<pre><code>AttributeError: 'module' object has no attribute 'control_flow_ops'
</code></pre>

<p>These are the versions I am using.</p>

<pre><code>print tensorflow.__version__
0.11.0rc0
print keras.__version__
1.1.0
</code></pre>

<blockquote>
  <p>What can I do to get keras to run with tensorflow?</p>
</blockquote>
"
"Keras custom RMSLE metric","<p>How do I implement this metric in Keras? My code below gives the wrong result!
Note that I'm undoing a previous log(x + 1) transformation via exp(x) - 1, also negative predictions are clipped to 0:</p>

<pre><code>def rmsle_cust(y_true, y_pred):
    first_log = K.clip(K.exp(y_pred) - 1.0, 0, None)
    second_log = K.clip(K.exp(y_true) - 1.0, 0, None)
    return K.sqrt(K.mean(K.square(K.log(first_log + 1.) - K.log(second_log + 1.)), axis=-1)
</code></pre>

<p>For comparison, here's the standard numpy implementation:</p>

<pre><code>def rmsle_cust_py(y, y_pred, **kwargs):
    # undo 1 + log
    y = np.exp(y) - 1
    y_pred = np.exp(y_pred) - 1

    y_pred[y_pred &lt; 0] = 0.0
    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]
    return (sum(to_sum) * (1.0/len(y))) ** 0.5
</code></pre>

<p>What I'm doing wrong? Thanks!</p>

<p>EDIT: Setting <code>axis=0</code> seems to give a value very close to the correct one, but I'm not sure since all the code I've seem uses <code>axis=-1</code>.</p>
"
"How to Implement the Conv1DTranspose in keras?","<p>I Know there is the Conv2DTranspose in keras which can be used in Image. We need to use it in NLP, so the 1D deconvolution is needed. </p>

<p>How do we implement the Conv1DTranspose in keras?</p>
"
"What is the difference between Keras and tf.contrib.keras in TensorFlow 1.1+?","<p>Now that TensorFlow 1.1 supports the Keras API under <code>tf.contrib.keras</code>, which one should I use if I intend to use Keras with a TF backend?</p>

<p>Is the <code>tf.contrib.keras</code> version different in any way than a regular Keras distribution? (TF specific optimizations of internal data structures come to mind). Is there any benefit in terms of using Keras and TensorFlow Core together if I use one or the other?</p>

<p>Or is <code>tf.contrib.keras</code> simply a copy of the same codebase as Keras but under a different namespace?</p>
"
"Keras Early Stopping","<p>I'm training neural network for my project using Keras. Keras has provided a function for early stopping. May I know what parameters should be observed to avoid my neural network from overfitting by using early stopping?</p>
"
"Keras loading color images","<p>I have 3 folders with color images. Name of the folder is label for the images inside.</p>

<pre><code>cls1
  |____img_0.png
  |____ ...
  |____img_n.png
cls2
  |____img_0.png
  |____ ...
  |____img_n.png   
cls3
  |____img_0.png
  |____ ...
  |____img_n.png
</code></pre>

<p>I would like to use Keras library to create Convolutional neural network for classification, but I can't find, how to create dataset from color images.
Can you help me?</p>
"
"Load saved checkpoint and predict not producing same results as in training","<p>I'm training based on a sample code I found on the Internet. The accuracy in testing is at 92% and the checkpoints are saved in a directory. In parallel (the training is running for 3 days now) I want to create my prediction code so I can learn more instead of just waiting.</p>

<p>This is my third day of deep learning so I probably don't know what I'm doing. Here's how I'm trying to predict:</p>

<ul>
<li>Instantiate the model using the same code as in training</li>
<li>Load the last checkpoint</li>
<li>Try to predict</li>
</ul>

<p>The code works but the results are nowhere near 90%.</p>

<p>Here's how I create the model:</p>

<pre><code>INPUT_LAYERS = 2
OUTPUT_LAYERS = 2
AMOUNT_OF_DROPOUT = 0.3
HIDDEN_SIZE = 700
INITIALIZATION = ""he_normal""  # : Gaussian initialization scaled by fan_in (He et al., 2014)
CHARS = list(""abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ ."")

def generate_model(output_len, chars=None):
    """"""Generate the model""""""
    print('Build model...')
    chars = chars or CHARS
    model = Sequential()
    # ""Encode"" the input sequence using an RNN, producing an output of HIDDEN_SIZE
    # note: in a situation where your input sequences have a variable length,
    # use input_shape=(None, nb_feature).
    for layer_number in range(INPUT_LAYERS):
        model.add(recurrent.LSTM(HIDDEN_SIZE, input_shape=(None, len(chars)), init=INITIALIZATION,
                         return_sequences=layer_number + 1 &lt; INPUT_LAYERS))
        model.add(Dropout(AMOUNT_OF_DROPOUT))
    # For the decoder's input, we repeat the encoded input for each time step
    model.add(RepeatVector(output_len))
    # The decoder RNN could be multiple layers stacked or a single layer
    for _ in range(OUTPUT_LAYERS):
        model.add(recurrent.LSTM(HIDDEN_SIZE, return_sequences=True, init=INITIALIZATION))
        model.add(Dropout(AMOUNT_OF_DROPOUT))

    # For each of step of the output sequence, decide which character should be chosen
    model.add(TimeDistributed(Dense(len(chars), init=INITIALIZATION)))
    model.add(Activation('softmax'))

    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model
</code></pre>

<p>In a separate file <code>predict.py</code> I import this method to create my model and try to predict:</p>

<pre><code>...import code
model = generate_model(len(question), dataset['chars'])
model.load_weights('models/weights.204-0.20.hdf5')

def decode(pred):
    return character_table.decode(pred, calc_argmax=False)


x = np.zeros((1, len(question), len(dataset['chars'])))
for t, char in enumerate(question):
    x[0, t, character_table.char_indices[char]] = 1.

preds = model.predict_classes([x], verbose=0)[0]

print(""======================================"")
print(decode(preds))
</code></pre>

<p>I don't know what the problem is. I have about 90 checkpoints in my directory and I'm loading the last one based on accuracy. All of them saved by a <code>ModelCheckpoint</code>:</p>

<pre><code>checkpoint = ModelCheckpoint(MODEL_CHECKPOINT_DIRECTORYNAME + '/' + MODEL_CHECKPOINT_FILENAME,
                         save_best_only=True)
</code></pre>

<p>I'm stuck. What am I doing wrong?</p>
"
"Data Augmentation Image Data Generator Keras Semantic Segmentation","<p>I'm fitting full convolutional network on some image data for semantic segmentation using Keras.  However, I'm having some problems overfitting. I don't have that much data and I want to do data augmentation.  However, as I want to do pixel-wise classification, I need any augmentations like flips, rotations, and shifts to apply to both feature images and the label images. Ideally I'd like to use the Keras ImageDataGenerator for on-the-fly transformations. However, as far as I can tell, you cannot do equivalent transformations on both the feature and label data.</p>

<p>Does anyone know if this is the case and if not, does anyone have any ideas? Otherwise, I'll use other tools to create a larger dataset and just feed it in all at once.</p>

<p>Thanks!</p>
"
"How do I create a variable-length input LSTM in Keras?","<p>I am trying to do some vanilla pattern recognition with an LSTM using Keras to predict the next element in a sequence.</p>

<p>My data look like this:</p>

<p><a href=""https://i.stack.imgur.com/NnEvI.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/NnEvI.png"" alt=""My data""></a></p>

<p>where the label of the training sequence is the last element in the list: <code>X_train['Sequence'][n][-1]</code>.</p>

<p>Because my <code>Sequence</code> column can have a variable number of elements in the sequence, I believe an RNN to be the best model to use. Below is my attempt to build an LSTM in Keras:</p>

<pre><code># Build the model

# A few arbitrary constants...
max_features = 20000
out_size = 128

# The max length should be the length of the longest sequence (minus one to account for the label)
max_length = X_train['Sequence'].apply(len).max() - 1

# Normal LSTM model construction with sigmoid activation
model = Sequential()
model.add(Embedding(max_features, out_size, input_length=max_length, dropout=0.2))
model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2))
model.add(Dense(1))
model.add(Activation('sigmoid'))

# try using different optimizers and different optimizer configs
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>

<p>And here's how I attempt to train my model:</p>

<pre><code># Train the model
for seq in X_train['Sequence']:
    print(""Length of training is {0}"".format(len(seq[:-1])))
    print(""Training set is {0}"".format(seq[:-1]))
    model.fit(np.array([seq[:-1]]), [seq[-1]])
</code></pre>

<p>My output is this:</p>

<pre><code>Length of training is 13
Training set is [1, 3, 13, 87, 1053, 28576, 2141733, 508147108, 402135275365, 1073376057490373, 9700385489355970183, 298434346895322960005291, 31479360095907908092817694945]
</code></pre>

<p>However, I get the following error:</p>

<pre><code>Exception: Error when checking model input: expected embedding_input_1 to have shape (None, 347) but got array with shape (1, 13)
</code></pre>

<p>I believe my training step is correctly setup, so my model construction must be wrong. Note that 347 is <code>max_length</code>.</p>

<p>How can I correctly build a variable-length input LSTM in Keras? I'd prefer not to pad the data. Not sure if it's relevant, but I'm using the Theano backend.</p>
"
"What is an Embedding in Keras?","<p>Keras documentation isn't clear what this actually is. I understand we can use this to compress the input feature space into a smaller one. But how is this done from a neural design perspective? Is it an autoenocder, RBM?</p>
"
"How to log Keras loss output to a file","<p>When you run a Keras neural network model you might see something like this in the console: </p>

<pre><code>Epoch 1/3
   6/1000 [..............................] - ETA: 7994s - loss: 5111.7661
</code></pre>

<p>As time goes on the loss hopefully improves. I want to log these losses to a file over time so that I can learn from them. I have tried: </p>

<pre><code>logging.basicConfig(filename='example.log', filemode='w', level=logging.DEBUG)
</code></pre>

<p>but this doesn't work. I am not sure what level of logging I need in this situation. </p>

<p>I have also tried using a callback like in: </p>

<pre><code>def generate_train_batch():
    while 1:
        for i in xrange(0,dset_X.shape[0],3):
            yield dset_X[i:i+3,:,:,:],dset_y[i:i+3,:,:]

class LossHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_batch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))
logloss=LossHistory()
colorize.fit_generator(generate_train_batch(),samples_per_epoch=1000,nb_epoch=3,callbacks=['logloss'])
</code></pre>

<p>but obviously this isn't writing to a file. Whatever the method, through a callback or the logging module or anything else, I would love to hear your solutions for logging loss of a keras neural network to a file. Thanks! </p>
"
"Policy Gradients in Keras","<p>I've been trying to build a model using 'Deep Q-Learning' where I have a large number of actions (2908). After some limited success with using standard DQN:
(<a href=""https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"">https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf</a>), I decided to do some more research because I figured the action space was too large to do effective exploration. </p>

<p>I then discovered this paper: <a href=""https://arxiv.org/pdf/1512.07679.pdf"">https://arxiv.org/pdf/1512.07679.pdf</a> where they use an actor-critic model and policy gradients, which then led me to: <a href=""https://arxiv.org/pdf/1602.01783.pdf"">https://arxiv.org/pdf/1602.01783.pdf</a> where they use policy gradients to get much better results then DQN overall.</p>

<p>I've found a few sites where they have implemented policy gradients in Keras, <a href=""https://yanpanlau.github.io/2016/10/11/Torcs-Keras.html"">https://yanpanlau.github.io/2016/10/11/Torcs-Keras.html</a> and <a href=""https://oshearesearch.com/index.php/2016/06/14/kerlym-a-deep-reinforcement-learning-toolbox-in-keras/"">https://oshearesearch.com/index.php/2016/06/14/kerlym-a-deep-reinforcement-learning-toolbox-in-keras/</a> however I'm confused how they are implemented. In the former (and when I read the papers) it seems like instead of providing an input and output pair for the actor network, you provide the gradients for the all the weights and then use the network to update it, whereas, in the latter they just calculate an input-output pair.</p>

<p>Have I just confused myself? Am I just supposed to be training the network by providing an input-output pair and use the standard 'fit', or do I have to do something special? If it's the latter, how do I do it with the Theano backend? (the examples above use tensorflow).</p>

<p>Any help would be great!</p>
"
"Keras Classification - Object Detection","<p>I am working on a classification then object detection with Keras and Python. I have classified cats/dogs with 80%+ accuracy, Im ok with the current result for now. My question is how do I detect cat or dog from an input image? I'm completely confused. I want to use my own heights and not pretrained ones from internet.</p>

<p>Here is my code currently:</p>

<pre><code>from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Convolution2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
import numpy as np
import matplotlib.pyplot as plt
import matplotlib

from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

#########################################################################################################
#VALUES
# dimensions of our images.
img_width, img_height = 150, 150

train_data_dir = 'data/train'
validation_data_dir = 'data/validation'
nb_train_samples = 2000 #1000 cats/dogs
nb_validation_samples = 800 #400cats/dogs
nb_epoch = 50
#########################################################################################################

#MODEL
model = Sequential()
model.add(Convolution2D(32, 3, 3, input_shape=(3, img_width, img_height)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Convolution2D(32, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Convolution2D(64, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])


# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)
##########################################################################################################
#TEST AUGMENTATION
img = load_img('data/train/cats/cat.0.jpg')  # this is a PIL image
x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)
x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)

# the .flow() command below generates batches of randomly transformed images
# and saves the results to the `preview/` directory
i = 0
for batch in train_datagen.flow(x, batch_size=1,
                          save_to_dir='data/TEST AUGMENTATION', save_prefix='cat', save_format='jpeg'):
    i += 1
    if i &gt; 20:
        break  # otherwise the generator would loop indefinitely
##########################################################################################################
# this is the augmentation configuration we will use for testing:
# only rescaling
test_datagen = ImageDataGenerator(rescale=1./255)

#PREPARE TRAINING DATA
train_generator = train_datagen.flow_from_directory(
        train_data_dir, #data/train
        target_size=(img_width, img_height),  #RESIZE to 150/150
        batch_size=32,
        class_mode='binary')  #since we are using binarycrosentropy need binary labels

#PREPARE VALIDATION DATA
validation_generator = test_datagen.flow_from_directory(
        validation_data_dir,  #data/validation
        target_size=(img_width, img_height), #RESIZE 150/150
        batch_size=32,
        class_mode='binary')


#START model.fit
history =model.fit_generator(
        train_generator, #train data
        samples_per_epoch=nb_train_samples,
        nb_epoch=nb_epoch,
        validation_data=validation_generator,  #validation data
        nb_val_samples=nb_validation_samples)


model.save_weights('savedweights.h5')
# list all data in history
print(history.history.keys())

#ACC VS VAL_ACC
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy ACC VS VAL_ACC')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
#LOSS VS VAL_LOSS
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss LOSS vs VAL_LOSS')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()


model.load_weights('first_try.h5')
</code></pre>

<p>So now since i classified cat and dog, how and what do I need to do to input an image and go through it to find cat or a dog in it with a bounding box? I'm completely new to this nd not even sure if I'm tackling this in a correct way?
Thank you.</p>

<p><strong>UPDATE</strong>
Hi, Sorry to post results so late, was unable to work on this for few days.
I am importing an image and reshaping it to 1,3,150,150 shape as 150,150 shape brings error:</p>

<pre><code>Exception: Error when checking : expected convolution2d_input_1 to have 4 dimensions, but got array with shape (150L, 150L)
</code></pre>

<p>Importing image:</p>

<pre><code>#load test image
img=load_img('data/prediction/cat.155.jpg')
#reshape to 1,3,150,150
img = np.arange(1* 150 * 150).reshape((1,3,150, 150))
#check shape
print(img.shape)
</code></pre>

<p>Then I have changed def predict_function(x) to:</p>

<pre><code>def predict_function(x):
    # example of prediction function for simplicity, you
    # should probably use `return model.predict(x)`
   # random.seed(x[0][0])
  #  return random.random()
   return model.predict(img)
</code></pre>

<p>Now when I run:</p>

<pre><code>best_box = get_best_bounding_box(img, predict_function)
print('best bounding box %r' % (best_box, ))
</code></pre>

<p>I get output as best bounding box: None</p>

<p>So I ran just:</p>

<pre><code>model.predict(img)
</code></pre>

<p>And get the following out:</p>

<pre><code>model.predict(img)
Out[54]: array([[ 0.]], dtype=float32)
</code></pre>

<p>So it is not checking at all if its a cat or a dog... Any ideas? </p>

<p>NOTE: when def predict)function(x) is using:</p>

<pre><code>random.seed(x[0][0])
   return random.random()
</code></pre>

<p>I do get the output as , it check boxes and gives the best one.</p>
"
"How to use models from keras.applications for transfer learnig?","<p>I want to get pretrained VGG16 model in Keras, remove its output layer, and then put a new output layer with the number of classes suited for my problem, and then to fit it on new data. For this reason, I am trying to use the model here: <a href=""https://keras.io/applications/#vgg16"" rel=""noreferrer"">https://keras.io/applications/#vgg16</a>, but since it is not Sequential, I cannot just <code>model.pop()</code>. Popping from layers and adding it also does not work, because in the predictions it still expects the old shape. How would I do that? Is there a way to convert this type of model to <code>Sequential</code>?</p>
"
"Error when checking model input: expected convolution2d_input_1 to have 4 dimensions, but got array with shape (32, 32, 3)","<p>I want to train a deep network starting with the following layer:</p>

<pre><code>model = Sequential()
model.add(Conv2D(32, 3, 3, input_shape=(32, 32, 3)))
</code></pre>

<p>using </p>

<pre><code>history = model.fit_generator(get_training_data(),
                samples_per_epoch=1, nb_epoch=1,nb_val_samples=5,
                verbose=1,validation_data=get_validation_data()
</code></pre>

<p>with the following generator:</p>

<pre><code>def get_training_data(self):
     while 1:
        for i in range(1,5):
            image = self.X_train[i]
            label = self.Y_train[i]
            yield (image,label)
</code></pre>

<p>(validation generator looks similar).</p>

<p>During training, I get the error: </p>

<pre><code>Error when checking model input: expected convolution2d_input_1 to have 4 
dimensions, but got array with shape (32, 32, 3)
</code></pre>

<p>How can that be, with a first layer</p>

<pre><code> model.add(Conv2D(32, 3, 3, input_shape=(32, 32, 3)))
</code></pre>

<p>?</p>
"
"Keras, How to get the output of each layer?","<p>I have trained a binary classification model with CNN, and here is my code</p>

<pre><code>model = Sequential()
model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],
                        border_mode='valid',
                        input_shape=input_shape))
model.add(Activation('relu'))
model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=pool_size))
# (16, 16, 32)
model.add(Convolution2D(nb_filters*2, kernel_size[0], kernel_size[1]))
model.add(Activation('relu'))
model.add(Convolution2D(nb_filters*2, kernel_size[0], kernel_size[1]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=pool_size))
# (8, 8, 64) = (2048)
model.add(Flatten())
model.add(Dense(1024))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(2))  # define a binary classification problem
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='adadelta',
              metrics=['accuracy'])
model.fit(x_train, y_train,
          batch_size=batch_size,
          nb_epoch=nb_epoch,
          verbose=1,
          validation_data=(x_test, y_test))
</code></pre>

<p>And here, I wanna get the output of each layer just like TensorFlow, how can I do that?</p>
"
"How to use return_sequences option and TimeDistributed layer in Keras?","<p>I have a dialog corpus like below. And I want to implement a LSTM model which predicts a system action. The system actions described as a bit vector. And user inputs are calculated as a word-embedding which is also a bit vector.</p>

<pre><code>t1: user: ""Do you know an apple?"", system: ""no""(action=2)
t2: user: ""xxxxxx"", system: ""yyyy"" (action=0)
t3: user: ""aaaaaa"", system: ""bbbb"" (action=5)
</code></pre>

<p>So what I want to realize is ""many to many (2)"" model. When my model receives a user input, it must output a system action.
<a href=""https://i.stack.imgur.com/13opm.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/13opm.jpg"" alt=""enter image description here""></a>
But I cannot understand return_sequences option and TimeDistributed layer after LSTM. To realize ""many-to-many (2)"", return_sequences==True and adding TimeDistributed after LSTM are required? I appreciate if you would give more description of them.</p>

<blockquote>
  <p><strong>return_sequences</strong>: Boolean. Whether to return the last output in the output sequence, or the full sequence.</p>
  
  <p><strong>TimeDistributed</strong>: This wrapper allows to apply a layer to every temporal slice of an input.</p>
</blockquote>

<h3>Updated 2017/03/13 17:40</h3>

<p>I think I could understand return_sequence option. But I am not still sure about TimeDistributed. If I add a TimeDistributed after LSTM, is the model same as ""my many-to-many(2)"" below? So I think Dense layers are applied for each output.
<a href=""https://i.stack.imgur.com/DiPyQ.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/DiPyQ.jpg"" alt=""enter image description here""></a></p>
"
"Many to one and many to many LSTM examples in Keras","<p>I try to understand LSTMs and how to build them with Keras. I found out, that there are principally the 4 modes to run a RNN (the 4 right ones in the picture)</p>

<p><a href=""https://i.stack.imgur.com/b4sus.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/b4sus.jpg"" alt=""enter image description here""></a></p>

<p>Now I wonder how a minimalistic code snippet for each of them would look like in Keras.
So something like</p>

<pre><code>model = Sequential()
model.add(LSTM(128, input_shape=(timesteps, data_dim)))
model.add(Dense(1))
</code></pre>

<p>for each of the 4 tasks, maybe with a little bit of explanation.</p>
"
"Negative dimension size caused by subtracting 3 from 1 for 'Conv2D'","<p>I'm using <a href=""https://keras.io/"" rel=""noreferrer"">Keras</a> with <a href=""https://www.tensorflow.org/"" rel=""noreferrer"">Tensorflow</a> as backend , here is my code:</p>

<pre><code>import numpy as np
np.random.seed(1373) 
import tensorflow as tf
tf.python.control_flow_ops = tf

import os
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.utils import np_utils

batch_size = 128
nb_classes = 10
nb_epoch = 12


img_rows, img_cols = 28, 28

nb_filters = 32

nb_pool = 2

nb_conv = 3


(X_train, y_train), (X_test, y_test) = mnist.load_data()

print(X_train.shape[0])

X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)


X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255


print('X_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')
print(X_test.shape[0], 'test samples')


Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)

model = Sequential()

model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
border_mode='valid',
input_shape=(1, img_rows, img_cols)))
model.add(Activation('relu'))
model.add(Convolution2D(nb_filters, nb_conv, nb_conv))
model.add(Activation('relu'))

model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(nb_classes)) 
model.add(Activation('softmax')) 

model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=[""accuracy""])


model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
verbose=1, validation_data=(X_test, Y_test))

score = model.evaluate(X_test, Y_test, verbose=0)

print('Test score:', score[0])
print('Test accuracy:', score[1])
</code></pre>

<p>and Trackback error:</p>

<pre><code>Using TensorFlow backend.
60000
('X_train shape:', (60000, 1, 28, 28))
(60000, 'train samples')
(10000, 'test samples')
Traceback (most recent call last):
  File ""mnist.py"", line 154, in &lt;module&gt;
    input_shape=(1, img_rows, img_cols)))
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 276, in add
    layer.create_input_layer(batch_input_shape, input_dtype)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 370, in create_input_layer
    self(x)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 514, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 572, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 149, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/convolutional.py"", line 466, in call
    filter_shape=self.W_shape)
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py"", line 1579, in conv2d
    x = tf.nn.conv2d(x, kernel, strides, padding=padding)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 396, in conv2d
    data_format=data_format, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2242, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1617, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1568, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 675, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Negative dimension size caused by subtracting 3 from 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,1,28,28], [3,3,28,32].
</code></pre>

<p>First I saw some answers that problem is with <code>Tensorflow</code> version so I upgrade <code>Tensorflow</code> to <code>0.12.0</code>, but still exist , is that problem with network or I missing something, what should <code>input_shape</code> looks like?</p>

<p><strong>Update</strong>
Here is <code>./keras/keras.json</code>:</p>

<pre><code>{
    ""image_dim_ordering"": ""tf"", 
    ""epsilon"": 1e-07, 
    ""floatx"": ""float32"", 
    ""backend"": ""tensorflow""
}
</code></pre>
"
"How to tell which Keras model is better?","<p>I don't understand which accuracy in the output to use to compare my 2 Keras models to see which one is better. </p>

<p>Do I use the ""acc"" (from the training data?) one or the ""val acc"" (from the validation data?) one?</p>

<p>There are different accs and val accs for each epoch. How do I know the acc or val acc for my model as a whole? Do I average all of the epochs accs or val accs to find the acc or val acc of the model as a whole?</p>

<p><strong>Model 1 Output</strong></p>

<pre><code>Train on 970 samples, validate on 243 samples
Epoch 1/20
0s - loss: 0.1708 - acc: 0.7990 - val_loss: 0.2143 - val_acc: 0.7325
Epoch 2/20
0s - loss: 0.1633 - acc: 0.8021 - val_loss: 0.2295 - val_acc: 0.7325
Epoch 3/20
0s - loss: 0.1657 - acc: 0.7938 - val_loss: 0.2243 - val_acc: 0.7737
Epoch 4/20
0s - loss: 0.1847 - acc: 0.7969 - val_loss: 0.2253 - val_acc: 0.7490
Epoch 5/20
0s - loss: 0.1771 - acc: 0.8062 - val_loss: 0.2402 - val_acc: 0.7407
Epoch 6/20
0s - loss: 0.1789 - acc: 0.8021 - val_loss: 0.2431 - val_acc: 0.7407
Epoch 7/20
0s - loss: 0.1789 - acc: 0.8031 - val_loss: 0.2227 - val_acc: 0.7778
Epoch 8/20
0s - loss: 0.1810 - acc: 0.8010 - val_loss: 0.2438 - val_acc: 0.7449
Epoch 9/20
0s - loss: 0.1711 - acc: 0.8134 - val_loss: 0.2365 - val_acc: 0.7490
Epoch 10/20
0s - loss: 0.1852 - acc: 0.7959 - val_loss: 0.2423 - val_acc: 0.7449
Epoch 11/20
0s - loss: 0.1889 - acc: 0.7866 - val_loss: 0.2523 - val_acc: 0.7366
Epoch 12/20
0s - loss: 0.1838 - acc: 0.8021 - val_loss: 0.2563 - val_acc: 0.7407
Epoch 13/20
0s - loss: 0.1835 - acc: 0.8041 - val_loss: 0.2560 - val_acc: 0.7325
Epoch 14/20
0s - loss: 0.1868 - acc: 0.8031 - val_loss: 0.2573 - val_acc: 0.7407
Epoch 15/20
0s - loss: 0.1829 - acc: 0.8072 - val_loss: 0.2581 - val_acc: 0.7407
Epoch 16/20
0s - loss: 0.1878 - acc: 0.8062 - val_loss: 0.2589 - val_acc: 0.7407
Epoch 17/20
0s - loss: 0.1833 - acc: 0.8072 - val_loss: 0.2613 - val_acc: 0.7366
Epoch 18/20
0s - loss: 0.1837 - acc: 0.8113 - val_loss: 0.2605 - val_acc: 0.7325
Epoch 19/20
0s - loss: 0.1906 - acc: 0.8010 - val_loss: 0.2555 - val_acc: 0.7407
Epoch 20/20
0s - loss: 0.1884 - acc: 0.8062 - val_loss: 0.2542 - val_acc: 0.7449
</code></pre>

<p><strong>Model 2 Output</strong></p>

<pre><code>Train on 970 samples, validate on 243 samples
Epoch 1/20
0s - loss: 0.1735 - acc: 0.7876 - val_loss: 0.2386 - val_acc: 0.6667
Epoch 2/20
0s - loss: 0.1733 - acc: 0.7825 - val_loss: 0.1894 - val_acc: 0.7449
Epoch 3/20
0s - loss: 0.1781 - acc: 0.7856 - val_loss: 0.2028 - val_acc: 0.7407
Epoch 4/20
0s - loss: 0.1717 - acc: 0.8021 - val_loss: 0.2545 - val_acc: 0.7119
Epoch 5/20
0s - loss: 0.1757 - acc: 0.8052 - val_loss: 0.2252 - val_acc: 0.7202
Epoch 6/20
0s - loss: 0.1776 - acc: 0.8093 - val_loss: 0.2449 - val_acc: 0.7490
Epoch 7/20
0s - loss: 0.1833 - acc: 0.7897 - val_loss: 0.2272 - val_acc: 0.7572
Epoch 8/20
0s - loss: 0.1827 - acc: 0.7928 - val_loss: 0.2376 - val_acc: 0.7531
Epoch 9/20
0s - loss: 0.1795 - acc: 0.8062 - val_loss: 0.2445 - val_acc: 0.7490
Epoch 10/20
0s - loss: 0.1746 - acc: 0.8103 - val_loss: 0.2491 - val_acc: 0.7449
Epoch 11/20
0s - loss: 0.1831 - acc: 0.8082 - val_loss: 0.2477 - val_acc: 0.7449
Epoch 12/20
0s - loss: 0.1831 - acc: 0.8113 - val_loss: 0.2496 - val_acc: 0.7490
Epoch 13/20
0s - loss: 0.1920 - acc: 0.8000 - val_loss: 0.2459 - val_acc: 0.7449
Epoch 14/20
0s - loss: 0.1945 - acc: 0.7928 - val_loss: 0.2446 - val_acc: 0.7490
Epoch 15/20
0s - loss: 0.1852 - acc: 0.7990 - val_loss: 0.2459 - val_acc: 0.7449
Epoch 16/20
0s - loss: 0.1800 - acc: 0.8062 - val_loss: 0.2495 - val_acc: 0.7449
Epoch 17/20
0s - loss: 0.1891 - acc: 0.8000 - val_loss: 0.2469 - val_acc: 0.7449
Epoch 18/20
0s - loss: 0.1891 - acc: 0.8041 - val_loss: 0.2467 - val_acc: 0.7531
Epoch 19/20
0s - loss: 0.1853 - acc: 0.8072 - val_loss: 0.2511 - val_acc: 0.7449
Epoch 20/20
0s - loss: 0.1905 - acc: 0.8062 - val_loss: 0.2460 - val_acc: 0.7531
</code></pre>
"
"Keras + Tensorflow: Prediction on multiple gpus","<p>I'm using Keras with tensorflow as backend.
I have one compiled/trained model.</p>

<p>My prediction loop is slow so I would like to find a way to parallelize the <code>predict_proba</code> calls to speed things up.
I would like to take a list of batches (of data) and then per available gpu, run <code>model.predict_proba()</code> over a subset of those batches.<br>
Essentially:</p>

<pre><code>data = [ batch_0, batch_1, ... , batch_N ]
on gpu_0 =&gt; return predict_proba(batch_0)
on gpu_1 =&gt; return predict_proba(batch_1)
...
on gpu_N =&gt; return predict_proba(batch_N) 
</code></pre>

<p>I know that it's possible in pure Tensorflow to assign ops to a given gpu (<a href=""https://www.tensorflow.org/tutorials/using_gpu"" rel=""noreferrer"">https://www.tensorflow.org/tutorials/using_gpu</a>).  However, I don't know how this translates to my situation since I've built/compiled/trained my model using Keras' api.</p>

<p>I had thought that maybe I just needed to use python's multiprocessing module and start a process per gpu that would run <code>predict_proba(batch_n)</code>.  I know this is theoretically possible given another SO post of mine: <a href=""https://stackoverflow.com/questions/42504669/keras-tensorflow-and-multiprocessing-in-python"">Keras + Tensorflow and Multiprocessing in Python</a>.  However, this still leaves me with the dilemma of not knowing how to actually ""choose"" a gpu to operate the process on.</p>

<p>My question boils down to: how does one parallelize prediction for one model in Keras across multiple gpus when using Tensorflow as Keras' backend?</p>

<p>Additionally I am curious if similar parallelization for prediction is possible with only one gpu.   </p>

<p>A high level description or code example would be greatly appreciated!</p>

<p>Thanks!</p>
"
"Where do I call the BatchNormalization function in Keras?","<p>If I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?</p>

<p>I read this documentation for it: <a href=""http://keras.io/layers/normalization/"">http://keras.io/layers/normalization/</a></p>

<p>I don't see where I'm supposed to call it. Below is my code attempting to use it:</p>

<pre><code>model = Sequential()
keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)
model.add(Dense(64, input_dim=14, init='uniform'))
model.add(Activation('tanh'))
model.add(Dropout(0.5))
model.add(Dense(64, init='uniform'))
model.add(Activation('tanh'))
model.add(Dropout(0.5))
model.add(Dense(2, init='uniform'))
model.add(Activation('softmax'))

sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='binary_crossentropy', optimizer=sgd)
model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)
</code></pre>

<p>I ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.</p>
"
"How to use advanced activation layers in Keras?","<p>This is my code that works if I use other activation layers like tanh:</p>

<pre><code>model = Sequential()
act = keras.layers.advanced_activations.PReLU(init='zero', weights=None)
model.add(Dense(64, input_dim=14, init='uniform'))
model.add(Activation(act))
model.add(Dropout(0.15))
model.add(Dense(64, init='uniform'))
model.add(Activation('softplus'))
model.add(Dropout(0.15))
model.add(Dense(2, init='uniform'))
model.add(Activation('softmax'))

sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='binary_crossentropy', optimizer=sgd)
model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)
</code></pre>

<p>In this case, it doesn't work and says ""TypeError: 'PReLU' object is not callable"" and the error is called at the model.compile line. Why is this the case? All the non-advanced activation functions works. However, neither of the advanced activation functions, including this one, works.</p>
"
"How do you make TensorFlow + Keras fast with a TFRecord dataset?","<p><strong>What is an example of how to use a TensorFlow TFRecord with a Keras Model and tf.session.run() while keeping the dataset in tensors w/ queue runners?</strong></p>

<p>Below is a snippet that works but it needs the following improvements:</p>

<ul>
<li>Use the <a href=""https://keras.io/models/model/"" rel=""noreferrer"">Model API</a></li>
<li>specify an Input()</li>
<li>Load a dataset from a TFRecord</li>
<li>Run through a dataset in parallel (such as with a queuerunner)</li>
</ul>

<p>Here is the snippet, there are several TODO lines indicating what is needed:</p>

<pre><code>from keras.models import Model
import tensorflow as tf
from keras import backend as K
from keras.layers import Dense, Input
from keras.objectives import categorical_crossentropy
from tensorflow.examples.tutorials.mnist import input_data

sess = tf.Session()
K.set_session(sess)

# Can this be done more efficiently than placeholders w/ TFRecords?
img = tf.placeholder(tf.float32, shape=(None, 784))
labels = tf.placeholder(tf.float32, shape=(None, 10))

# TODO: Use Input() 
x = Dense(128, activation='relu')(img)
x = Dense(128, activation='relu')(x)
preds = Dense(10, activation='softmax')(x)
# TODO: Construct model = Model(input=inputs, output=preds)

loss = tf.reduce_mean(categorical_crossentropy(labels, preds))

# TODO: handle TFRecord data, is it the same?
mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)

train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)

sess.run(tf.global_variables_initializer())

# TODO remove default, add queuerunner
with sess.as_default():
    for i in range(1000):
        batch = mnist_data.train.next_batch(50)
        train_step.run(feed_dict={img: batch[0],
                                  labels: batch[1]})
    print(loss.eval(feed_dict={img: mnist_data.test.images, labels: mnist_data.test.labels}))
</code></pre>

<p><strong>Why is this question relevant?</strong></p>

<ul>
<li>For high performance training without going back to python

<ul>
<li>no <a href=""https://stackoverflow.com/questions/36026892/how-can-i-convert-tfrecords-into-numpy-arrays"">TFRecord to numpy</a> to tensor conversions</li>
</ul></li>
<li><a href=""https://github.com/fchollet/keras/issues/5358"" rel=""noreferrer"">Keras will soon be part of tensorflow</a></li>
<li>Demonstrate how Keras Model() classes can accept tensors for input data correctly.</li>
</ul>

<p><strong>Here is some starter information for a semantic segmentation problem example:</strong></p>

<ul>
<li>example unet Keras model <a href=""https://github.com/ahundt/tf-image-segmentation/blob/cd7df53e6f59ef9e3dff1ed0119e12922ae98a3a/tf_image_segmentation/models/unet.py"" rel=""noreferrer"">unet.py</a>, happens to be for semantic segmentation.</li>
<li><a href=""https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html"" rel=""noreferrer"">Keras + Tensorflow Blog Post</a></li>
<li>An <a href=""https://github.com/ahundt/tf-image-segmentation/blob/cd7df53e6f59ef9e3dff1ed0119e12922ae98a3a/tf_image_segmentation/recipes/pascal_voc/FCNs/densenet_fcn.py#L78"" rel=""noreferrer"">attempt at running the unet model a tf session with TFRecords and a Keras model</a> (not working)</li>
<li>Code to create the TFRecords: <a href=""https://github.com/ahundt/tf-image-segmentation/blob/cd7df53e6f59ef9e3dff1ed0119e12922ae98a3a/tf_image_segmentation/utils/tf_records.py"" rel=""noreferrer"">tf_records.py</a></li>
<li>An attempt at running the unet model a tf session with TFRecords and a Keras model is in <a href=""https://github.com/ahundt/tf-image-segmentation/blob/cd7df53e6f59ef9e3dff1ed0119e12922ae98a3a/tf_image_segmentation/recipes/pascal_voc/FCNs/densenet_fcn.py#L78"" rel=""noreferrer"">densenet_fcn.py</a> (not working)</li>
</ul>
"
"Loading a trained Keras model and continue training","<p>I was wondering if it was possible to save a partly trained Keras model and continue the training after loading the model again.</p>

<p>The reason for this is that I will have more training data in the future and I do not want to retrain the whole model again.</p>

<p>The functions which I am using are:</p>

<pre><code>#Partly train model
model.fit(first_training, first_classes, batch_size=32, nb_epoch=20)

#Save partly trained model
model.save('partly_trained.h5')

#Load partly trained model
from keras.models import load_model
model = load_model('partly_trained.h5')

#Continue training
model.fit(second_training, second_classes, batch_size=32, nb_epoch=20)
</code></pre>

<hr>

<p><strong>Edit 1: added fully working example</strong></p>

<p>With the first dataset after 10 epochs the loss of the last epoch will be 0.0748 and the accuracy 0.9863.</p>

<p>After saving, deleting and reloading the model the loss and accuracy of the model trained on the second dataset will be 0.1711 and 0.9504 respectively.</p>

<p>Is this caused by the new training data or by a completely re-trained model?</p>

<pre><code>""""""
Model by: http://machinelearningmastery.com/
""""""
# load (downloaded if needed) the MNIST dataset
import numpy
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils
from keras.models import load_model
numpy.random.seed(7)

def baseline_model():
    model = Sequential()
    model.add(Dense(num_pixels, input_dim=num_pixels, init='normal', activation='relu'))
    model.add(Dense(num_classes, init='normal', activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

if __name__ == '__main__':
    # load data
    (X_train, y_train), (X_test, y_test) = mnist.load_data()

    # flatten 28*28 images to a 784 vector for each image
    num_pixels = X_train.shape[1] * X_train.shape[2]
    X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')
    X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')
    # normalize inputs from 0-255 to 0-1
    X_train = X_train / 255
    X_test = X_test / 255
    # one hot encode outputs
    y_train = np_utils.to_categorical(y_train)
    y_test = np_utils.to_categorical(y_test)
    num_classes = y_test.shape[1]

    # build the model
    model = baseline_model()

    #Partly train model
    dataset1_x = X_train[:3000]
    dataset1_y = y_train[:3000]
    model.fit(dataset1_x, dataset1_y, nb_epoch=10, batch_size=200, verbose=2)

    # Final evaluation of the model
    scores = model.evaluate(X_test, y_test, verbose=0)
    print(""Baseline Error: %.2f%%"" % (100-scores[1]*100))

    #Save partly trained model
    model.save('partly_trained.h5')
    del model

    #Reload model
    model = load_model('partly_trained.h5')

    #Continue training
    dataset2_x = X_train[3000:]
    dataset2_y = y_train[3000:]
    model.fit(dataset2_x, dataset2_y, nb_epoch=10, batch_size=200, verbose=2)
    scores = model.evaluate(X_test, y_test, verbose=0)
    print(""Baseline Error: %.2f%%"" % (100-scores[1]*100))
</code></pre>
"
"Restore original text from Kerass imdb dataset","<p>Restore original text from Kerass imdb dataset</p>

<p>I want to restore imdbs original text from Kerass imdb dataset.</p>

<p>First, when I load Kerass imdb dataset, it returned sequence of word index.</p>

<p>

<pre><code>&gt;&gt;&gt; (X_train, y_train), (X_test, y_test) = imdb.load_data()
&gt;&gt;&gt; X_train[0]
[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]
</code></pre>

<p>I found imdb.get_word_index method(), it returns word index dictionary like {create: 984, make: 94,}. For converting, I create index word dictionary.


<pre><code>&gt;&gt;&gt; word_index = imdb.get_word_index()
&gt;&gt;&gt; index_word = {v:k for k,v in word_index.items()}
</code></pre>

<p>Then, I tried to restore original text like following.</p>

<p>

<pre><code>&gt;&gt;&gt; ' '.join(index_word.get(w) for w in X_train[5])
""the effort still been that usually makes for of finished sucking ended cbc's an because before if just though something know novel female i i slowly lot of above freshened with connect in of script their that out end his deceptively i i""
</code></pre>

<p>Im not good at English, but I know this sentence is something strange.</p>

<p>Why is this happened? How can I restore original text?</p>
"
"How do I install Keras and Theano in Anaconda Python on Windows?","<p>I am trying to work on neural networks in Python using the following Keras packages:</p>

<pre><code>from keras.utils import np_utils
from keras.layers.core import Dense, Activation, Dropout
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.optimizers import SGD
</code></pre>

<p>But, I am getting the following error:</p>

<pre><code> 15 import theano
 ---&gt; 16 from theano import gof
 17 from theano.compat.python2x import partial
 18 import theano.compile.mode
 ImportError: cannot import name gof
</code></pre>

<p>Installing installed <code>conda install keras</code>. Later I tried to use <code>pip install Theano</code>, but it did not work. I Tried to install using <code>pip install git</code>, but I am getting this error: <code>cannot find command git.</code> So I installed Git and I set the environment variables.</p>

<p>So, is there any procedure to install these packages?</p>
"
"How to concatenate two layers in keras?","<p>I have an example of a neural network with two layers. The first layer takes two arguments and has one output. The second should take one argument as result of the first layer and one additional argument. It should looks like this:</p>

<pre><code>x1  x2  x3
 \  /   /
  y1   /
   \  /
    y2
</code></pre>

<p>So, I'd created a model with two layers and tried to merge them but it returns an error: <code>The first layer in a Sequential model must get an ""input_shape"" or ""batch_input_shape"" argument.</code> on the line <code>result.add(merged)</code>.</p>

<p>Model:</p>

<pre class=""lang-python prettyprint-override""><code>first = Sequential()
first.add(Dense(1, input_shape=(2,), activation='sigmoid'))

second = Sequential()
second.add(Dense(1, input_shape=(1,), activation='sigmoid'))

result = Sequential()
merged = Concatenate([first, second])
ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)
result.add(merged)
result.compile(optimizer=ada_grad, loss=_loss_tensor, metrics=['accuracy'])
</code></pre>
"
"Keras binary_crossentropy vs categorical_crossentropy performance?","<p>I'm trying to train a CNN to categorize text by topic. When I use binary_crossentropy I get ~80% acc, with categorical_crossentrop I get ~50% acc.</p>

<p>I don't understand why this is. It's a multiclass problem, does that mean I have to use categorical and the binary results are meaningless?</p>



<pre class=""lang-python prettyprint-override""><code>model.add(embedding_layer)
model.add(Dropout(0.25))
# convolution layers
model.add(Conv1D(nb_filter=32,
                    filter_length=4,
                    border_mode='valid',
                    activation='relu'))
model.add(MaxPooling1D(pool_length=2))
# dense layers
model.add(Flatten())
model.add(Dense(256))
model.add(Dropout(0.25))
model.add(Activation('relu'))
# output layer
model.add(Dense(len(class_id_index)))
model.add(Activation('softmax'))
</code></pre>

<p>then </p>

<pre class=""lang-python prettyprint-override""><code>model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>

<p>or </p>

<pre class=""lang-python prettyprint-override""><code>model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>
"
"Keras Masking for RNN with Varying Time Steps","<p>I'm trying to fit an RNN in Keras using sequences that have varying time lengths. My data is in a Numpy array with format <code>(sample, time, feature) = (20631, max_time, 24)</code> where <code>max_time</code> is determined at run-time as the number of time steps available for the sample with the most time stamps. I've padded the beginning of each time series with <code>0</code>, except for the longest one, obviously.</p>

<p>I've initially defined my model like so...</p>

<pre><code>model = Sequential()
model.add(Masking(mask_value=0., input_shape=(max_time, 24)))
model.add(LSTM(100, input_dim=24))
model.add(Dense(2))
model.add(Activation(activate))
model.compile(loss=weibull_loglik_discrete, optimizer=RMSprop(lr=.01))
model.fit(train_x, train_y, nb_epoch=100, batch_size=1000, verbose=2, validation_data=(test_x, test_y))
</code></pre>

<p>For completeness, here's the code for the loss function:</p>

<pre><code>def weibull_loglik_discrete(y_true, ab_pred, name=None):
    y_ = y_true[:, 0]
    u_ = y_true[:, 1]
    a_ = ab_pred[:, 0]
    b_ = ab_pred[:, 1]

    hazard0 = k.pow((y_ + 1e-35) / a_, b_)
    hazard1 = k.pow((y_ + 1) / a_, b_)

    return -1 * k.mean(u_ * k.log(k.exp(hazard1 - hazard0) - 1.0) - hazard1)
</code></pre>

<p>And here's the code for the custom activation function:</p>

<pre><code>def activate(ab):
    a = k.exp(ab[:, 0])
    b = k.softplus(ab[:, 1])

    a = k.reshape(a, (k.shape(a)[0], 1))
    b = k.reshape(b, (k.shape(b)[0], 1))

    return k.concatenate((a, b), axis=1)
</code></pre>

<p>When I fit the model and make some test predictions, <em>every sample in the test set gets exactly the same prediction</em>, which seems fishy.</p>

<p>Things get better if I remove the masking layer, which makes me think there's something wrong with the masking layer, but as far as I can tell, I've followed the documentation exactly.</p>

<p>Is there something mis-specified with the masking layer? Am I missing something else?</p>
"
"How to load a model from an HDF5 file in Keras?","<p>How to load a model from an HDF5 file in Keras?</p>

<p>What I tried:</p>

<pre><code>model = Sequential()

model.add(Dense(64, input_dim=14, init='uniform'))
model.add(LeakyReLU(alpha=0.3))
model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))
model.add(Dropout(0.5))

model.add(Dense(64, init='uniform'))
model.add(LeakyReLU(alpha=0.3))
model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))
model.add(Dropout(0.5))

model.add(Dense(2, init='uniform'))
model.add(Activation('softmax'))


sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='binary_crossentropy', optimizer=sgd)

checkpointer = ModelCheckpoint(filepath=""/weights.hdf5"", verbose=1, save_best_only=True)
model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2, callbacks=[checkpointer])
</code></pre>

<p>The above code successfully saves the best model to a file named weights.hdf5. What I want to do is then load that model. The below code shows how I tried to do so:</p>

<pre><code>model2 = Sequential()
model2.load_weights(""/Users/Desktop/SquareSpace/weights.hdf5"")
</code></pre>

<p>This is the error I get:</p>

<pre><code>IndexError                                Traceback (most recent call last)
&lt;ipython-input-101-ec968f9e95c5&gt; in &lt;module&gt;()
      1 model2 = Sequential()
----&gt; 2 model2.load_weights(""/Users/Desktop/SquareSpace/weights.hdf5"")

/Applications/anaconda/lib/python2.7/site-packages/keras/models.pyc in load_weights(self, filepath)
    582             g = f['layer_{}'.format(k)]
    583             weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]
--&gt; 584             self.layers[k].set_weights(weights)
    585         f.close()
    586 

IndexError: list index out of range
</code></pre>
"
"How to manually specify class labels in keras flow_from_directory?","<p><strong>Problem:</strong> I am training a model for multilabel image recognition. My images are therefore associated with multiple y labels. This is conflicting with the convenient keras method ""flow_from_directory"" of the ImageDataGenerator, where each image is supposed to be in the folder of the corresponding label (<a href=""https://keras.io/preprocessing/image/"" rel=""noreferrer"">https://keras.io/preprocessing/image/</a>).</p>

<p><strong>Workaround:</strong> Currently, I am reading all images into a numpy array and use the ""flow"" function from there. But this results in heavy memory loads and a slow read-in process. </p>

<p><strong>Question:</strong> Is there a way to use the ""flow_from_directory"" method and to supply manually the (multiple) class labels?</p>

<hr>

<p><strong>Update</strong>: I ended up extending the DirectoryIterator class for the multilabel case. You can now set the attribute ""class_mode"" to the value ""multilabel"" and provide a dictionary ""multlabel_classes"" which maps filenames to their labels. Code: <a href=""https://github.com/tholor/keras/commit/29ceafca3c4792cb480829c5768510e4bdb489c5"" rel=""noreferrer"">https://github.com/tholor/keras/commit/29ceafca3c4792cb480829c5768510e4bdb489c5</a></p>
"
"How do I use the Tensorboard callback of Keras?","<p>I have built a neural network with Keras. I would visualize its data by Tensorboard, therefore I have utilized:</p>

<pre><code>keras.callbacks.TensorBoard(log_dir='/Graph', histogram_freq=0,
                            write_graph=True, write_images=True)
</code></pre>

<p>as explained in <a href=""https://keras.io/callbacks/#tensorboard"" rel=""noreferrer"">keras.io</a>. When I run the callback I get <code>&lt;keras.callbacks.TensorBoard at 0x7f9abb3898&gt;</code>, but I don't get any file in my folder ""Graph"". There is something wrong in how I have used this callback?</p>
"
"What does the standard Keras model output mean? What is epoch and loss in Keras?","<p>I have just built my first model using Keras and this is the output. It looks like the standard output you get after building any Keras artificial neural network. Even after looking in the documentation, I do not fully understand what the epoch is and what the loss is which is printed in the output.</p>

<p><strong>What is epoch and loss in Keras?</strong> </p>

<p>(I know it's probably an extremely basic question, but I couldn't seem to locate the answer online, and if the answer is really that hard to glean from the documentation I thought others would have the same question and thus decided to post it here.)</p>

<pre><code>Epoch 1/20
1213/1213 [==============================] - 0s - loss: 0.1760     
Epoch 2/20
1213/1213 [==============================] - 0s - loss: 0.1840     
Epoch 3/20
1213/1213 [==============================] - 0s - loss: 0.1816     
Epoch 4/20
1213/1213 [==============================] - 0s - loss: 0.1915     
Epoch 5/20
1213/1213 [==============================] - 0s - loss: 0.1928     
Epoch 6/20
1213/1213 [==============================] - 0s - loss: 0.1964     
Epoch 7/20
1213/1213 [==============================] - 0s - loss: 0.1948     
Epoch 8/20
1213/1213 [==============================] - 0s - loss: 0.1971     
Epoch 9/20
1213/1213 [==============================] - 0s - loss: 0.1899     
Epoch 10/20
1213/1213 [==============================] - 0s - loss: 0.1957     
Epoch 11/20
1213/1213 [==============================] - 0s - loss: 0.1923     
Epoch 12/20
1213/1213 [==============================] - 0s - loss: 0.1910     
Epoch 13/20
1213/1213 [==============================] - 0s - loss: 0.2104     
Epoch 14/20
1213/1213 [==============================] - 0s - loss: 0.1976     
Epoch 15/20
1213/1213 [==============================] - 0s - loss: 0.1979     
Epoch 16/20
1213/1213 [==============================] - 0s - loss: 0.2036     
Epoch 17/20
1213/1213 [==============================] - 0s - loss: 0.2019     
Epoch 18/20
1213/1213 [==============================] - 0s - loss: 0.1978     
Epoch 19/20
1213/1213 [==============================] - 0s - loss: 0.1954     
Epoch 20/20
1213/1213 [==============================] - 0s - loss: 0.1949
</code></pre>
"
"Why do I get a Keras LSTM RNN input_shape error?","<p>I keep getting an input_shape error from the following code.</p>

<pre><code>from keras.models import Sequential
from keras.layers.core import Dense, Activation, Dropout
from keras.layers.recurrent import LSTM

def _load_data(data):
    """"""
    data should be pd.DataFrame()
    """"""
    n_prev = 10
    docX, docY = [], []
    for i in range(len(data)-n_prev):
        docX.append(data.iloc[i:i+n_prev].as_matrix())
        docY.append(data.iloc[i+n_prev].as_matrix())
    if not docX:
        pass
    else:
        alsX = np.array(docX)
        alsY = np.array(docY)
        return alsX, alsY

X, y = _load_data(dframe)
poi = int(len(X) * .8)
X_train = X[:poi]
X_test = X[poi:]
y_train = y[:poi]
y_test = y[poi:]

input_dim = 3
</code></pre>

<p>All of the above runs smoothly. This is where it goes wrong.</p>

<pre><code>in_out_neurons = 2
hidden_neurons = 300
model = Sequential()
#model.add(Masking(mask_value=0, input_shape=(input_dim,)))
model.add(LSTM(in_out_neurons, hidden_neurons, return_sequences=False, input_shape=(len(full_data),)))
model.add(Dense(hidden_neurons, in_out_neurons))
model.add(Activation(""linear""))
model.compile(loss=""mean_squared_error"", optimizer=""rmsprop"")
model.fit(X_train, y_train, nb_epoch=10, validation_split=0.05)
</code></pre>

<p>It returns this error.</p>

<pre><code>Exception: Invalid input shape - Layer expects input ndim=3, was provided with input shape (None, 10320)
</code></pre>

<p>When I check <a href=""http://keras.io/layers/core/"" rel=""noreferrer"">the website</a> it says to specify a tuple ""(e.g. (100,) for 100-dimensional inputs).""</p>

<p>That being said, my data set consists of one column with a length of 10320. I assume that that means that I should be putting <code>(10320,)</code> in as the input_shape, but I get the error anyways. Does anyone have a solution?</p>
"
"Mnist recognition using keras","<p>How can I train the model to recognize five numbers in one picture.
The code is as follows:</p>

<pre><code>from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dropout, Dense, Input
from keras.models import Model, Sequential

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
             activation='relu',
             input_shape=(28, 140, 1)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dropout(0.5))
</code></pre>

<p>Here should be a loop for recognizing each number in the picture, but I don't know how to realize it.</p>

<pre><code>model.add(Dense(11, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
          optimizer=keras.optimizers.Adadelta(),
          metrics=['accuracy'])

model.fit(X_train, y_train,
      batch_size=1000,
      epochs=8,
      verbose=1,
      validation_data=(X_valid, y_valid))
</code></pre>

<p>The picture of combined mnist number is as follows:</p>

<p><img src=""https://i.stack.imgur.com/uOFFU.png"" alt=""combined numbers in one picture""></p>
"
"Role of ""Flatten"" in Keras","<p>I am trying to understand the role of the <code>Flatten</code> function in Keras. Below is my code, which is a simple two-layer network. It takes in 2-dimensional data of shape (3, 2), and outputs 1-dimensional data of shape (1, 4):</p>

<pre><code>model = Sequential()
model.add(Dense(16, input_shape=(3, 2)))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(4))
model.compile(loss='mean_squared_error', optimizer='SGD')

x = np.array([[[1, 2], [3, 4], [5, 6]]])

y = model.predict(x)

print y.shape
</code></pre>

<p>This prints out that <code>y</code> has shape (1, 4). However, if I remove the <code>Flatten</code> line, then it prints out that <code>y</code> has shape (1, 3, 4).</p>

<p>I don't understand this. From my understanding of neural networks, the <code>model.add(Dense(16, input_shape=(3, 2)))</code> function is creating a hidden fully-connected layer, with 16 nodes. Each of these nodes is connected to each of the 3x2 input elements. Therefore, the 16 nodes at the output of this first layer are already ""flat"". So, the output shape of the first layer should be (1, 16). Then, the second layer takes this as an input, and outputs data of shape (1, 4).</p>

<p>So if the output of the first layer is already ""flat"" and of shape (1, 16), why do I need to further flatten it?</p>

<p>Thanks!</p>
"
"Keras Conv2D and input channels","<p>The Keras layer documentation specifies the input and output sizes for convolutional layers:
<a href=""https://keras.io/layers/convolutional/"" rel=""noreferrer"">https://keras.io/layers/convolutional/</a></p>

<p>Input shape: <code>(samples, channels, rows, cols)</code></p>

<p>Output shape: <code>(samples, filters, new_rows, new_cols)</code></p>

<p>And the kernel size is a spatial parameter, i.e. detemines only width and height.</p>

<p>So an input with <code>c</code> channels will yield an output with <code>filters</code> channels regardless of the value of <code>c</code>. It must therefore apply 2D convolution with a spatial <code>height x width</code> filter and then aggregate the results somehow for each learned filter. </p>

<p>What is this aggregation operator? is it a summation across channels? can I control it? I couldn't find any information on the Keras documentation.</p>

<ul>
<li>Note that in TensorFlow the filters are specified in the depth channel as well:
<a href=""https://www.tensorflow.org/api_guides/python/nn#Convolution"" rel=""noreferrer"">https://www.tensorflow.org/api_guides/python/nn#Convolution</a>,
So the depth operation is clear.</li>
</ul>

<p>Thanks.</p>
"
"How does Keras handle multilabel classification?","<p>I am unsure how to interpret the default behavior of Keras in the following situation:</p>

<p>My Y (ground truth) was set up using scikit-learn's <code>MultilabelBinarizer</code>().</p>

<p>Therefore, to give a random example, one row of my <code>y</code> column is one-hot encoded as such:
<code>[0,0,0,1,0,1,0,0,0,0,1]</code>.</p>

<p>So I have 11 classes that could be predicted, and more than one can be true; hence the multilabel nature of the problem.  There are three labels for this particular sample.</p>

<p>I train the model as I would for a non multilabel problem (business as usual) and I get no errors.</p>

<pre><code>from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD

model = Sequential()
model.add(Dense(5000, activation='relu', input_dim=X_train.shape[1]))
model.add(Dropout(0.1))
model.add(Dense(600, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(y_train.shape[1], activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy',
              optimizer=sgd,
              metrics=['accuracy',])

model.fit(X_train, y_train,epochs=5,batch_size=2000)

score = model.evaluate(X_test, y_test, batch_size=2000)
score
</code></pre>

<p>What does Keras do when it encounters my <code>y_train</code> and sees that it is ""multi"" one-hot encoded, meaning there is more than one 'one' present in each row of <code>y_train</code>?  Basically, does Keras automatically perform multilabel classification?  Any differences in the interpretation of the scoring metrics?</p>
"
"Multi dimensional input for LSTM in Keras","<p>I would like to understand how an RNN, specifically an LSTM is working with multiple input dimensions using Keras and Tensorflow. I mean the input shape is (batch_size, timesteps, input_dim) where input_dim > 1.<br>
I think the below images illustrate quite well the concept of LSTM if the input_dim = 1.<br>
Does this mean if input_dim > 1 then x is not a single value anymore but an array? But if it's like this then the weights are also become arrays, same shape as x + the context?</p>

<p><a href=""https://i.stack.imgur.com/YW2bI.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/YW2bI.png"" alt=""LSTM structure""></a></p>

<p><a href=""https://i.stack.imgur.com/2x8NZ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/2x8NZ.png"" alt=""enter image description here""></a></p>
"
"How can I use the Keras OCR example?","<p>I found <a href=""https://github.com/fchollet/keras/blob/master/examples/image_ocr.py"" rel=""noreferrer""><code>examples/image_ocr.py</code></a> which seems to for OCR. Hence it should be possible to give the model an image and receive text. However, I have no idea how to do so. How do I feed the model with a new image? Which kind of preprocessing is necessary? </p>

<h2>What I did</h2>

<p>Installing the depencencies:</p>

<ul>
<li>Install <a href=""https://pypi.python.org/pypi/cairocffi"" rel=""noreferrer""><code>cairocffi</code></a>: <code>sudo apt-get install python-cairocffi</code></li>
<li>Install <code>editdistance</code>: <code>sudo -H pip install editdistance</code></li>
<li>Change <code>train</code> to return the model and save the trained model.</li>
<li>Run the script to train the model.</li>
</ul>

<p>Now I have a <code>model.h5</code>. What's next?</p>

<p>See <a href=""https://github.com/MartinThoma/algorithms/tree/master/ML/ocr/keras"" rel=""noreferrer"">https://github.com/MartinThoma/algorithms/tree/master/ML/ocr/keras</a> for my current code. I know how to load the model (see below) and this seems to work. The problem is that I don't know how to feed new scans of images with text to the model.</p>

<h2>Related side questions</h2>

<ul>
<li>What is CTC? <a href=""http://www.cs.toronto.edu/~graves/icml_2006.pdf"" rel=""noreferrer"">Connectionist Temporal Classification</a>?</li>
<li>Are there algorithms which reliably detect the rotation of a document?</li>
<li>Are there algorithms which reliably detect lines / text blocks / tables / images (hence make a reasonable segmentation)? I guess edge detection with smoothing and line-wise histograms already works reasonably well for that?</li>
</ul>

<h2>What I tried</h2>

<pre><code>#!/usr/bin/env python

from keras import backend as K
import keras
from keras.models import load_model
import os

from image_ocr import ctc_lambda_func, create_model, TextImageGenerator
from keras.layers import Lambda
from keras.utils.data_utils import get_file
import scipy.ndimage
import numpy

img_h = 64
img_w = 512
pool_size = 2
words_per_epoch = 16000
val_split = 0.2
val_words = int(words_per_epoch * (val_split))
if K.image_data_format() == 'channels_first':
    input_shape = (1, img_w, img_h)
else:
    input_shape = (img_w, img_h, 1)

fdir = os.path.dirname(get_file('wordlists.tgz',
                                origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))

img_gen = TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),
                             bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),
                             minibatch_size=32,
                             img_w=img_w,
                             img_h=img_h,
                             downsample_factor=(pool_size ** 2),
                             val_split=words_per_epoch - val_words
                             )
print(""Input shape: {}"".format(input_shape))
model, _, _ = create_model(input_shape, img_gen, pool_size, img_w, img_h)

model.load_weights(""my_model.h5"")

x = scipy.ndimage.imread('example.png', mode='L').transpose()
x = x.reshape(x.shape + (1,))

# Does not work
print(model.predict(x))
</code></pre>

<p>this gives</p>

<pre><code>2017-07-05 22:07:58.695665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN Black, pci bus id: 0000:01:00.0)
Traceback (most recent call last):
  File ""eval_example.py"", line 45, in &lt;module&gt;
    print(model.predict(x))
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1567, in predict
    check_batch_axis=False)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 106, in _standardize_input_data
    'Found: array with shape ' + str(data.shape))
ValueError: The model expects 4 arrays, but only received one array. Found: array with shape (512, 64, 1)
</code></pre>
"
"How to find Number of parameters of a keras model?","<p>For a Feedforward Network (FFN), it is easy to compute the number of parameters. Given a CNN, LSTM etc is there a quick way to find the number of parameters in a keras model?</p>
"
"AttributeError: 'module' object has no attribute 'computation'","<p>Im trying to use Keras (Sequential) but I get the following error when I try to import it:</p>

<pre><code>File ""kaggle_titanic_keras.py"", line 3, in &lt;module&gt;
    from keras.models import Sequential
  File ""/anaconda/lib/python2.7/site-packages/keras/__init__.py"", line 4, in &lt;module&gt;
    from . import applications
  File ""/anaconda/lib/python2.7/site-packages/keras/applications/__init__.py"", line 1, in &lt;module&gt;
    from .vgg16 import VGG16
  File ""/anaconda/lib/python2.7/site-packages/keras/applications/vgg16.py"", line 14, in &lt;module&gt;
    from ..models import Model
  File ""/anaconda/lib/python2.7/site-packages/keras/models.py"", line 14, in &lt;module&gt;
    from . import layers as layer_module
  File ""/anaconda/lib/python2.7/site-packages/keras/layers/__init__.py"", line 4, in &lt;module&gt;
    from ..engine import Layer
  File ""/anaconda/lib/python2.7/site-packages/keras/engine/__init__.py"", line 8, in &lt;module&gt;
    from .training import Model
  File ""/anaconda/lib/python2.7/site-packages/keras/engine/training.py"", line 24, in &lt;module&gt;
    from .. import callbacks as cbks
  File ""/anaconda/lib/python2.7/site-packages/keras/callbacks.py"", line 25, in &lt;module&gt;
    from tensorflow.contrib.tensorboard.plugins import projector
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/__init__.py"", line 30, in &lt;module&gt;
    from tensorflow.contrib import factorization
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/factorization/__init__.py"", line 24, in &lt;module&gt;
    from tensorflow.contrib.factorization.python.ops.gmm import *
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/factorization/python/ops/gmm.py"", line 27, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.estimators import estimator
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/__init__.py"", line 87, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn import *
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/__init__.py"", line 23, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn import *
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/__init__.py"", line 25, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn import estimators
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py"", line 297, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py"", line 29, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 31, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.estimators import estimator
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 49, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py"", line 21, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py"", line 26, in &lt;module&gt;
    import dask.dataframe as dd
  File ""/anaconda/lib/python2.7/site-packages/dask/dataframe/__init__.py"", line 3, in &lt;module&gt;
    from .core import (DataFrame, Series, Index, _Frame, map_partitions,
  File ""/anaconda/lib/python2.7/site-packages/dask/dataframe/core.py"", line 38, in &lt;module&gt;
    pd.computation.expressions.set_use_numexpr(False)
AttributeError: 'module' object has no attribute 'computation'
</code></pre>

<p>Im running Python 2.7, TensorFlow 1.1 , Keras 2.0.3 and 'upgraded' to Pandas 0.20.1 yesterday which I suspect is causing the problem but the error message says nothing about it.</p>
"
"How to calculate prediction uncertainty using Keras?","<p>I would like to calculate NN model certainty / confidence (see <a href=""http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html"" rel=""noreferrer"">What my deep model doesn't know</a>) - when NN tells me an image represents ""8"", I would like to know how certain it is. Is my model 99% certain it is ""8"" or is it 51% it is ""8"", but it could also be ""6""? Some digits are quite ambigious and I would like to know for which images the model is just ""flipping a coin"".</p>

<p>I have found some theoretical writings about this but I have trouble putting this in code. If I understand correctly, I should evaluate a testing image multiple times while ""killing off"" different neurons (using dropout) and then...?</p>

<p>Working on MNIST dataset, I am running a following model:</p>

<pre><code>from keras.models import Sequential
from keras.layers import Dense, Activation, Conv2D, Flatten, Dropout

model = Sequential()
model.add(Conv2D(128, kernel_size=(7, 7),
                 activation='relu',
                 input_shape=(28, 28, 1,)))
model.add(Dropout(0.20))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Dropout(0.20))
model.add(Flatten())
model.add(Dense(units=64, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(units=10, activation='softmax'))
model.summary()
model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])
model.fit(train_data, train_labels,  batch_size=100, epochs=30, validation_data=(test_data, test_labels,))
</code></pre>

<p>Question: how should I predict with this model so that I get its certainty about predictions too? I would appreciate some practical example (preferably in Keras, but any will do).</p>

<p><strong>EDIT</strong>: to clarify, I am looking for example how to get certainty using the method outlined by Yurin Gal (or an explanation why some other method yields better results). </p>
"
"Keras IndexError: indices are out-of-bounds","<p>I'm new to Keras and im trying to do Binary MLP on a dataset, and keep getting indices out of bounds with no idea why.</p>

<pre><code>from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.optimizers import SGD

model = Sequential()
model.add(Dense(64, input_dim=20, init='uniform', activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
          optimizer='rmsprop')
model.fit(trainx, trainy, nb_epoch=20, batch_size=16) # THROWS INDICES ERROR
</code></pre>

<p>Error:</p>

<pre><code>model.fit(trainx, trainy, nb_epoch=20, batch_size=16)

Epoch 1/20
Traceback (most recent call last):

  File ""&lt;ipython-input-6-c81bd7606eb0&gt;"", line 1, in &lt;module&gt;
model.fit(trainx, trainy, nb_epoch=20, batch_size=16)

  File ""C:\Users\Thiru\Anaconda3\lib\site-packages\keras\models.py"", line 646, in fit
shuffle=shuffle, metrics=metrics)

  File ""C:\Users\Thiru\Anaconda3\lib\site-packages\keras\models.py"", line 271, in _fit
ins_batch = slice_X(ins, batch_ids)

  File ""C:\Users\Thiru\Anaconda3\lib\site-packages\keras\models.py"", line 65, in slice_X
return [x[start] for x in X]

  File ""C:\Users\Thiru\Anaconda3\lib\site-packages\keras\models.py"", line 65, in &lt;listcomp&gt;
return [x[start] for x in X]

  File ""C:\Users\Thiru\Anaconda3\lib\site-packages\pandas\core\frame.py"", line 1963, in __getitem__
return self._getitem_array(key)

  File ""C:\Users\Thiru\Anaconda3\lib\site-packages\pandas\core\frame.py"", line 2008, in _getitem_array
return self.take(indexer, axis=1, convert=True)

  File ""C:\Users\Thiru\Anaconda3\lib\site-packages\pandas\core\generic.py"", line 1371, in take
convert=True, verify=True)

  File ""C:\Users\Thiru\Anaconda3\lib\site-packages\pandas\core\internals.py"", line 3619, in take
indexer = maybe_convert_indices(indexer, n)

  File ""C:\Users\Thiru\Anaconda3\lib\site-packages\pandas\core\indexing.py"", line 1750, in maybe_convert_indices
raise IndexError(""indices are out-of-bounds"")

IndexError: indices are out-of-bounds
</code></pre>

<p>Does anyone have any idea why this is happening? Im able to run other models just fine</p>
"
"Convert Keras model to TensorFlow protobuf","<p>We're currently training various neural networks using Keras, which is ideal because it has a nice interface and is relatively easy to use, but we'd like to be able to apply them in our production environment. </p>

<p>Unfortunately the production environment is C++, so our plan is to:</p>

<ul>
<li>Use the TensorFlow backend to save the model to a protobuf</li>
<li>Link our production code to TensorFlow, and then load in the protobuf</li>
</ul>

<p>Unfortunately I don't know how to access the TensorFlow saving utilities from Keras, which normally saves to HDF5 and JSON. How do I save to protobuf?</p>
"
"Character-Word Embeddings from lm_1b in Keras","<p>I would like to use some pre-trained word embeddings in a Keras NN model, which have been published by Google in a <a href=""https://arxiv.org/pdf/1602.02410.pdf"" rel=""noreferrer"">very well known article</a>.   They have provided the code to train a new model, as well as the embeddings <a href=""https://github.com/tensorflow/models/tree/master/lm_1b"" rel=""noreferrer"">here</a>.</p>

<p>However, it is not clear from the documentation how to retrieve an embedding vector from a given string of characters (word) from a simple python function call.  Much of the documentation seems to center on dumping vectors to a <em>file</em> for an entire sentence presumably for sentimental analysis.  </p>

<p>So far, I have seen that you can feed in pretrained embeddings with the following syntax:</p>

<pre><code>embedding_layer = Embedding(number_of_words??,
                            out_dim=128??,
                            weights=[pre_trained_matrix_here],
                            input_length=60??,
                            trainable=False)
</code></pre>

<p>However, converting the different files and their structures to <code>pre_trained_matrix_here</code> is not quite clear to me.</p>

<p>They have several softmax outputs, so I am uncertain which one would belong - and furthermore how to align the words in my input to the dictionary of words for which they have.</p>

<p>Is there a simple manner to use these word/char embeddings in keras and/or to construct the character/word embedding portion of the model in keras such that further layers may be added for other NLP tasks?</p>
"
"Keras: Difference between Kernel and Activity regularizers","<p>I have noticed that <em>weight_regularizer</em> is no more available in Keras and that, in its place, there are <em>activity</em> and <em>kernel</em> regularizer. 
I would like to know:</p>

<ul>
<li>What are the main differences between <em>kernel</em> and <em>activity</em> regularizers?</li>
<li>Could I use <em>activity_regularizer</em> in place of <em>weight_regularizer</em>?</li>
</ul>
"
"Make predictions using a tensorflow graph from a keras model","<p>I have a model trained using Keras with Tensorflow as my backend, but now I need to turn my model into a tensorflow graph for a certain application. I attempted to do this and make predictions to insure that it is working correctly, but when comparing to the results gathered from model.predict() I get very different values. For instance:</p>

<pre><code>from keras.models import load_model
import tensorflow as tf

model = load_model('model_file.h5')

x_placeholder = tf.placeholder(tf.float32, shape=(None,7214,1))
y = model(x_placeholder)

x = np.ones((1,7214,1))


with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(""Predictions from:\ntf graph:      ""+str(sess.run(y, feed_dict={x_placeholder:x})))
    print(""keras predict: ""+str(model.predict(x)))
</code></pre>

<p>returns:</p>

<pre><code>Predictions from:
tf graph:      [[-0.1015993   0.07432419  0.0592984 ]]
keras predict: [[ 0.39339241  0.57949686 -3.67846966]]
</code></pre>

<p>The values from keras predict are correct, but the tf graph results are not.</p>

<p>If it helps to know the final intended application, I am creating a jacobian matrix with the tf.gradients() function, but currently it does not return the correct results when comparing to theano's jacobian function, which gives the correct jacobian. Here is my tensorflow jacobian code:</p>

<pre><code>x = tf.placeholder(tf.float32, shape=(None,7214,1))
y = tf.reshape(model(x)[0],[-1])
y_list = tf.unstack(y)

jacobian_list = [tf.gradients(y_, x)[0] for y_ in y_list]
jacobian = tf.stack(jacobian_list)
</code></pre>

<p>EDIT: Model code</p>

<pre><code>import numpy as np

from keras.models import Sequential
from keras.layers import Dense, InputLayer, Flatten
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping, ReduceLROnPlateau

# activation function used following every layer except for the output layers
activation = 'relu'

# model weight initializer
initializer = 'he_normal'

# shape of input data that is fed into the input layer
input_shape = (None,7214,1)

# number of filters used in the convolutional layers
num_filters = [4,16]

# length of the filters in the convolutional layers
filter_length = 8

# length of the maxpooling window 
pool_length = 4

# number of nodes in each of the hidden fully connected layers
num_hidden_nodes = [256,128]

# number of samples fed into model at once during training
batch_size = 64

# maximum number of interations for model training
max_epochs = 30

# initial learning rate for optimization algorithm
lr = 0.0007

# exponential decay rate for the 1st moment estimates for optimization algorithm
beta_1 = 0.9

# exponential decay rate for the 2nd moment estimates for optimization algorithm
beta_2 = 0.999

# a small constant for numerical stability for optimization algorithm
optimizer_epsilon = 1e-08

model = Sequential([

    InputLayer(batch_input_shape=input_shape),

    Conv1D(kernel_initializer=initializer, activation=activation, padding=""same"", filters=num_filters[0], kernel_size=filter_length),

    Conv1D(kernel_initializer=initializer, activation=activation, padding=""same"", filters=num_filters[1], kernel_size=filter_length),

    MaxPooling1D(pool_size=pool_length),

    Flatten(),

    Dense(units=num_hidden_nodes[0], kernel_initializer=initializer, activation=activation),

    Dense(units=num_hidden_nodes[1], kernel_initializer=initializer, activation=activation),

    Dense(units=3, activation=""linear"", input_dim=num_hidden_nodes[1]),
]) 

# compile model
loss_function = mean squared error
early_stopping_min_delta = 0.0001
early_stopping_patience = 4
reduce_lr_factor = 0.5
reuce_lr_epsilon = 0.0009
reduce_lr_patience = 2
reduce_lr_min = 0.00008

optimizer = Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=optimizer_epsilon, decay=0.0)

early_stopping = EarlyStopping(monitor='val_loss',     min_delta=early_stopping_min_delta, 
                                   patience=early_stopping_patience, verbose=2, mode='min')

reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, epsilon=reuce_lr_epsilon, 
                              patience=reduce_lr_patience,     min_lr=reduce_lr_min, mode='min', verbose=2)

model.compile(optimizer=optimizer, loss=loss_function)

model.fit(train_x, train_y, validation_data=(cv_x, cv_y),
      epochs=max_epochs, batch_size=batch_size, verbose=2,
      callbacks=[reduce_lr,early_stopping])

model.save('model_file.h5')
</code></pre>
"
"How do I check if keras is using gpu version of tensorflow?","<p>When I run a keras script, I get the following output:</p>

<pre><code>Using TensorFlow backend.
2017-06-14 17:40:44.621761: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use SSE4.1 instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:40:44.621783: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use SSE4.2 instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:40:44.621788: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use AVX instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:40:44.621791: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use AVX2 instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:40:44.621795: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use FMA instructions, but these are 
available 
on your machine and could speed up CPU computations.
2017-06-14 17:40:44.721911: I 
tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful 
NUMA node read from SysFS had negative value (-1), but there must be 
at least one NUMA node, so returning NUMA node zero
2017-06-14 17:40:44.722288: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 
with properties: 
name: GeForce GTX 850M
major: 5 minor: 0 memoryClockRate (GHz) 0.9015
pciBusID 0000:0a:00.0
Total memory: 3.95GiB
Free memory: 3.69GiB
2017-06-14 17:40:44.722302: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-06-14 17:40:44.722307: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-06-14 17:40:44.722312: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating 
TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 850M, 
pci bus id: 0000:0a:00.0)
</code></pre>

<p>What does this mean? Am I using GPU or CPU version of tensorflow?</p>

<p>Before installing keras, I was working with the GPU version of tensorflow. </p>

<p>Also <code>sudo pip3 list</code> shows <code>tensorflow-gpu(1.1.0)</code> and nothing like <code>tensorflow-cpu</code>.</p>

<p>Running the command mentioned on [this stackoverflow question], gives the following:</p>

<pre><code>The TensorFlow library wasn't compiled to use SSE4.1 instructions, 
but these are available on your machine and could speed up CPU 
computations.
2017-06-14 17:53:31.424793: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use SSE4.2 instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:53:31.424803: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use AVX instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:53:31.424812: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use AVX2 instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:53:31.424820: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use FMA instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:53:31.540959: I 
tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful 
NUMA node read from SysFS had negative value (-1), but there must be 
at least one NUMA node, so returning NUMA node zero
2017-06-14 17:53:31.541359: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 
with properties: 
name: GeForce GTX 850M
major: 5 minor: 0 memoryClockRate (GHz) 0.9015
pciBusID 0000:0a:00.0
Total memory: 3.95GiB
Free memory: 128.12MiB
2017-06-14 17:53:31.541407: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-06-14 17:53:31.541420: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-06-14 17:53:31.541441: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating 
TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 850M, 
pci bus id: 0000:0a:00.0)
2017-06-14 17:53:31.547902: E 
tensorflow/stream_executor/cuda/cuda_driver.cc:893] failed to 
allocate 128.12M (134348800 bytes) from device: 
CUDA_ERROR_OUT_OF_MEMORY
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce 
GTX 850M, pci bus id: 0000:0a:00.0
2017-06-14 17:53:31.549482: I 
tensorflow/core/common_runtime/direct_session.cc:257] Device 
mapping:
/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce 
GTX 850M, pci bus id: 0000:0a:00.0
</code></pre>
"
"Convert Keras model to C++","<p>I am using Keras (with Theano) to train my CNN model. Does anyone has idea how can I use it in my C++ application? Does anyone tried something similar? I have idea to write some python code that will generate a c++ code with network functions - any suggestion on it?</p>

<p>I found a similar question <a href=""https://stackoverflow.com/questions/36412098/convert-keras-model-to-tensorflow-protobuf"">here</a> how to use Tensorflow Keras model in C++ but without answer.</p>
"
"LSTM Autoencoder","<p>I'm trying to build a LSTM autoencoder with the goal of getting a fixed sized vector from a sequence, which represents the sequence as good as possible. This autoencoder consists of two parts:</p>

<ul>
<li><code>LSTM</code> Encoder: Takes a sequence and returns an output vector (<code>return_sequences = False</code>)</li>
<li><code>LSTM</code> Decoder: Takes an output vector and returns a sequence (<code>return_sequences = True</code>)</li>
</ul>

<p>So, in the end, the encoder is a <strong>many to one</strong> LSTM and the decoder is a <strong>one to many</strong> LSTM.</p>

<p><a href=""https://i.stack.imgur.com/kwhAP.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/kwhAP.jpg"" alt=""enter image description here""></a></p>

<p>On a high level the coding looks like this (similar as described <a href=""https://github.com/fchollet/keras/issues/5138"" rel=""noreferrer"">here</a>):</p>

<pre><code>encoder = Model(...)
decoder = Model(...)

autoencoder = Model(encoder.inputs, decoder(encoder(encoder.inputs)))

autoencoder.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

autoencoder.fit(data, data,
          batch_size=100,
          epochs=1500)
</code></pre>

<p>The shape (number of training examples, sequence length, input dimension) of the <code>data</code> array is <code>(1200, 10, 5)</code> and looks like this:</p>

<pre><code>array([[[1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0],
        [0, 0, 1, 0, 0],
        ..., 
        [0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0]],
        ... ]
</code></pre>

<p><strong>Problem:</strong> I am not sure how to proceed, especially how to integrate <code>LSTM</code> to <code>Model</code> and how to get the decoder to generate a sequence from a vector.</p>

<p>I am using <code>keras</code> with <code>tensorflow</code> backend.</p>

<p><strong>EDIT:</strong> If someone wants to try out, here is my procedure to generate random sequences with moving ones (including padding):</p>

<pre><code>import random
import math

def getNotSoRandomList(x):
    rlen = 8
    rlist = [0 for x in range(rlen)]
    if x &lt;= 7:
        rlist[x] = 1
    return rlist


sequence = [[getNotSoRandomList(x) for x in range(round(random.uniform(0, 10)))] for y in range(5000)]

### Padding afterwards

from keras.preprocessing import sequence as seq

data = seq.pad_sequences(
    sequences = sequence,
    padding='post',
    maxlen=None,
    truncating='post',
    value=0.
)
</code></pre>
"
"Keras and Sklearn logreg returning different results","<p>I'm comparing the results of a logistic regressor written in Keras to the default Sklearn Logreg. My input is one-dimensional. My output has two classes and I'm interested in the probability that the output belongs to the class 1.</p>

<p>I'm expecting the results to be almost identical, but they are not even close.</p>

<p>Here is how I generate my random data. Note that X_train, X_test are still vectors, I'm just using capital letters because I'm used to it. Also there is no need for scaling in this case.</p>

<pre><code>X = np.linspace(0, 1, 10000)
y = np.random.sample(X.shape)
y = np.where(y&lt;X, 1, 0)
</code></pre>

<p>Here's cumsum of y plotted over X. Doing a regression here is not rocket science.</p>

<p><a href=""https://i.stack.imgur.com/1Ba18.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1Ba18.png"" alt=""here&#39;s y plotted over x""></a></p>

<p>I do a standard train-test-split:</p>

<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y)
X_train = X_train.reshape(-1,1)
X_test = X_test.reshape(-1,1)
</code></pre>

<p>Next, I train a default logistic regressor:</p>

<pre><code>from sklearn.linear_model import LogisticRegression
sk_lr = LogisticRegression()
sk_lr.fit(X_train, y_train)
sklearn_logreg_result = sk_lr.predict_proba(X_test)[:,1]
</code></pre>

<p>And a logistic regressor that I write in Keras:</p>

<pre><code>from keras.models import Sequential
from keras.layers import Dense
keras_lr = Sequential()
keras_lr.add(Dense(1, activation='sigmoid', input_dim=1))
keras_lr.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])
_ = keras_lr.fit(X_train, y_train, verbose=0)
keras_lr_result = keras_lr.predict(X_test)[:,0]
</code></pre>

<p>And a hand-made solution:</p>

<pre><code>pearson_corr = np.corrcoef(X_train.reshape(X_train.shape[0],), y_train)[0,1]
b = pearson_corr * np.std(y_train) / np.std(X_train)
a = np.mean(y_train) - b * np.mean(X_train)
handmade_result = (a + b * X_test)[:,0]
</code></pre>

<p>I expect all three to deliver similar results, but here is what happens. This is a reliability diagram using 100 bins.</p>

<p><a href=""https://i.stack.imgur.com/1Zg0z.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1Zg0z.png"" alt=""enter image description here""></a></p>

<p>I have played around with loss functions and other parameters, but the Keras logreg stays roughly like this. What might be causing the problem here?</p>

<p>edit: Using binary crossentropy is not the solution here, as shown by this plot (note that the input data has changed between the two plots).</p>

<p><a href=""https://i.stack.imgur.com/gZEjF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gZEjF.png"" alt=""enter image description here""></a></p>
"
"Keras: ""RuntimeError: Failed to import pydot."" after installing graphviz and pydot","<p>I'm using Anaconda Python 2.7 on windows 10</p>

<p>I was planning on doing Keras visualization so (whilst spyder was open) I opened the Anaconda command prompt and pip installed graphviz and pydot. Now when I try run the following:</p>

<pre><code>from keras.models import Sequential
</code></pre>

<p>or any sort of ""from keras."" ,  I get the error:</p>

<pre><code>ImportError: cannot import name gof
</code></pre>

<p>I have uninstalled and reinstalled Keras, Graphviz and pydot. i am using the development version of theano. I cannot find a fix. </p>

<p><strong>P.S</strong></p>

<p>If I uninstall graphviz and pydot, keras works again</p>

<p><strong>EDIT</strong></p>

<p>After uninstalling anaconda and reinstalling it including theano, keras, <strong>graphviz and pydot</strong> I now get the following error:</p>

<pre><code>from keras.utils.visualize_util import plot

Using Theano backend.
Using gpu device 0: GeForce GTX 970M (CNMeM is disabled, cuDNN not available)
Traceback (most recent call last):

  File ""&lt;ipython-input-1-65016ddab3cd&gt;"", line 1, in &lt;module&gt;
  from keras.utils.visualize_util import plot

  File ""C:\Anaconda2\lib\site-packages\keras\utils\visualize_util.py"", line  8, in &lt;module&gt;
  raise RuntimeError('Failed to import pydot. You must install pydot'

RuntimeError: Failed to import pydot. You must install pydot and graphviz  for `pydotprint` to work.
</code></pre>

<p>I used <code>pip install graphviz</code> and <code>pip install git+https://github.com/nlhepler/pydot.git</code></p>
"
"Keras not using multiple cores","<p>Based on the famous <code>check_blas.py</code> script, I wrote this one to check that theano can in fact use multiple cores:</p>



<pre class=""lang-py prettyprint-override""><code>import os
os.environ['MKL_NUM_THREADS'] = '8'
os.environ['GOTO_NUM_THREADS'] = '8'
os.environ['OMP_NUM_THREADS'] = '8'
os.environ['THEANO_FLAGS'] = 'device=cpu,blas.ldflags=-lblas -lgfortran'

import numpy
import theano
import theano.tensor as T

M=2000
N=2000
K=2000
iters=100
order='C'

a = theano.shared(numpy.ones((M, N), dtype=theano.config.floatX, order=order))
b = theano.shared(numpy.ones((N, K), dtype=theano.config.floatX, order=order))
c = theano.shared(numpy.ones((M, K), dtype=theano.config.floatX, order=order))
f = theano.function([], updates=[(c, 0.4 * c + .8 * T.dot(a, b))])

for i in range(iters):
    f(y)
</code></pre>

<p>Running this as <code>python3 check_theano.py</code> shows that 8 threads are being used. And more importantly, the code runs approximately 9 times faster than without the <code>os.environ</code> settings, which apply just 1 core: 7.863s vs 71.292s on a single run.</p>

<p>So, I would expect that Keras now also uses multiple cores when calling <code>fit</code> (or <code>predict</code> for that matter). However this is not the case for the following code:</p>

<pre class=""lang-py prettyprint-override""><code>import os
os.environ['MKL_NUM_THREADS'] = '8'
os.environ['GOTO_NUM_THREADS'] = '8'
os.environ['OMP_NUM_THREADS'] = '8'
os.environ['THEANO_FLAGS'] = 'device=cpu,blas.ldflags=-lblas -lgfortran'

import numpy
from keras.models import Sequential
from keras.layers import Dense

coeffs = numpy.random.randn(100)

x = numpy.random.randn(100000, 100);
y = numpy.dot(x, coeffs) + numpy.random.randn(100000) * 0.01

model = Sequential()
model.add(Dense(20, input_shape=(100,)))
model.add(Dense(1, input_shape=(20,)))
model.compile(optimizer='rmsprop', loss='categorical_crossentropy')

model.fit(x, y, verbose=0, nb_epoch=10)
</code></pre>

<p>This script uses only 1 core with this output:</p>

<pre class=""lang-py prettyprint-override""><code>Using Theano backend.
/home/herbert/venv3/lib/python3.4/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.
warnings.warn(""downsample module has been moved to the pool module."")
</code></pre>

<p>Why does the <code>fit</code> of Keras only use 1 core for the same setup? Is the <code>check_blas.py</code> script actually representative for neural network training calculations?</p>

<p>FYI:</p>

<pre class=""lang-py prettyprint-override""><code>(venv3)herbert@machine:~/ $ python3 -c 'import numpy, theano, keras; print(numpy.__version__); print(theano.__version__); print(keras.__version__);'
ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.
1.11.0
0.8.0rc1.dev-e6e88ce21df4fbb21c76e68da342e276548d4afd
0.3.2
(venv3)herbert@machine:~/ $
</code></pre>

<p><strong>EDIT</strong></p>

<p>I created a Theano implementaiton of a simple MLP as well, which also does not run multi-core:</p>

<pre class=""lang-py prettyprint-override""><code>import os
os.environ['MKL_NUM_THREADS'] = '8'
os.environ['GOTO_NUM_THREADS'] = '8'
os.environ['OMP_NUM_THREADS'] = '8'
os.environ['THEANO_FLAGS'] = 'device=cpu,blas.ldflags=-lblas -lgfortran'

import numpy
import theano
import theano.tensor as T

M=2000
N=2000
K=2000
iters=100
order='C'

coeffs = numpy.random.randn(100)
x = numpy.random.randn(100000, 100).astype(theano.config.floatX)
y = (numpy.dot(x, coeffs) + numpy.random.randn(100000) * 0.01).astype(theano.config.floatX).reshape(100000, 1)

x_shared = theano.shared(x)
y_shared = theano.shared(y)

x_tensor = T.matrix('x')
y_tensor = T.matrix('y')

W0_values = numpy.asarray(
    numpy.random.uniform(
        low=-numpy.sqrt(6. / 120),
        high=numpy.sqrt(6. / 120),
        size=(100, 20)
    ),
    dtype=theano.config.floatX
)
W0 = theano.shared(value=W0_values, name='W0', borrow=True)

b0_values = numpy.zeros((20,), dtype=theano.config.floatX)
b0 = theano.shared(value=b0_values, name='b0', borrow=True)

output0 = T.dot(x_tensor, W0) + b0

W1_values = numpy.asarray(
    numpy.random.uniform(
        low=-numpy.sqrt(6. / 120),
        high=numpy.sqrt(6. / 120),
        size=(20, 1)
    ),
    dtype=theano.config.floatX
)
W1 = theano.shared(value=W1_values, name='W1', borrow=True)

b1_values = numpy.zeros((1,), dtype=theano.config.floatX)
b1 = theano.shared(value=b1_values, name='b1', borrow=True)

output1 = T.dot(output0, W1) + b1

params = [W0, b0, W1, b1]
cost = ((output1 - y_tensor) ** 2).sum()

gradients = [T.grad(cost, param) for param in params]

learning_rate = 0.0000001

updates = [
    (param, param - learning_rate * gradient)
    for param, gradient in zip(params, gradients)
]

train_model = theano.function(
    inputs=[],#x_tensor, y_tensor],
    outputs=cost,
    updates=updates,
    givens={
        x_tensor: x_shared,
        y_tensor: y_shared
    }
)

errors = []
for i in range(1000):
    errors.append(train_model())

print(errors[0:50:])
</code></pre>
"
"Keras model.summary() result - Understanding the # of Parameters","<p>I have a simple NN model for detecting hand-written digits from a 28x28px image written in python using Keras (Theano backend):</p>

<pre><code>model0 = Sequential()

#number of epochs to train for
nb_epoch = 12
#amount of data each iteration in an epoch sees
batch_size = 128

model0.add(Flatten(input_shape=(1, img_rows, img_cols)))
model0.add(Dense(nb_classes))
model0.add(Activation('softmax'))
model0.compile(loss='categorical_crossentropy', 
         optimizer='sgd',
         metrics=['accuracy'])

model0.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
      verbose=1, validation_data=(X_test, Y_test))

score = model0.evaluate(X_test, Y_test, verbose=0)

print('Test score:', score[0])
print('Test accuracy:', score[1])
</code></pre>

<p>This runs well and I get ~90% accuracy. I then perform the following command to get a summary of my network's structure by doing <code>print(model0.summary())</code>. This outputs the following:</p>

<pre><code>Layer (type)         Output Shape   Param #     Connected to                     
=====================================================================
flatten_1 (Flatten)   (None, 784)     0           flatten_input_1[0][0]            
dense_1 (Dense)     (None, 10)       7850        flatten_1[0][0]                  
activation_1        (None, 10)          0           dense_1[0][0]                    
======================================================================
Total params: 7850
</code></pre>

<p>I don't understand how they get to 7850 total params and what that actually means?</p>
"
"Using Deep Learning to Predict Subsequence from Sequence","<p>I have a data that looks like this:</p>

<p><a href=""https://i.stack.imgur.com/CNK0K.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CNK0K.jpg"" alt=""enter image description here""></a></p>

<p>It can be viewed <a href=""http://dpaste.com/2PZ9WH6"" rel=""nofollow noreferrer"">here</a> and has been included in the code below.
In actuality I have ~7000 samples (row), <a href=""http://www.filedropper.com/test_148"" rel=""nofollow noreferrer"">downloadable too</a>. </p>

<p>The task is given antigen, predict the corresponding epitope.
So epitope is always an exact substring of antigen. This is equivalent with 
the <strong><a href=""http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf"" rel=""nofollow noreferrer"">Sequence to Sequence Learning</a></strong>. Here is my code running on Recurrent Neural Network under Keras. It was modeled according the <a href=""https://github.com/fchollet/keras/blob/master/examples/addition_rnn.py"" rel=""nofollow noreferrer""><strong>example</strong></a>.</p>

<p>My question are:</p>

<ol>
<li>Can RNN, LSTM or GRU used to predict subsequence as posed above?</li>
<li>How can I improve the accuracy of my code?</li>
<li>How can I modify my code so that it can run faster?</li>
</ol>

<p>Here is my running code which gave very bad accuracy score.</p>

<pre><code>#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import print_function
import sys
import json
import pandas as pd
from keras.models import Sequential
from keras.engine.training import slice_X
from keras.layers.core import Activation,  RepeatVector, Dense
from keras.layers import recurrent, TimeDistributed
import numpy as np
from six.moves import range

class CharacterTable(object):
    '''
    Given a set of characters:
    + Encode them to a one hot integer representation
    + Decode the one hot integer representation to their character output
    + Decode a vector of probabilties to their character output
    '''
    def __init__(self, chars, maxlen):
        self.chars = sorted(set(chars))
        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))
        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))
        self.maxlen = maxlen

    def encode(self, C, maxlen=None):
        maxlen = maxlen if maxlen else self.maxlen
        X = np.zeros((maxlen, len(self.chars)))
        for i, c in enumerate(C):
            X[i, self.char_indices[c]] = 1
        return X

    def decode(self, X, calc_argmax=True):
        if calc_argmax:
            X = X.argmax(axis=-1)
        return ''.join(self.indices_char[x] for x in X)

class colors:
    ok = '\033[92m'
    fail = '\033[91m'
    close = '\033[0m'

INVERT = True
HIDDEN_SIZE = 128
BATCH_SIZE = 64
LAYERS = 3
# Try replacing GRU, or SimpleRNN
RNN = recurrent.LSTM


def main():
    """"""
    Epitope_core = answers
    Antigen      = questions
    """"""

    epi_antigen_df = pd.io.parsers.read_table(""http://dpaste.com/2PZ9WH6.txt"")
    antigens = epi_antigen_df[""Antigen""].tolist()
    epitopes = epi_antigen_df[""Epitope Core""].tolist()

    if INVERT:
        antigens = [ x[::-1] for x in antigens]

    allchars = """".join(antigens+epitopes)
    allchars = list(set(allchars))
    aa_chars =  """".join(allchars)
    sys.stderr.write(aa_chars + ""\n"")

    max_antigen_len = len(max(antigens, key=len))
    max_epitope_len = len(max(epitopes, key=len))

    X = np.zeros((len(antigens),max_antigen_len, len(aa_chars)),dtype=np.bool)
    y = np.zeros((len(epitopes),max_epitope_len, len(aa_chars)),dtype=np.bool)

    ctable = CharacterTable(aa_chars, max_antigen_len)

    sys.stderr.write(""Begin vectorization\n"")
    for i, antigen in enumerate(antigens):
        X[i] = ctable.encode(antigen, maxlen=max_antigen_len)
    for i, epitope in enumerate(epitopes):
        y[i] = ctable.encode(epitope, maxlen=max_epitope_len)


    # Shuffle (X, y) in unison as the later parts of X will almost all be larger digits
    indices = np.arange(len(y))
    np.random.shuffle(indices)
    X = X[indices]
    y = y[indices]

    # Explicitly set apart 10% for validation data that we never train over
    split_at = len(X) - len(X) / 10
    (X_train, X_val) = (slice_X(X, 0, split_at), slice_X(X, split_at))
    (y_train, y_val) = (y[:split_at], y[split_at:])

    sys.stderr.write(""Build model\n"")
    model = Sequential()
    # ""Encode"" the input sequence using an RNN, producing an output of HIDDEN_SIZE
    # note: in a situation where your input sequences have a variable length,
    # use input_shape=(None, nb_feature).
    model.add(RNN(HIDDEN_SIZE, input_shape=(max_antigen_len, len(aa_chars))))
    # For the decoder's input, we repeat the encoded input for each time step
    model.add(RepeatVector(max_epitope_len))
    # The decoder RNN could be multiple layers stacked or a single layer
    for _ in range(LAYERS):
        model.add(RNN(HIDDEN_SIZE, return_sequences=True))

    # For each of step of the output sequence, decide which character should be chosen
    model.add(TimeDistributed(Dense(len(aa_chars))))
    model.add(Activation('softmax'))

    model.compile(loss='categorical_crossentropy',
                optimizer='adam',
                metrics=['accuracy'])

    # Train the model each generation and show predictions against the validation dataset
    for iteration in range(1, 200):
        print()
        print('-' * 50)
        print('Iteration', iteration)
        model.fit(X_train, y_train, batch_size=BATCH_SIZE, nb_epoch=5,
                validation_data=(X_val, y_val))
        ###
        # Select 10 samples from the validation set at random so we can visualize errors
        for i in range(10):
            ind = np.random.randint(0, len(X_val))
            rowX, rowy = X_val[np.array([ind])], y_val[np.array([ind])]
            preds = model.predict_classes(rowX, verbose=0)
            q = ctable.decode(rowX[0])
            correct = ctable.decode(rowy[0])
            guess = ctable.decode(preds[0], calc_argmax=False)
            # print('Q', q[::-1] if INVERT else q)
            print('T', correct)
            print(colors.ok + '' + colors.close if correct == guess else colors.fail + '' + colors.close, guess)
            print('---')

if __name__ == '__main__':
    main()
</code></pre>
"
"How to return history of validation loss in Keras","<p>Using Anaconda Python 2.7 Windows 10.</p>

<p>I am training a language model using the Keras exmaple:</p>

<pre><code>print('Build model...')
model = Sequential()
model.add(GRU(512, return_sequences=True, input_shape=(maxlen, len(chars))))
model.add(Dropout(0.2))
model.add(GRU(512, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(len(chars)))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

def sample(a, temperature=1.0):
    # helper function to sample an index from a probability array
    a = np.log(a) / temperature
    a = np.exp(a) / np.sum(np.exp(a))
    return np.argmax(np.random.multinomial(1, a, 1))


# train the model, output generated text after each iteration
for iteration in range(1, 3):
    print()
    print('-' * 50)
    print('Iteration', iteration)
    model.fit(X, y, batch_size=128, nb_epoch=1)
    start_index = random.randint(0, len(text) - maxlen - 1)

    for diversity in [0.2, 0.5, 1.0, 1.2]:
        print()
        print('----- diversity:', diversity)

        generated = ''
        sentence = text[start_index: start_index + maxlen]
        generated += sentence
        print('----- Generating with seed: ""' + sentence + '""')
        sys.stdout.write(generated)

        for i in range(400):
            x = np.zeros((1, maxlen, len(chars)))
            for t, char in enumerate(sentence):
                x[0, t, char_indices[char]] = 1.

            preds = model.predict(x, verbose=0)[0]
            next_index = sample(preds, diversity)
            next_char = indices_char[next_index]

            generated += next_char
            sentence = sentence[1:] + next_char

            sys.stdout.write(next_char)
            sys.stdout.flush()
        print()
</code></pre>

<p>According to Keras documentation, the <code>model.fit</code> method returns a History callback, which has a history attribute containing the lists of successive losses and other metrics.</p>

<pre><code>hist = model.fit(X, y, validation_split=0.2)
print(hist.history)
</code></pre>

<p>After training my model, if I run <code>print(model.history)</code> I get the error:</p>

<pre><code> AttributeError: 'Sequential' object has no attribute 'history'
</code></pre>

<p>How do I return my model history after training my model with the above code?</p>

<p><strong>UPDATE</strong></p>

<p>The issue was that:</p>

<p>The following had to first be defined:</p>

<pre><code>from keras.callbacks import History 
history = History()
</code></pre>

<p>The callbacks option had to be called</p>

<pre><code>model.fit(X_train, Y_train, nb_epoch=5, batch_size=16, callbacks=[history])
</code></pre>

<p>But now if I print</p>

<pre><code>print(history.History)
</code></pre>

<p>it returns</p>

<pre><code>{}
</code></pre>

<p>even though I ran an iteration. </p>
"
"NaN loss when training regression network","<p>I have a data matrix in ""one-hot encoding"" (all ones and zeros) with 260,000 rows and 35 columns.  I am using Keras to train a simple neural network to predict a continuous variable.  The code to make the network is the following:</p>

<pre><code>model = Sequential()
model.add(Dense(1024, input_shape=(n_train,)))
model.add(Activation('relu'))
model.add(Dropout(0.1))

model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.1))

model.add(Dense(256))
model.add(Activation('relu'))
model.add(Dropout(0.1))
model.add(Dense(1))

sgd = SGD(lr=0.01, nesterov=True);
#rms = RMSprop()
#model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])
model.compile(loss='mean_absolute_error', optimizer=sgd)
model.fit(X_train, Y_train, batch_size=32, nb_epoch=3, verbose=1, validation_data=(X_test,Y_test), callbacks=[EarlyStopping(monitor='val_loss', patience=4)] )
</code></pre>

<p>However, during the training process, I see the loss decrease nicely, but during the middle of the second epoch, it goes to nan:</p>

<pre><code>Train on 260000 samples, validate on 64905 samples
Epoch 1/3
260000/260000 [==============================] - 254s - loss: 16.2775 - val_loss:
 13.4925
Epoch 2/3
 88448/260000 [=========&gt;....................] - ETA: 161s - loss: nan
</code></pre>

<p>I tried using <code>RMSProp</code> instead of <code>SGD</code>, I tried <code>tanh</code> instead of <code>relu</code>, I tried with and without dropout, all to no avail.  I tried with a smaller model, i.e. with only one hidden layer, and same issue (it becomes nan at a different point).  However, it does work with less features, i.e. if there are only 5 columns, and gives quite good predictions. It seems to be there is some kind of overflow, but I can't imagine why--the loss is not unreasonably large at all.  </p>

<p>Python version 2.7.11, running on a linux machine, CPU only.  I tested it with the latest version of Theano, and I also get Nans, so I tried going to Theano 0.8.2 and have the same problem.  With the latest version of Keras has the same problem, and also with the 0.3.2 version.  </p>
"
"Keras input explanation: input_shape, units, batch_size, dim, etc","<p>For any keras layer (<code>Layer</code> class), can someone explain how to understand the difference between <code>input_shape</code>, <code>units</code>, <code>dim</code>, etc.?  For example the doc says <code>units</code> specify the output shape of a layer. Say in correspondence with an image of a neural net like the below one, the <code>hidden layer1</code> has 4 units. Does this directly translates to the <code>units</code> attribute of the <code>Layer</code> object or is it shape of every weight in the hidden layer times the number of units? </p>

<p>In short how does one understand/visualize the attributes of the model in particular the layers, as one would do with the given image? 
<a href=""https://i.stack.imgur.com/iHW2o.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/iHW2o.jpg"" alt=""enter image description here""></a></p>
"
"Keras, how do I predict after I trained a model?","<p>I'm playing with the reuters-example dataset and it runs fine (my model is trained).  I read about how to save a model, so I could load it later to use again.  But how do I use this saved model to predict a new text?  Do I use <code>models.predict()</code>?</p>

<p>Do I have to prepare this text in a special way?</p>

<p>I tried it with</p>

<pre><code>import keras.preprocessing.text

text = np.array(['this is just some random, stupid text'])
print(text.shape)

tk = keras.preprocessing.text.Tokenizer(
        nb_words=2000,
        filters=keras.preprocessing.text.base_filter(),
        lower=True,
        split="" "")

tk.fit_on_texts(text)
pred = tk.texts_to_sequences(text)
print(pred)

model.predict(pred)
</code></pre>

<p>But I always get</p>

<pre><code>(1L,)
[[2, 4, 1, 6, 5, 7, 3]]
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-83-42d744d811fb&gt; in &lt;module&gt;()
      7 print(pred)
      8 
----&gt; 9 model.predict(pred)

C:\Users\bkey\Anaconda2\lib\site-packages\keras\models.pyc in predict(self, x, batch_size, verbose)
    457         if self.model is None:
    458             self.build()
--&gt; 459         return self.model.predict(x, batch_size=batch_size, verbose=verbose)
    460 
    461     def predict_on_batch(self, x):

C:\Users\bkey\Anaconda2\lib\site-packages\keras\engine\training.pyc in predict(self, x, batch_size, verbose)
   1132         x = standardize_input_data(x, self.input_names,
   1133                                    self.internal_input_shapes,
-&gt; 1134                                    check_batch_dim=False)
   1135         if self.stateful:
   1136             if x[0].shape[0] &gt; batch_size and x[0].shape[0] % batch_size != 0:

C:\Users\bkey\Anaconda2\lib\site-packages\keras\engine\training.pyc in standardize_input_data(data, names, shapes, check_batch_dim, exception_prefix)
     79     for i in range(len(names)):
     80         array = arrays[i]
---&gt; 81         if len(array.shape) == 1:
     82             array = np.expand_dims(array, 1)
     83             arrays[i] = array

AttributeError: 'list' object has no attribute 'shape'
</code></pre>

<p>Do you have any recommendations as to how to make predictions with a trained model?</p>
"
"Using Keras & Tensorflow with AMD GPU","<p>I'm starting to learn Keras, which I believe is a layer on top of Tensorflow and Theano.  However, I only have access to AMD GPUs such as the AMD R9 280X.</p>

<p>How can I setup my Python environment such that I can make use of my AMD GPUs through Keras/Tensorflow support for OpenCL?</p>

<p>I'm running on OSX.</p>
"
"Confusion between Binary_crossentropy and Categorical_crossentropy","<p>I am doing binary class classification using deep neural network. Whenever I am using binary_crossentropy my model is not giving good accuracy (it is closer to the random prediction). But if I use categorical crossentropy by making the size of the output layer 2, I am getting good accuracy in only 1 epoch which is close to the 0.90. Can anyone please explain what is happening here?</p>
"
"Keras retrieve value of node before activation function","<p>Imagine a fully-connected neural network with its last two layers of the following structure:</p>

<pre><code>[Dense]
    units = 612
    activation = softplus

[Dense]
    units = 1
    activation = sigmoid
</code></pre>

<p>The output value of the net is 1, but I'd like to know what the input x to the sigmoidal function was (must be some high number, since sigm(x) is 1 here).</p>

<p>Folllowing <a href=""https://stackoverflow.com/a/41712013/1922302"">indraforyou's</a> answer I managed to retrieve the output and weights of Keras layers:</p>

<pre><code>outputs = [layer.output for layer in model.layers[-2:]]
functors = [K.function( [model.input]+[K.learning_phase()], [out] ) for out in outputs]

test_input = np.array(...)
layer_outs = [func([test_input, 0.]) for func in functors]

print layer_outs[-1][0]  # -&gt; array([[ 1.]])

dense_0_out = layer_outs[-2][0]                           # shape (612, 1)
dense_1_weights = model.layers[-1].weights[0].get_value() # shape (1, 612)
dense_1_bias = model.layers[-1].weights[1].get_value()

x = np.dot(dense_0_out, dense_1_weights) + dense_1_bias
print x # -&gt; -11.7
</code></pre>

<p>How can x be a negative number? In that case the last layers output should be a number closer to 0.0 than 1.0. Are <code>dense_0_out</code> or <code>dense_1_weights</code> the wrong outputs or weights?</p>
"
"Keras | Getting the Inception v3 example running","<p>I am trying learn some Keras syntax and playing with the <a href=""https://github.com/fchollet/keras/blob/master/examples/inception_v3.py"">Inception v3 example</a></p>

<p>I have a 4-class multiclass classification toy problem so I changed the following lines from the example:</p>

<pre><code>NB_CLASS = 4  # number of classes
DIM_ORDERING = 'tf'  # 'th' (channels, width, height) or 'tf' (width, height, channels)
</code></pre>

<p>My toy datasets have the following dimensions:</p>

<ul>
<li>Size of the array containing all the images:  (595, 299, 299, 3)</li>
<li>Size of the array containing the training images:  (416, 299, 299, 3)</li>
<li>Size of the array containing the training labels:  (179, 4)</li>
<li>Size of the array containing the test images:  (179, 299, 299, 3)</li>
<li>Size of the array containing the test labels:  (179, 4)</li>
</ul>

<p>I then try to train the model with the following code: </p>

<pre><code># fit the model on the batches generated by datagen.flow()
#  https://github.com/fchollet/keras/issues/1627
#    http://keras.io/models/sequential/#sequential-model-methods
checkpointer = ModelCheckpoint(filepath=""/tmp/weights.hdf5"", verbose=1, save_best_only=True)
model.fit_generator(datagen.flow(X_train, Y_train,
                batch_size=32),
                nb_epoch=10,
                samples_per_epoch=32,
                class_weight=None, #classWeights,
                verbose=2,
                validation_data=(X_test, Y_test),
                callbacks=[checkpointer])
</code></pre>

<p>Then I get the following error:</p>

<pre class=""lang-none prettyprint-override""><code>Exception: The model expects 2 input arrays, but only received one array. Found: array with shape (179, 4)`
</code></pre>

<p>Which probably relates to this as Inception would like to have the <a href=""https://arxiv.org/abs/1409.4842"">auxiliary classifiers (Szegedy et al., 2014)</a>:</p>

<pre><code>model = Model(input=img_input, output=[preds, aux_preds])
</code></pre>

<p><strong>How do I give the two labels to the model</strong> in Keras being not an advanced Python programmer either?</p>
"
"Saving tf.trainable_variables() using convert_variables_to_constants","<p>I have a Keras model that I would like to convert to a Tensorflow protobuf (e.g. <code>saved_model.pb</code>).</p>

<p>This model comes from transfer learning on the vgg-19 network in which and the head was cut-off and trained with fully-connected+softmax layers while the rest of the vgg-19 network was frozen</p>

<p>I can load the model in Keras, and then use <code>keras.backend.get_session()</code> to run the model in tensorflow, generating the correct predictions:</p>

<pre><code>frame = preprocess(cv2.imread(""path/to/img.jpg"")
keras_model = keras.models.load_model(""path/to/keras/model.h5"")

keras_prediction = keras_model.predict(frame)

print(keras_prediction)

with keras.backend.get_session() as sess:

    tvars = tf.trainable_variables()

    output = sess.graph.get_tensor_by_name('Softmax:0')
    input_tensor = sess.graph.get_tensor_by_name('input_1:0')

    tf_prediction = sess.run(output, {input_tensor: frame})
    print(tf_prediction) # this matches keras_prediction exactly
</code></pre>

<p>If I don't include the line <code>tvars = tf.trainable_variables()</code>, then the <code>tf_prediction</code> variable is completely wrong and doesn't match the output from <code>keras_prediction</code> at all. In fact all the values in the output (single array with 4 probability values) are exactly the same (~0.25, all adding to 1). This made me suspect that weights for the head are just initialized to 0 if <code>tf.trainable_variables()</code> is not called first, which was confirmed after inspecting the model variables. In any case, calling <code>tf.trainable_variables()</code> causes the tensorflow prediction to be correct.</p>

<p>The problem is that when I try to save this model, the variables from <code>tf.trainable_variables()</code> don't actually get saved to the <code>.pb</code> file:</p>

<pre><code>with keras.backend.get_session() as sess:
    tvars = tf.trainable_variables()

    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), ['Softmax'])
    graph_io.write_graph(constant_graph, './', 'saved_model.pb', as_text=False)
</code></pre>

<p>What I am asking is, how can I save a Keras model as a Tensorflow protobuf with the <code>tf.training_variables()</code> intact? </p>

<p>Thanks so much!</p>
"
"In Keras model.fit_generator() method, what is the generator queue controlled parameter ""max_q_size"" used for?","<p>I built a simple generator that the yields a <code>tuple(inputs, targets)</code> with only single item in the <code>inputs</code> and <code>targets</code> lists--basically crawling the data set, one sample item at a time.</p>

<p>I pass this generator into: </p>

<pre><code>  model.fit_generator(my_generator(),
                      nb_epoch=10,
                      samples_per_epoch=1,
                      max_q_size=1  # defaults to 10
                      )
</code></pre>

<p>I get that:</p>

<ul>
<li><code>nb_epoch</code> is the number of times the training batch will be run</li>
<li><code>samples_per_epoch</code> is the number of samples trained with per epoch</li>
</ul>

<p>But what is <code>max_q_size</code> for and why would it default to 10?  I thought the purpose of using a generator was to batch data sets into reasonable chunks, so why the additional queue? </p>
"
"How to tell Keras stop training based on loss value?","<p>Currently I use the following code:</p>

<pre><code>callbacks = [
    EarlyStopping(monitor='val_loss', patience=2, verbose=0),
    ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),
]
model.fit(X_train.astype('float32'), Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
      shuffle=True, verbose=1, validation_data=(X_valid, Y_valid),
      callbacks=callbacks)
</code></pre>

<p>It tells Keras to stop training when loss didn't improve for 2 epochs. But I want to stop training after loss became smaller than some constant ""THR"":</p>

<pre><code>if val_loss &lt; THR:
    break
</code></pre>

<p>I've seen in documentation there are possibility to make your own callback:
<a href=""http://keras.io/callbacks/"">http://keras.io/callbacks/</a>
But nothing found how to stop training process. I need an advice.</p>
"
"keras BLSTM for sequence labeling","<p>I'm relatively new to neural nets so please excuse my ignorance. I'm trying to adapt the keras BLSTM example <a href=""https://github.com/fchollet/keras/blob/master/examples/imdb_bidirectional_lstm.py"" rel=""noreferrer"">here</a>. The example reads in texts and classifies them as 0 or 1. I want a BLSTM that does something very much like POS tagging, though extras like lemmatizing or other advanced features are not neccessary, I just want a basic model. My data is a list of sentences and each word is given a category 1-8. I want to train a BLSTM that can use this data to predict the category for each word in an unseen sentence.</p>

<p>e.g. input = ['The', 'dog', 'is', 'red'] gives output = [2, 4, 3, 7]</p>

<p>If the keras example is not the best route, I'm open to other suggestions.</p>

<p>I currently have this:</p>

<pre><code>'''Train a Bidirectional LSTM.'''

from __future__ import print_function
import numpy as np
from keras.preprocessing import sequence
from keras.models import Model
from keras.layers import Dense, Dropout, Embedding, LSTM, Input, merge
from prep_nn import prep_scan


np.random.seed(1337)  # for reproducibility
max_features = 20000
batch_size = 16
maxlen = 18

print('Loading data...')
(X_train, y_train), (X_test, y_test) = prep_scan(nb_words=max_features,
                                                 test_split=0.2)
print(len(X_train), 'train sequences')
print(len(X_test), 'test sequences')

print(""Pad sequences (samples x time)"")
# type issues here? float/int?
X_train = sequence.pad_sequences(X_train, value=0.)
X_test = sequence.pad_sequences(X_test, value=0.)  # pad with zeros

print('X_train shape:', X_train.shape)
print('X_test shape:', X_test.shape)

# need to pad y too, because more than 1 ouput value, not classification?
y_train = sequence.pad_sequences(np.array(y_train), value=0.)
y_test = sequence.pad_sequences(np.array(y_test), value=0.)

print('y_train shape:', X_train.shape)
print('y_test shape:', X_test.shape)

# this is the placeholder tensor for the input sequences
sequence = Input(shape=(maxlen,), dtype='int32')

# this embedding layer will transform the sequences of integers
# into vectors of size 128
embedded = Embedding(max_features, 128, input_length=maxlen)(sequence)

# apply forwards LSTM
forwards = LSTM(64)(embedded)
# apply backwards LSTM
backwards = LSTM(64, go_backwards=True)(embedded)

# concatenate the outputs of the 2 LSTMs
merged = merge([forwards, backwards], mode='concat', concat_axis=-1)
after_dp = Dropout(0.5)(merged)
# number after dense has to corresponse to output matrix?
output = Dense(17, activation='sigmoid')(after_dp)

model = Model(input=sequence, output=output)

# try using different optimizers and different optimizer configs
model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])

print('Train...')
model.fit(X_train, y_train,
          batch_size=batch_size,
          nb_epoch=4,
          validation_data=[X_test, y_test])

X_test_new = np.array([[0,0,0,0,0,0,0,0,0,12,3,55,4,34,5,45,3,9],[0,0,0,0,0,0,0,1,7,65,34,67,34,23,24,67,54,43,]])

classes = model.predict(X_test_new, batch_size=16)
print(classes)
</code></pre>

<p>My output is the right dimension, but is giving me floats 0-1. I think this is because it's still looking for binary classfication. Anyone know how to fix this?</p>

<p>SOLVED</p>

<p>Just make sure the labels are each binary arrays:</p>

<pre><code>(X_train, y_train), (X_test, y_test), maxlen, word_ids, tags_ids = prep_model(
    nb_words=nb_words, test_len=75)

W = (y_train &gt; 0).astype('float')

print(len(X_train), 'train sequences')
print(int(len(X_train)*val_split), 'validation sequences')
print(len(X_test), 'heldout sequences')

# this is the placeholder tensor for the input sequences
sequence = Input(shape=(maxlen,), dtype='int32')

# this embedding layer will transform the sequences of integers
# into vectors of size 256
embedded = Embedding(nb_words, output_dim=hidden,
                     input_length=maxlen, mask_zero=True)(sequence)

# apply forwards LSTM
forwards = LSTM(output_dim=hidden, return_sequences=True)(embedded)
# apply backwards LSTM
backwards = LSTM(output_dim=hidden, return_sequences=True,
                 go_backwards=True)(embedded)

# concatenate the outputs of the 2 LSTMs
merged = merge([forwards, backwards], mode='concat', concat_axis=-1)
after_dp = Dropout(0.15)(merged)

# TimeDistributed for sequence
# change activation to sigmoid?
output = TimeDistributed(
    Dense(output_dim=nb_classes,
          activation='softmax'))(after_dp)

model = Model(input=sequence, output=output)

# try using different optimizers and different optimizer configs
# loss=binary_crossentropy, optimizer=rmsprop
model.compile(loss='categorical_crossentropy',
              metrics=['accuracy'], optimizer='adam',
              sample_weight_mode='temporal')

print('Train...')
model.fit(X_train, y_train,
          batch_size=batch_size,
          nb_epoch=epochs,
          shuffle=True,
          validation_split=val_split,
          sample_weight=W)
</code></pre>
"
"Building a mutlivariate, multi-task LSTM with Keras","<p><strong>Preamble</strong></p>

<p>I am currently working on a Machine Learning problem where we are tasked with using past data on product sales in order to predict sales volumes going forward (so that shops can better plan their stocks). We essentially have time series data, where for each and every product we know how many units were sold on which days. We also have information like what the weather was like, whether there was a public holiday, if any of the products were on sales etc. </p>

<p>We've been able to model this with some success using an MLP with dense layers, and just using a sliding window approach to include sales volumes from the surrounding days. However, we believe we'll be able to get much better results with a time-series approach such as an LSTM.</p>

<p><strong>Data</strong></p>

<p>The data we have essentially is as follows:</p>

<p><a href=""https://i.stack.imgur.com/fOr4z.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/fOr4z.jpg"" alt=""enter image description here""></a></p>

<p>(<strong>EDIT:</strong> for clarity the ""Time"" column in the picture above is not correct. We have inputs once per day, not once per month. But otherwise the structure is the same!)</p>

<p>So the X data is of shape:</p>

<pre><code>(numProducts, numTimesteps, numFeatures) = (50 products, 1096 days, 90 features)
</code></pre>

<p>And the Y data is of shape:</p>

<pre><code>(numProducts, numTimesteps, numTargets) =  (50 products, 1096 days, 3 binary targets)
</code></pre>

<p><a href=""https://i.stack.imgur.com/uaSl5.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/uaSl5.jpg"" alt=""enter image description here""></a></p>

<p>So we have data for three years (2014, 2015, 2016) and want to train on this in order to make predictions for 2017. (That's of course not 100% true, since we actually have data up to Oct 2017, but let's just ignore that for now)</p>

<p><strong>Problem</strong></p>

<p>I would like to build an LSTM in Keras that allows me to make these predictions. There are a few places where I am getting stuck though. So I have six concrete questions (I know one is supposed to try to limit a Stackoverflow post to one question, but these are all intertwined).</p>

<p>Firstly, <strong>how would I slice up my data for the batches</strong>? Since I have three full years, does it make sense to simply push through three batches, each time of size one year? Or does it make more sense to make smaller batches (say 30 days) and also to using sliding windows? I.e. instead of 36 batches of 30 days each, I use 36 * 6 batches of 30 days each, each time sliding with 5 days? Or is this not really the way LSTMs should be used? (Note that there is quite a bit of seasonality in the data, to I need to catch that kind of long-term trend as well).</p>

<p>Secondly, <strong>does it make sense to use</strong> <code>return_sequences=True</code> here? In other words, I keep my Y data as is <code>(50, 1096, 3)</code> so that (as far as I've understood it) there is a prediction at every time step for which a loss can be calculated against the target data? Or would I be better off with <code>return_sequences=False</code>, so that only the final value of each batch is used to evaluate the loss (i.e. if using yearly batches, then in 2016 for product 1, we evaluate against the Dec 2016 value of <code>(1,1,1)</code>).</p>

<p>Thirdly <strong>how should I deal with the 50 different products?</strong> They are different, but still strongly correlated and we've seen with other approaches (for example an MLP with simple time-windows) that the results are better when all products are considered in the same model. Some ideas that are currently on the table are:</p>

<ul>
<li>change the target variable to be not just 3 variables, but 3 * 50 = 150; i.e. for each product there are three targets, all of which are trained simultaneously. </li>
<li>split up the results after the LSTM layer into 50 dense networks, which take as input the ouputs from the LSTM, plus some features that are specific to each product - i.e. we get a multi-task network with 50 loss functions, which we then optimise together. Would that be crazy?</li>
<li>consider a product as a single observation, and include product specific features already at the LSTM layer. Use just this one layer followed by an ouput layer of size 3 (for the three targets). Push through each product in a separate batch.</li>
</ul>

<p>Fourthly, <strong>how do I deal with validation data</strong>? Normally I would just keep out a randomly selected sample to validate against, but here we need to keep the time ordering in place. So I guess the best is to just keep a few months aside?</p>

<p>Fifthly, and this is the part that is probably the most unclear to me - <strong>how can I use the actual results to perform predictions</strong>? Let's  say I used <code>return_sequences=False</code> and I trained on all three years in three batches (each time up to Nov) with the goal of training the model to predict the next value (Dec 2014, Dec 2015, Dec 2016). If I want to use these results in 2017, how does this actually work? If I understood it correctly, the only thing I can do in this instance is to then feed the model all the data points for Jan to Nov 2017 and it will give me back a prediction for Dec 2017. Is that correct? However, if I were to use <code>return_sequences=True</code>, then trained on all data up to Dec 2016, would I then be able to get a prediction for Jan 2017 just by giving the model the features observed at Jan 2017? Or do I need to also give it the 12 months before Jan 2017? What about Feb 2017, do I in addition need to give the value for 2017, plus a further 11 months before that? (If it sounds like I'm confused, it's because I am!)</p>

<p>Lastly, depending on what structure I should use, <strong>how do I do this in Keras</strong>? What I have in mind at the moment is something along the following lines: (though this would be for only one product, so doesn't solve having all products in the same model):</p>

<p><strong>Keras code</strong></p>

<pre><code>trainX = trainingDataReshaped #Data for Product 1, Jan 2014 to Dec 2016
trainY = trainingTargetReshaped
validX = validDataReshaped #Data for Product 1, for ??? Maybe for a few months?
validY = validTargetReshaped    

numSequences = trainX.shape[0]
numTimeSteps = trainX.shape[1]
numFeatures = trainX.shape[2]

numTargets = trainY.shape[2]

model = Sequential()
model.add(LSTM(100, input_shape=(None, numFeatures), return_sequences=True)) 
model.add(Dense(numTargets, activation=""softmax""))    

model.compile(loss=stackEntry.params[""loss""],
      optimizer=""adam"",
      metrics=['accuracy'])

history = model.fit(trainX, trainY,
            batch_size=30,
            epochs=20,
            verbose=1,
            validation_data=(validX, validY))               

predictX  = predictionDataReshaped #Data for Product 1, Jan 2017 to Dec 2017

prediction=model.predict(predictX)
</code></pre>
"
"Keras network can never classify the last class","<p>I have been working on my project <a href=""https://github.com/aliostad/deep-learning-lang-detection"" rel=""noreferrer"">Deep Learning Language Detection</a> which is a network with these layers to recognise from 16 programming languages:</p>

<p><a href=""https://i.stack.imgur.com/SF1F0.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/SF1F0.jpg"" alt=""enter image description here""></a></p>

<p>And this is the code to produce the network:</p>

<pre><code># Setting up the model
graph_in = Input(shape=(sequence_length, number_of_quantised_characters))
convs = []
for i in range(0, len(filter_sizes)):
    conv = Conv1D(filters=num_filters,
                  kernel_size=filter_sizes[i],
                  padding='valid',
                  activation='relu',
                  strides=1)(graph_in)
    pool = MaxPooling1D(pool_size=pooling_sizes[i])(conv)
    flatten = Flatten()(pool)
    convs.append(flatten)

if len(filter_sizes)&gt;1:
    out = Concatenate()(convs)
else:
    out = convs[0]

graph = Model(inputs=graph_in, outputs=out)

# main sequential model
model = Sequential()


model.add(Dropout(dropout_prob[0], input_shape=(sequence_length, number_of_quantised_characters)))
model.add(graph)
model.add(Dense(hidden_dims))
model.add(Dropout(dropout_prob[1]))
model.add(Dense(number_of_classes))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])
</code></pre>

<p>So my last language class is SQL and in the test phase, it can never predict SQL correctly and it scores 0% on them. I thought this was due to poor quality of SQL samples (and indeed they were poor) so I removed this class and started training on 15 classes. To my surprise, now F# files had 0% detection and F# was the last class after removing SQL (i.e. the one-hot-vector where the last position is 1 and the rest is 0). Now if a network that was trained on 16 used against 15, it would achieve a very high success rate of 98.5%.</p>

<p>The code that I am using is pretty simple and available mainly in <a href=""https://github.com/aliostad/deep-learning-lang-detection/blob/master/defs.py"" rel=""noreferrer"">defs.py</a> and <a href=""https://github.com/aliostad/deep-learning-lang-detection/blob/master/data_helper.py"" rel=""noreferrer"">data_helper.py</a></p>

<p>Here is the result of network trained with 16 classes tested against 16 classes:</p>

<pre><code>Final result: 14827/16016 (0.925761738262)
xml:        995/1001 (0.994005994006)
fsharp:     974/1001 (0.973026973027)
clojure:        993/1001 (0.992007992008)
java:       996/1001 (0.995004995005)
scala:      990/1001 (0.989010989011)
python:     983/1001 (0.982017982018)
sql:        0/1001 (0.0)
js:     991/1001 (0.99000999001)
cpp:        988/1001 (0.987012987013)
css:        987/1001 (0.986013986014)
csharp:     994/1001 (0.993006993007)
go:     989/1001 (0.988011988012)
php:        998/1001 (0.997002997003)
ruby:       995/1001 (0.994005994006)
powershell:     992/1001 (0.991008991009)
bash:       962/1001 (0.961038961039)
</code></pre>

<p>And this is the result of the same network (trained against 16) ran against 15 classes:</p>

<pre><code>Final result: 14827/15015 (0.987479187479)
xml:        995/1001 (0.994005994006)
fsharp:     974/1001 (0.973026973027)
clojure:        993/1001 (0.992007992008)
java:       996/1001 (0.995004995005)
scala:      990/1001 (0.989010989011)
python:     983/1001 (0.982017982018)
js:     991/1001 (0.99000999001)
cpp:        988/1001 (0.987012987013)
css:        987/1001 (0.986013986014)
csharp:     994/1001 (0.993006993007)
go:     989/1001 (0.988011988012)
php:        998/1001 (0.997002997003)
ruby:       995/1001 (0.994005994006)
powershell:     992/1001 (0.991008991009)
bash:       962/1001 (0.961038961039)
</code></pre>

<p>Has anyone else seen this? How can I get around it?</p>
"
"input dimensions to a one dimensional convolutional network in keras","<p>really finding it hard to understand the input dimensions to the convolutional 1d <a href=""http://keras.io/layers/convolutional/#convolution1d"" rel=""noreferrer"">layer</a> in keras:</p>

<p>Input shape</p>

<p>3D tensor with shape: (samples, steps, input_dim).</p>

<p>Output shape</p>

<p>3D tensor with shape: (samples, new_steps, nb_filter). steps value might have changed due to padding.</p>

<p>I want my network to take in a time series of prices (101, in order) and output 4 probabilities. My current non-convolutional network which does this fairly well (with a training set of 28000) looks like this:</p>

<pre><code>standardModel = Sequential()
standardModel.add(Dense(input_dim=101, output_dim=100, W_regularizer=l2(0.5), activation='sigmoid'))
standardModel.add(Dense(4, W_regularizer=l2(0.7), activation='softmax'))
</code></pre>

<p>To improve this, I want to make a feature map from the input layer which has a local receptive field of length 10. (and therefore has 10 shared weights and 1 shared bias). I then want to use max pooling and feed this in to a hidden layer of 40 or so neurons and then output this with 4 neurons with softmax in the outer layer. </p>

<p><a href=""http://i.stack.imgur.com/Kx8yT.png"" rel=""noreferrer"">picture (it's quite awful sorry!)</a></p>

<p>So ideally, the convolutional layer would take a 2d tensor of dimensions:</p>

<p>(minibatch_size, 101)</p>

<p>and output a 3d tensor of dimensions</p>

<p>(minibatch_size, 91, no_of_featuremaps)</p>

<p>However, the keras layer seems to require a dimension in the input called step. I've tried understanding this and still don't quite get it. In my case, should step be 1 as each step in the vector is an increase in the time by 1? Also, what is new_step? </p>

<p>In addition, how do you turn the output of the pooling layers (a 3d tensor) into input suitable for the standard hidden layer (i.e a Dense keras layer) in the form of a 2d tensor?</p>

<p>Update: After the very helpful suggestions given, I tried making a convolutional network like so:</p>

<pre><code>conv = Sequential()
conv.add(Convolution1D(64, 10, input_shape=(1,101)))
conv.add(Activation('relu'))
conv.add(MaxPooling1D(2))
conv.add(Flatten())
conv.add(Dense(10))
conv.add(Activation('tanh'))
conv.add(Dense(4))
conv.add(Activation('softmax'))
</code></pre>

<p>The line conv.Add(Flatten()) throws a range exceeds valid bounds error. Interestingly, this error is <strong>not</strong> thrown for just this code:</p>

<pre><code>conv = Sequential()
conv.add(Convolution1D(64, 10, input_shape=(1,101)))
conv.add(Activation('relu'))
conv.add(MaxPooling1D(2))
conv.add(Flatten())
</code></pre>

<p>doing </p>

<pre><code>print conv.input_shape
print conv.output_shape
</code></pre>

<p>results in </p>

<pre><code>(None, 1, 101
(None, -256)
</code></pre>

<p>being returned</p>

<p>Update 2:</p>

<p>Changed </p>

<pre><code>conv.add(Convolution1D(64, 10, input_shape=(1,101)))
</code></pre>

<p>to</p>

<pre><code>conv.add(Convolution1D(10, 10, input_shape=(101,1))
</code></pre>

<p>and it started working. However, is there any important different between 
inputting (None, 101, 1) to a 1d conv layer or (None, 1, 101) that I should be aware of? Why does (None, 1, 101) not work?</p>
"
"Can Keras deal with input images with different size?","<p>Can the Keras deal with input images with different size? For example, in the fully convolutional neural network, the input images can have any size. However, we need to specify the input shape when we create a network by Keras. Therefore, how can we use Keras to deal with different input size without resizing the input images to the same size? Thanks for any help.</p>
"
"Keras uses way too much GPU memory when calling train_on_batch, fit, etc","<p>I've been messing with Keras, and like it so far. There's one big issue I have been having, when working with fairly deep networks: When calling model.train_on_batch, or model.fit etc., Keras allocates significantly more GPU memory than what the model itself should need. This is not caused by trying to train on some really large images, it's the network model itself that seems to require a lot of GPU memory. I have created this toy example to show what I mean. Here's essentially what's going on:</p>

<p>I first create a fairly deep network, and use model.summary() to get the total number of parameters needed for the network (in this case 206538153, which corresponds to about 826 MB). I then use nvidia-smi to see how much GPU memory Keras has allocated, and I can see that it makes perfect sense (849 MB).</p>

<p>I then compile the network, and can confirm that this does not increase GPU memory usage. And as we can see in this case, I have almost 1 GB of VRAM available at this point.</p>

<p>Then I try to feed a simple 16x16 image and a 1x1 ground truth to the network, and then everything blows up, because Keras starts allocating lots of memory again, for no reason that is obvious to me. Something about training the network seems to require a lot more memory than just having the model, which doesn't make sense to me. I have trained significantly deeper networks on this GPU in other frameworks, so that makes me think that I'm using Keras wrong (or there's something wrong in my setup, or in Keras, but of course that's hard to know for sure).</p>

<p>Here's the code:</p>



<pre class=""lang-python prettyprint-override""><code>from scipy import misc
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Reshape, Flatten, ZeroPadding2D, Dropout
import os

model = Sequential()

model.add(Convolution2D(256, 3, 3, border_mode='same', input_shape=(16,16,1)))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))
model.add(Convolution2D(512, 3, 3, border_mode='same'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(Convolution2D(1024, 3, 3, border_mode='same'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))
model.add(Convolution2D(256, 3, 3, border_mode='same'))
model.add(Convolution2D(32, 3, 3, border_mode='same'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Flatten())
model.add(Dense(4))
model.add(Dense(1))

model.summary()

os.system(""nvidia-smi"")
raw_input(""Press Enter to continue..."")    

model.compile(optimizer='sgd',
              loss='mse', 
              metrics=['accuracy'])

os.system(""nvidia-smi"")              
raw_input(""Compiled model. Press Enter to continue..."")

n_batches = 1
batch_size = 1
for ibatch in range(n_batches):
    x = np.random.rand(batch_size, 16,16,1)
    y = np.random.rand(batch_size, 1)

    os.system(""nvidia-smi"")
    raw_input(""About to train one iteration. Press Enter to continue..."")

    model.train_on_batch(x, y)         
    print(""Trained one iteration"")
</code></pre>

<p>Which gives the following output for me:</p>

<pre class=""lang-python prettyprint-override""><code>Using Theano backend.
Using gpu device 0: GeForce GTX 960 (CNMeM is disabled, cuDNN 5103)
/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.
  warnings.warn(warn)
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 256)   2560        convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 8, 8, 256)     0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 8, 8, 512)     1180160     maxpooling2d_1[0][0]             
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 4, 4, 512)     0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 4, 4, 1024)    4719616     maxpooling2d_2[0][0]             
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 4, 4, 1024)    9438208     convolution2d_3[0][0]            
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 4, 4, 1024)    9438208     convolution2d_4[0][0]            
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 4, 4, 1024)    9438208     convolution2d_5[0][0]            
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 4, 4, 1024)    9438208     convolution2d_6[0][0]            
____________________________________________________________________________________________________
convolution2d_8 (Convolution2D)  (None, 4, 4, 1024)    9438208     convolution2d_7[0][0]            
____________________________________________________________________________________________________
convolution2d_9 (Convolution2D)  (None, 4, 4, 1024)    9438208     convolution2d_8[0][0]            
____________________________________________________________________________________________________
convolution2d_10 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_9[0][0]            
____________________________________________________________________________________________________
convolution2d_11 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_10[0][0]           
____________________________________________________________________________________________________
convolution2d_12 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_11[0][0]           
____________________________________________________________________________________________________
convolution2d_13 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_12[0][0]           
____________________________________________________________________________________________________
convolution2d_14 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_13[0][0]           
____________________________________________________________________________________________________
convolution2d_15 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_14[0][0]           
____________________________________________________________________________________________________
convolution2d_16 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_15[0][0]           
____________________________________________________________________________________________________
convolution2d_17 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_16[0][0]           
____________________________________________________________________________________________________
convolution2d_18 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_17[0][0]           
____________________________________________________________________________________________________
convolution2d_19 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_18[0][0]           
____________________________________________________________________________________________________
convolution2d_20 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_19[0][0]           
____________________________________________________________________________________________________
convolution2d_21 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_20[0][0]           
____________________________________________________________________________________________________
convolution2d_22 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_21[0][0]           
____________________________________________________________________________________________________
convolution2d_23 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_22[0][0]           
____________________________________________________________________________________________________
convolution2d_24 (Convolution2D) (None, 4, 4, 1024)    9438208     convolution2d_23[0][0]           
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 2, 2, 1024)    0           convolution2d_24[0][0]           
____________________________________________________________________________________________________
convolution2d_25 (Convolution2D) (None, 2, 2, 256)     2359552     maxpooling2d_3[0][0]             
____________________________________________________________________________________________________
convolution2d_26 (Convolution2D) (None, 2, 2, 32)      73760       convolution2d_25[0][0]           
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 1, 1, 32)      0           convolution2d_26[0][0]           
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 32)            0           maxpooling2d_4[0][0]             
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 4)             132         flatten_1[0][0]                  
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             5           dense_1[0][0]                    
====================================================================================================
Total params: 206538153
____________________________________________________________________________________________________
None
Thu Oct  6 09:05:42 2016       
+------------------------------------------------------+                       
| NVIDIA-SMI 352.63     Driver Version: 352.63         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 960     Off  | 0000:01:00.0      On |                  N/A |
| 30%   37C    P2    28W / 120W |   1082MiB /  2044MiB |      9%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1796    G   /usr/bin/X                                     155MiB |
|    0      2597    G   compiz                                          65MiB |
|    0      5966    C   python                                         849MiB |
+-----------------------------------------------------------------------------+
Press Enter to continue...
Thu Oct  6 09:05:44 2016       
+------------------------------------------------------+                       
| NVIDIA-SMI 352.63     Driver Version: 352.63         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 960     Off  | 0000:01:00.0      On |                  N/A |
| 30%   38C    P2    28W / 120W |   1082MiB /  2044MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1796    G   /usr/bin/X                                     155MiB |
|    0      2597    G   compiz                                          65MiB |
|    0      5966    C   python                                         849MiB |
+-----------------------------------------------------------------------------+
Compiled model. Press Enter to continue...
Thu Oct  6 09:05:44 2016       
+------------------------------------------------------+                       
| NVIDIA-SMI 352.63     Driver Version: 352.63         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 960     Off  | 0000:01:00.0      On |                  N/A |
| 30%   38C    P2    28W / 120W |   1082MiB /  2044MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1796    G   /usr/bin/X                                     155MiB |
|    0      2597    G   compiz                                          65MiB |
|    0      5966    C   python                                         849MiB |
+-----------------------------------------------------------------------------+
About to train one iteration. Press Enter to continue...
Error allocating 37748736 bytes of device memory (out of memory). Driver report 34205696 bytes free and 2144010240 bytes total 
Traceback (most recent call last):
  File ""memtest.py"", line 65, in &lt;module&gt;
    model.train_on_batch(x, y)         
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 712, in train_on_batch
    class_weight=class_weight)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1221, in train_on_batch
    outputs = self.train_function(ins)
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 717, in __call__
    return self.function(*inputs)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
MemoryError: Error allocating 37748736 bytes of device memory (out of memory).
Apply node that caused the error: GpuContiguous(GpuDimShuffle{3,2,0,1}.0)
Toposort index: 338
Inputs types: [CudaNdarrayType(float32, 4D)]
Inputs shapes: [(1024, 1024, 3, 3)]
Inputs strides: [(1, 1024, 3145728, 1048576)]
Inputs values: ['not shown']
Outputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='half', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0}), GpuDnnConvGradI{algo='none', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='half', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
</code></pre>

<p>A few things to note: </p>

<ul>
<li>I have tried both Theano and TensorFlow backends. Both have the same problems, and run out of memory at the same line. In TensorFlow, it seems that Keras preallocates a lot of memory (about 1.5 GB) so nvidia-smi doesn't help us track what's going on there, but I get the same out-of-memory exceptions. Again, this points towards an error in (my usage of) Keras (although it's hard to be certain about such things, it could be something with my setup).</li>
<li>I tried using CNMEM in Theano, which behaves like TensorFlow: It preallocates a large amount of memory (about 1.5 GB) yet crashes in the same place.</li>
<li>There are some warnings about the CudNN-version. I tried running the Theano backend with CUDA but not CudNN and I got the same errors, so that is not the source of the problem.</li>
<li>If you want to test this on your own GPU, you might want to make the network deeper/shallower depending on how much GPU memory you have to test this.</li>
<li>My configuration is as follows: Ubuntu 14.04, GeForce GTX 960, CUDA 7.5.18, CudNN 5.1.3, Python 2.7, Keras 1.1.0 (installed via pip)</li>
<li>I've tried changing the compilation of the model to use different optimizers and losses, but that doesn't seem to change anything.</li>
<li>I've tried changing the train_on_batch function to use fit instead, but it has the same problem.</li>
<li>I saw one similar question here on StackOverflow - <a href=""https://stackoverflow.com/questions/35757151/why-does-this-keras-model-require-over-6gb-of-memory"">Why does this Keras model require over 6GB of memory?</a> - but as far as I can tell, I don't have those issues in my configuration. I've never had multiple versions of CUDA installed, and I've double checked my PATH, LD_LIBRARY_PATH and CUDA_ROOT variables more times than I can count.</li>
<li>Julius suggested that the activation parameters themselves take up GPU memory. If this is true, can somebody explain it a bit more clearly? I have tried changing the activation function of my convolution layers to functions that are clearly hard-coded with no learnable parameters as far as I can tell, and that doesn't change anything. Also, it seems unlikely that these parameters would take up almost as much memory as the rest of the network itself.</li>
<li>After thorough testing, the largest network I can train is about 453 MB of parameters, out of my ~2 GB of GPU RAM. Is this normal? </li>
<li>After testing Keras on some smaller CNNs that do fit in my GPU, I can see that there are very sudden spikes in GPU RAM usage. If I run a network with about 100 MB of parameters, 99% of the time during training it'll be using less than 200 MB of GPU RAM. But every once in a while, memory usage spikes to about 1.3 GB. It seems safe to assume that it's these spikes that are causing my problems. I've never seen these spikes in other frameworks, but they might be there for a good reason? <strong>If anybody knows what causes them, and if there's a way to avoid them, please chime in!</strong></li>
</ul>
"
"Recurrentshop and Keras: multi-dimensional RNN results in a dimensions mismatch error","<p>I have an issue with Recurrentshop and Keras. I am trying to use Concatenate and multidimensional tensors in a Recurrent Model, and I get dimension issue regardless of how I arrange the  Input, shape and batch_shape.</p>

<p>Minimal code:</p>

<pre><code>from keras.layers import *
from keras.models import *
from recurrentshop import *
from keras.layers import Concatenate

input_shape=(128,128,3)

x_t = Input(shape=(128,128,3,))
h_tm1 = Input(shape=(128,128,3, ))

h_t1 = Concatenate()([x_t, h_tm1])
last = Conv2D(3, kernel_size=(3,3), strides=(1,1), padding='same',     name='conv2')(h_t1)

# Build the RNN
rnn = RecurrentModel(input=x_t, initial_states=[h_tm1], output=last,     final_states=[last], state_initializer=['zeros'])

x = Input(shape=(128,128,3, ))
y = rnn(x)

model = Model(x, y)

model.predict(np.random.random((1, 128, 128, 3)))
</code></pre>

<p>ErrorCode:</p>

<pre><code>ValueError: Shape must be rank 3 but it is rank 4 for 'recurrent_model_1/concatenate_1/concat' (op:ConcatV2) with input shapes: [?,128,3], [?,128,128,3], [].
</code></pre>

<p>Please help.</p>
"